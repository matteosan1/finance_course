{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VaR and Credit Risk - Practical Lesson 9\n",
    "\n",
    "## Overview\n",
    "In past lessons we have already seen the concepts of credit event, survival probability and hazard rate.\n",
    "Today we will concentrate more on the credit risk topic studying few more examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value at Risk \n",
    "\n",
    "The value at risk (VaR) of a portfolio is a function of two parameters (time horizon and confidence level) and it is usually involved when it is important to know to a certain precentage of confidence ($X$) how much will be the maximum loss\n",
    "in the next $N $days. It can be interpreted as the loss level over $N$ days that has a probability of only $(100 - X)\\%$ of being exceeded.\n",
    "\n",
    "Mathematically the VaR is the loss corresponding to the $(100-X)\\textrm{th}$ precentile of the distribution of the change in the value of the portfolio over the next $N$ days.\n",
    "For example, with $N=1$ and $X=95$, VaR is the fifth percentile of the distribution of changes in the value of the portfolio over the next day (e.g. in the next picture the graphical representation of the VaR assuming a normal distribution for the changes of value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline\n",
    "\n",
    "mu=0\n",
    "sigma = 1\n",
    "x = np.arange(-10, -1.645, 0.001)\n",
    "x_all = np.arange(-4, 4, 0.001)\n",
    "y = norm.pdf(x, 0, 1)\n",
    "y2 = norm.pdf(x_all, 0, 1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.style.use('fivethirtyeight')\n",
    "ax.plot(x_all, y2)\n",
    "\n",
    "ax.fill_between(x, y, 0, alpha=0.3, color='b')\n",
    "ax.fill_between(x_all, y2, 0, alpha=0.1)\n",
    "ax.set_xlim([-4, 4])\n",
    "ax.set_xlabel(\"Changes of value\")\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title(\"Distribution of changes of value\")\n",
    "plt.axvline(x=-1.645, ymin=0, ymax=90,linestyle=':',linewidth=1, color = 'k')\n",
    "plt.text(-1.9, .12, '95% percentile (VaR loss)',fontsize=10, rotation=90, color='k')\n",
    "\n",
    "plt.savefig('normal_curve.png', dpi=72, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VaR is useful to summarize all the information about the risk of a portfolio in one single number, but this can be also considered its main limitation (too much simplification).\n",
    "\n",
    "Concerning the time horizon parameter it is usually set to $N=1$ since it is not easy to estimate market variables over periods longer than 1 day. To generalize the VaR estimate it is assumed:\n",
    "\n",
    "$$\\textrm{N-day VaR} = \\textrm{1-day VaR}\\times \\sqrt{N}$$\n",
    "\n",
    "This relation is true only if the value changes of the portfolio over the considered period of time have indipendent and identical normal distributions with mean 0 (otherwise it is just an approximation).\n",
    "\n",
    "## How to Estimate the VaR\n",
    "\n",
    "### Historical Simulation\n",
    "In order to estimate the VaR from an historical series, we need to collect the market variables affecting the portfolio over the last $N$ days (with $N$ quite large). \n",
    "\n",
    "The variation over each day in our time interval will provide different scenarios to be applied to today's market simulation so that for each of them we need to compute the variation in the portfolio value ($\\Delta P$). Our VaR estimate will be the (100 - X)% percentile of the resulting distribution.\n",
    "Given the 1-day VaR it is then possible to determine the N-day VaR using the above formula.\n",
    "\n",
    "Of course such historical simulation relies on the assumption that past behaviors are indicative of what might happen in the future.\n",
    "\n",
    "#### Example\n",
    "Imagine a portfolio $P$ whose value depends only on two market variables ($x_1(t) , x_2(t)$). From the historical series of the market variables we can determine various *simulated* portfolio values:\n",
    "\n",
    "$$P_i(t_n+1) = P\\Big(x_1(t_n)\\frac{x_1(t_i)}{x_1(t_{i-1})} , x_2(t_n)\\frac{x_2(t_i)}{x_2(t_{i-1})}\\Big)$$\n",
    "\n",
    "Essentially rescaling the market variables according to the variation between day $i$ and $i-1$ we can draw a distribution of the possible changes in the portfolio value $P_i$ and then compute the VaR taking the appropriate percentile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming the last value is today's one\n",
    "var = [0.56, 0.75, 0.44, 0.50]\n",
    "\n",
    "scenario1 = var[-1] * var[1] / var[0]\n",
    "scenario2 = var[-1] * var[2] / var[1]\n",
    "scenario3 = var[-1] * var[3] / var[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to Compute Percentiles in Python\n",
    "\n",
    "Later we will see how to compute percentiles of a gaussian distribution without using python but for I would like to mention that `numpy` has a convinient functions to compute n-percentiles of a generic distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.16 10.  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "dist = [2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "perc = numpy.percentile(dist, [1, 50])\n",
    "print (perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3989422804014327\n",
      "0.5\n",
      "-2.3263478740408408\n"
     ]
    }
   ],
   "source": [
    "# when dealing with gaussian distributions a couple more of\n",
    "# functions may be useful\n",
    "# all of them refers to a standard gaussian mu=0; sigma=1\n",
    "from scipy.stats import norm\n",
    "\n",
    "print (norm.pdf(0))    # value of gaussian for X=0\n",
    "print (norm.cdf(0))    # value of the integral from -inf to 0\n",
    "print (norm.ppf(.01))  # 1% percentile of normal gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Approach\n",
    "Imagine that a portfolio $P$ consists of different amounts $a_i$ invested on various assets. If with $\\Delta x_i$ we denote the daily return of the ith asset the change in the value of the portfolio can be expressed as:\n",
    "\n",
    "$$\\Delta P = \\sum_{i=1}^n a_i \\Delta x_i$$\n",
    "\n",
    "If we then assume that the asset variations are normally distributed with mean 0 (in this approach is typical to assume the expected change in a market variable over the considered period zero), $\\Delta P$ will be normally distributed (as a sum of normal distribution) with zero mean.\n",
    "\n",
    "To estimate the VaR we just need to compute the standard deviation of $\\Delta P$. In the general case with many different assets we define $\\sigma_i$ the daily volatility of the ith asset and with $\\rho_{ij}$ the correlation coefficient between the assets i and j. The variance of $\\Delta P$ can then be expressed as:\n",
    "\n",
    "$$\\begin{align*}\\sigma^2_P & = \\sum_{i=1}^{n}\\sum_{j=1}^{n}\\rho_{ij}a_i a_j \\sigma_i \\sigma_j \\\\\n",
    "& = \\sum_{i=1}^{n} a_i^2 \\sigma_i^2 + 2 \\sum_{i=1}^{n}\\sum_{j<i}^{n}\\rho_{ij}a_i a_j \\sigma_i \\sigma_j \\end{align*}$$\n",
    "\n",
    "As in the previous case if we are interested in a longer time horizon we can use the previous relationship between 1-day VaR and N-day VaR.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation to Standard Normal\n",
    "Values of the Standard Normal Gaussian ($Z = \\mathcal{N}(0,1)$) percentiles are tabeled everywhere and from them it is possible to derive the values relative to any other gaussian distributions.\n",
    "\n",
    "![](norm_gauss_percentile.png)\n",
    "\n",
    "Given a generic gaussian $\\mathcal{N}(\\mu , \\sigma)$, we can go back to the standard gaussian as:\n",
    "\n",
    "$$Z= \\frac{X-\\mu}{\\sigma}$$\n",
    "\n",
    "and from the table above get the correct percentile.\n",
    "\n",
    "Assume you need to know the percentage of a generic gaussian $\\mathcal{N}(\\mu=20 ,\\sigma=5)$ above $X=30$:\n",
    "\n",
    "$$Z=\\frac{X-\\mu}{\\sigma} = \\frac{30-20}{5}=2$$\n",
    "\n",
    "So we just need to check on the table above the percentage related to $Z=2$ which is 2.28% (look at row -2.00, colum .00). Thus, 2.28% of the population with a normal distribution $\\mathcal{N}(\\mu=20 ,\\sigma=5)$ lies above $X=30$:\n",
    "\n",
    "$$P(X>30)=P(Z>2)=0.0228$$\n",
    "\n",
    "Conversely if you need to know the 1% percentile of a generic gaussian $\\mathcal{N}(\\mu=20 ,\\sigma=5)$, first look for .01 in the table above and check the corresponding $Z$ value (-3.1).\n",
    "Finally inverting the above formula get the right value of the percentile:\n",
    "\n",
    "$$ X= \\sigma Z + \\mu = 5\\cdot -3.1 + 20 = 4.5 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Simulation\n",
    "A very useful alternative to the previous approaches is using a Monte Carlo simulation to generate the probability distribution for the $\\Delta P$ distribution. Imagine we need to compute the 1-day VaR for a portfolio, the following steps need to be implemented:\n",
    "\n",
    "* determine today's value of the portfolio;\n",
    "* simulate the evolution of all the portfolio market variables in one day;\n",
    "* recompute the value of the portfolio using the simulated market variables;\n",
    "* compute the $\\Delta P$ value as the simulated minus today's value of the portfolio;\n",
    "* repeat from the second step on as many times as needed to build the probability distribution for $\\Delta P$.\n",
    "\n",
    "VaR is finally estimated as the appropriate percentile of the probability distribution of $\\Delta P$.\n",
    "\n",
    "For examples of Monte Carlo simulations check lesson 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stress Testing and Back Testing\n",
    "In addition to calculating VaR, it can be useful to perform a *stress test*. This essentially implies to estimate how a portfolio would behave under the most extreme market moves seen in the last 20 years.\n",
    "To test those effects from the historical series are taken the market variables seen in a particular day with exceptional large variations. The idea is to take into account extreme events that can occur but that have such low probability that are hard to simulate (e.g. a 5-standard deviation move should happen once every 7000 years but in practice can be observed twice over 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to compute how likely is a n-sigma event ? \n",
    "# (assuming gaussian dist.)\n",
    "# the probability is the integral of the distribution\n",
    "# from -inf to n-sigma\n",
    "\n",
    "from scipy.stats import norm\n",
    "prob = norm.cdf(-5) * 2 # since I'm fine with +- 5sigma movements\n",
    "nyears = (1/prob) / 252 # number of days for 1 event / working days \n",
    "print (\"Expect one 5-sigma event every {:.0f} years\".format(nyears))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important check to be done is the so-called *back testing* which consists of checking how well the VaR estimate would have performed in the past. Basically it has to be tested how often the daily loss exceeded the N-days X% VaR just computed. If it happens on about (100-X)% of the times we can be confident that our estimate is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Ratings\n",
    "A credit rating is a quantified assessment of the creditworthiness of a borrower either in general terms or with respect to a particular debt or financial obligation. A credit rating can be assigned to any entity that seeks to borrow money (e.g. an individual, corporation, state or provincial authority, or sovereign government).\n",
    "\n",
    "A loan is a essentially a promise and the credit rating determines the likelihood that the borrower will be able to pay back it within the loan agreement terms. \n",
    "A high credit rating indicates a high possibility of paying back the loan in its entirety without any issues; a poor credit rating suggests that the borrower has had trouble paying back loans in the past and might follow the same pattern in the future. \n",
    "\n",
    "Individual credit is scored from credit bureaus (e.g. Experian and TransUnion) and it is reported as a number, generally ranging from 300 to 850. \n",
    "\n",
    "Credit assessment and evaluation for companies and governments instead is generally done by  credit rating agencies (e.g. Standard & Poor’s (S&P), Moody’s, or Fitch), which typically assign letter grades to indicate ratings. Standard & Poor’s, for instance, has a credit rating scale ranging from AAA (excellent) to C and D. A debt instrument with a rating below BB is considered to be a speculative grade or a junk bond, which means it is more likely to default on loans.\n",
    "\n",
    "### Why Credit Ratings Are Important\n",
    "A borrowing entity will strive to have the highest possible credit rating since it has a major impact on interest rates charged by lenders. Rating agencies, on the other hand, must take a balanced and objective view of the borrower’s financial situation and capacity to service/repay the debt.\n",
    "\n",
    "A credit rating not only determines whether or not a borrower will be approved for a loan but also determines the interest rate at which the loan will need to be repaid. Since companies depend on loans for many start-up and other expenses, being denied a loan could spell disaster, in any case a high interest rate is much more difficult to pay back. Credit ratings also play a large role in a potential investor's determining whether or not to purchase bonds. A poor credit rating is a risky investment; it indicates a larger probability that the company will be unable to make its bond payments.\n",
    "\n",
    "It is important for a borrower to remain diligent in maintaining a high credit rating. Credit ratings are never static; in fact, they change all the time based on the newest data, and one negative debt will bring down even the best score. Credit also takes time to build up. An entity with good credit but a short credit history is not seen as positively as another entity with the same quality of credit but a longer history. Debtors want to know a borrower can maintain good credit consistently over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Probability\n",
    "\n",
    "The **non-default probability** (**NDP**) is the probability that an issuer will not suffer a credit event (e.g. default) before a given value date. \n",
    "The **default probability** can be obtained as follows:\n",
    "\n",
    "$$\\mathbb{P}[ \\tau \\geq d' ] = 1 - \\mathbb{P}[ \\tau \\lt d' ] = N(d')$$\n",
    "\n",
    "where $\\tau$ is the default date. \n",
    "\n",
    "Hence if you have to compute the default probability for a given time interval this can be expressed as follows:\n",
    "\n",
    "$$\\mathbb{P}[ \\tau \\geq d' ] - \\mathbb{P}[ \\tau \\geq d' + \\Delta t ] = N(d') - N(d' + \\Delta t) $$\n",
    "\n",
    "![](timeline.png)\n",
    "\n",
    "(do you remember CDS ?).\n",
    "Finally the **hazard rate**, often called a *conditional failure rate*, refers to the rate of default of an item at a given age. In other words, it is the likelihood that if something survives to one moment, it will also survive to the next. The hazard rate $\\lambda$measures the propensity of an item to fail or die depending on the age it has reached and can expressed as:\n",
    "\n",
    "$$\\lambda = -\\frac{dN}{dt}\\frac{1}{N(t_0, t_1)}$$\n",
    "\n",
    "Conversly given the hazard rate the non-default probability can be determined as:\n",
    "\n",
    "$$\\lambda = -\\frac{1}{dt}\\cdot\\frac{dN}{N} = -\\frac{d(\\textrm{log}N)}{dt}$$\n",
    "\n",
    "$$N(t_0, t) = e^{-\\int_{t_0}^{t}\\lambda dt}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonds\n",
    "\n",
    "A bond is an instrument that represents a loan made by an investor to a borrower (typically corporate or governmental). Bonds are used by companies, municipalities, states, and sovereign governments to finance projects and operations. Owners of bonds are debtholders, or creditors, of the issuer. Bond details include the end date when the principal of the loan is due to be paid to the bond owner and usually includes the terms for variable or fixed interest payments made by the borrower.\n",
    "\n",
    "The coupon is the interest rate that the issuer pays to the holder. Usually this rate is fixed throughout the life of the bond. It can also vary with a money market index, such as LIBOR, or it can be even more exotic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing\n",
    "\n",
    "The price of a bond can be computed as the present discounted value of future cash flows generated by the bond itself. \n",
    "\n",
    "For example consider a 3-years bond with a face value of 100 EUR providing coupons at a 6% rate annualy. Assume also that the interest rates are 5.0% 5.8% 6.4% and 6.8% for 1, 2, 3, 4 year maturities. To compute the present value of the first copuon we need to discount it at 5.0% for 1 year, for the second the discount has to be at 5.8% and so on. The price will be then:\n",
    "\n",
    "$$6e^{-0.05\\times 1}+6e^{-0.058\\times 2}+106e^{-0.064\\times 3} = 98.53~\\textrm{EUR}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "rates = [0.05, 0.058, 0.064, 0.068]\n",
    "\n",
    "N = 100\n",
    "maturity = 3\n",
    "fixed_coupon = 0.06\n",
    "price = 0\n",
    "for tau in range(1, maturity + 1):\n",
    "    price += N * fixed_coupon * exp(-rates[tau-1] * tau)\n",
    "\n",
    "price += N * exp(-rates[maturity - 1] * maturity)\n",
    "    \n",
    "print (\"{:.2f} EUR\".format(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Probabilities and Bond Prices\n",
    "\n",
    "The price of a bond issued by a party is directly linked to the credit rating of that party, since there is always a default risk associated with a bond, which means that the borrower might not be able to pay the full or partial amount of the loan taken. So, bonds with low ratings, called junk bonds, are sold at lower prices and those with higher ratings, called investment-grade bonds, are sold at higher prices.\n",
    "\n",
    "We can then estimate the probability of a company default directly from the prices of the bonds issued by it. You can imagine that the spread between a corporate bond over the risk-free rate should compensate for the loss in case of default, so naively:\n",
    "\n",
    "$$\\lambda = \\frac{s}{1-R}$$\n",
    "\n",
    "From a different point of view, consider a bond which pays $N=100$ EUR at maturity. Consider also that the issuer has a default probability $DP$ of 20% and in case of default the recovery $R$ is 50% of the face value.\n",
    "\n",
    "**What will be the price of this bond ?**\n",
    "\n",
    "$$\\textrm{P}_{\\textrm{bond}} = \n",
    "\\begin{cases}\n",
    "D\\cdot R \\cdot N & \\text{in case of default of the issuer}\\\\\n",
    "D\\cdot N & \\text{in case of no default} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Since we don't know if the issuer will default or not we can estimate the bond price as:\n",
    "\n",
    "$$ \\textrm{P}_{\\textrm{bond}} = D\\cdot R \\cdot N \\cdot \\mathbb{P}(\\tau) + D\\cdot N \\cdot (1 - \\mathbb{P}(\\tau)) = DN\\cdot ( 1 - (1-R)\\mathbb{P}(\\tau))$$\n",
    "\n",
    "From the last equation is clear that the higher the default probability the lower is the bond price. We have already used this technique when estimating the NPV of the default leg of the CDS and it allows to include default probabilities in the pricing of a contract.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VaR and Default\n",
    "\n",
    "The possibility that the counterparty might default clearly affects also the computation of the VaR. Using the same technique highlighted in the case of the bond price it is possible to modify the distribution of the changes in the portfolio values in order to include the case of default. The rest of the computation remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Valuation Adjustment\n",
    "\n",
    "If you have a portfolio of derivatives with a counterparty and this counterparty defaults before the trades mature, the net mark to market value of the portfolio will be calculated according to the master agreement and a close-out amount will be supposed to be paid by one party to the other.\n",
    "\n",
    "If this portfolio has a positive mark to market value (from your point of view), you won't be able to recover the full amount in the insolvency proceedings, but rather only a part of it (determined by the recovery rate).\n",
    "\n",
    "This means there's a probability that you incur a loss, due to counterparty credit risk. CVA is basically the expected value of this loss, or equivalently the price of hedging this risk in the market. It can be expressed in the following way:\n",
    "\n",
    "$$ \\text{CVA} = (1-R) \\int_0^T D(t) \\cdot EE(t) d\\mathbb{P}(t) $$\n",
    "\n",
    "where $T$ is the latest maturity in the portfolio, $D$ is the discount factor, $EE$ is the expected exposure or $\\mathbb{E}[\\text{max(0, NPV}_\\text{portfolio})]$.\n",
    "\n",
    "For an easier computation it is natural to discretize the above integral and use a time grid going from 0 to the maturity of the portfolio:\n",
    "\n",
    "$$ \\text{CVA} = (1-R) \\sum_i^n D(t_i) \\cdot EE(t_i) \\mathbb{P}(t_{i-1}, t_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 9.1\n",
    "Given the historical series of two stock prices in the file $\\href{https://repl.it/@MatteoSani/support9}{\\textrm{historical_data.py}}$ compute the 5-day 95% VaR for a portfolio consisting of 100 shares of stock 1 and 50 shares of stock 2 (assume that last price of the series is today's price).\n",
    "\n",
    "### Exercise 9.2\n",
    "Imagine a position consisting of 500000 EUR investemnt in FCA shares and a 750000 investiment in Apple shares. Assume that the daily volatilites of the two assets are 2.5% and 0.7% and that their correlation coefficient is 0.4.\n",
    "\n",
    "What is tha 10-day 97.5% VaR for the portfolio ? \n",
    "\n",
    "### Exercise 9.3\n",
    "Find today's price of a 4-years bond which pays semiannual coupons indexed with the LIBOR curve defined in $\\href{https://repl.it/@MatteoSani/support9}{\\textrm{curve_data.py}}$. The face value of the bond is 100000 EUR.\n",
    "\n",
    "### Exercise 9.4\n",
    "Given an arbitrary number of students and some project label write a python program which assigns randomly a project to the students."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
