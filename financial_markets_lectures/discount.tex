\chapter{Interpolation, Discount Factors and Forward Rates}
\label{interpolation}

In this Chapter we will begin to see some \texttt{python} applications to financial calculations, in particular discount curves and forward rates will be involved. In doing so we will review a widely used mathematical tool: \emph{interpolation}.

\section{Discounting}
\label{discount-factors}

%\subsection{Time Value of Money}
%Imagine a bank that offers a guaranteed return of 10\% on whichever amount of money a client put in her account as long as that amount stays in the account for one full year (no withdrawals possible). If the client knows would need \$11000 at the end of one year, how much money does she need to put in today so that the $X$ amount (principal) at the claimed 10\% a year interest rate will grow to the desired amount ?
%
%We know that at 10\% $X$ dollar today grows to
%
%\begin{equation}
%X * (1 + 0.1) = Y
%\end{equation}
%in one year, so the needed investment $X$ can be found by inverting the previous formula:
%
%\begin{equation*}
%X \cdot (1 + 10\%) = 11000 \implies X = \cfrac{11000}{(1 + 10\%)}
%\end{equation*}
%
%\begin{ipython}
%11000 / (1 + 0.1)
%\end{ipython}
%\begin{ioutput}
%10000
%\end{ioutput}
%
%What this says is that to have \$11000 in one year from now, the client needs to invest \$10000.
%What about 11000 dollars in two years from now ? Taking the approach used above
%
%\begin{equation*}
%	X = \cfrac{11000}{\left((1 + 10\%) \cdot (1 + 10\%)\right)} =  \cfrac{11000}{(1+10\%)^ 2}
%\end{equation*}
%
%\begin{ipython}
%11000 / (1 + 0.1)**2
%\end{ipython}
%\begin{ioutput}
%9090.90909090909
%\end{ioutput}
%
%In other words this means the \$11000 we need in two years from now are valued about 9090 dollars today.
%
%What we have just done above is called \emph{discounting}. We are adjusting a future value to bring it to its present value (PV or NPV). The rate used to adjust the future payment is called the \emph{discount rate}.
%
%The idea behind discounting is also known as \emph{time value of money}. Since a dollar will grow in any bank account at that certain rate, if it is invested in an alternative opportunity, it should at least earn that same rate to even consider the alternative worth thinking about. 
%The bottom line is that if you fail to earn the discount rate, you have actually lost money, anything less than that would mean you have not put your money to its best use.
%
%When we calculate the value of future payments today, we are doing a present value calculation. When we calculate the value of anything in the future we do a \emph{future value} calculation.
%
%A positive NPV denotes that at a certain cost of capital the returns or inflows from an investment opportunity outweigh the outflows and vice-versa. Obviously, when comparing various alternatives available for investment, the option with the most positive NPV or least negative NPV will be favoured. 
%
%As an example imagine that you have the chance to invest in a project, that will pay \$100 in year 1, and \$200 in year 2. How much are you willing to pay for this opportunity ? (assume an annual discount rate of 10\%).
%
%The answer is that you will be willing to pay at most an amount that is equal to the present value of this payments stream. To calculate it you need to scale each payment by its respective discount factors ($D(0, T)$ discount factor for year $T$)
%\begin{equation}
%D(0, T) = \cfrac{1}{(1 + r)^T}
%\label{eq:discount_factor}
%\end{equation}
%
%\begin{ipython}
%d1 = 1/(1 + 0.1)**1
%d2 = 1/(1 + 0.1)**2
%
%print ("discount factor for year 1: {:.2f}".format(d1))
%print ("discount factor for year 2: {:.2f}".format(d2))
%
%pv = 100*d1 + 200*d2
%
%print ("Total PV: {:.2f}".format(pv))
%\end{ipython}
%\begin{ioutput}
%discount factor for year 1: 0.91
%discount factor for year 2: 0.83
%Total PV: 256.20
%\end{ioutput}
%\noindent
%Hence, you would be willing to pay \$256.2 for this opportunity.
%
%%If there are $Y$ payments each year the discount factor formula becomes
%%
%%\begin{equation}
%%D(0, T) = \left(1+\cfrac{r}{Y}\right)^{-T}
%%\end{equation}
%%\noindent
%When the continuously-compounded hypothesis is used the discount factor becomes
%
%\begin{equation}
%D(0, T) = e^{-rT}
%\end{equation}

\section{Linear Interpolation}
\label{linear-interpolation}

Consider to have few data points, obtained by sampling or experimenting. These points represent the values of a not well known function $f(x)$, where $x$ is an independent variable (e.g. in recording a trip: distances at certain times, $d = f(t)$).

It may be necessary to estimate values of the function $f$ at particular $x$ for which samples are not available. Interpolation is a method of "constructing" these "new points" within the range of known data.

Let's clarify the technique with an example.
Assume you are going on holidays by car and that luckily there isn't much traffic so that you can drive at constant speed (which gives a linear relation between traveled space and time i.e.~$s = v \cdot t$. This means that if you plot the distances $s$ as a function of the time $t$ you get a line with slope $v$), see Fig.~\ref{fig:samples_for_interpolation}.

\begin{figure}[hb]
  \centering
  \includegraphics[width=0.7\textwidth]{figures/interp_example1.png}
  \caption{Samples of traveled distances at some time (black points). The blue and red crosses show an interpolated and an extrapolated point. It is clear how the extrapolation failed since after 150 minutes the relation between time and space changed.}
  \label{fig:samples_for_interpolation}
\end{figure}

Given two samples of the distance $s_1$ and $s_2$ taken at two different times $t_1$ and $t_2$ you can linearly interpolate to find the distance at an intermediate time using the following relation:

\begin{equation}
s = (1 - w)\cdot s_1 + w \cdot s_2
\end{equation}
where $t$ is the generic time at which we want to know the distance $s$ and $w = \cfrac{t - t_1}{t_2 - t_1}$.

\begin{attention}
\subsubsection{Derivation}
The equation of a line for two points $(t_1, s_1)$ and $(t_2, s_2)$ can be written as:

\begin{equation}
\frac{t - t_1}{t_2 - t_1} = \frac{s - s_1}{s_2 - s_1}
\end{equation}

Setting $w = \cfrac{t - t_1}{t_2 - t_1}$ and solving for $s$ we find the desired solution:

\begin{equation}
(s_2 - s_1)\cdot w = s - s_1\quad\implies\quad s = (1 - w)\cdot s_1 + w \cdot s_2
\end{equation}

This formula can also be understood as a weighted average where the weights are inversely related to the distance from the end points to the unknown point ($w_1 = (1 - w) = \cfrac{t_2 - t}{t_2 -t_1}, w_2 = w$), which means that the closer point has more "influence" than the farther point on the result.
\end{attention}

Back to our example, if
$s_1 = 25.75~\mathrm{km}\;(@t_1 = 15~\mathrm{min})$ and $s_2 = 171.7~\mathrm{km}\;(@t_2 = 100~\mathrm{min})$ let's find the distance traveled in 1 hour:

\begin{ipython}
s_1 = 25.75 # distance in km
t_1 = 15 	# elapsed time in minutes
s_2 = 171.7
t_2 = 100

t = 60
w = (t - t_1)/(t_2 - t_1)
s = (1 - w)*s_1 + w*s_2
print (f"{s:.1f} km")
\end{ipython}
\begin{ioutput}
103.0 km
\end{ioutput}

Instead of reinventing the wheel, \texttt{python} provides a function for interpolation, \texttt{numpy.interp}. 
To repeat our previous example:

\begin{ipython}
import numpy as np
	
t = [15, 100, 150]
s = [25.75, 171.7, 257.7]

np.interp(60, t, s)
\end{ipython}
\begin{ioutput}
103.01764705882351
\end{ioutput}

\emph{Always interpret critically your results to guess if they make sense or not and avoid mistakes}. In the previous example we certainly expected something between 25.75 and 171.7~km (our range ends) furthermore since we are looking for the distance at a time which is almost halfway the considered interval, the result will be somehow in the middle, so around 100~km. This is indeed more or less what we have got. This simple kind of reasoning should be applied every time you have a result to quickly judge it.

\begin{curiosity}
\subsubsection{Epic Failure}
The Mars Climate Orbiter \emph{was} a 638~kg (1,407~lb), 326.7~M\$ space probe launched by NASA on December 11, 1998 to study Martian climate, atmosphere, and surface changes. 

On September 15, 1999, the necessary corrections to speed and direction of the probe were computed in order to place the spacecraft at an optimal position for an orbital insertion maneuver that would bring it around Mars at the proper altitude. 
But one week later communication with the spacecraft was permanently lost as it went into Martian orbital insertion. 

A committee of experts was created to investigate the reasons of 
such failure and they found out that the spacecraft encountered Mars at a lower than foreseen altitude causing either its destruction by atmospheric friction or making it bouncing against the atmosphere re-entering heliocentric orbit after leaving Mars.

The primary cause of this discrepancy was found in one piece of software (supplied by Lockheed Martin) that produced results in "Imperial" units,  while a second system (supplied by NASA) expected those results to be in SI units. Specifically, the software calculated the total impulse produced by thrust in \emph{pound-force seconds}. The trajectory calculation software then used these results, expected to be in \emph{newton seconds}, thus incorrect by a factor of 4.45, to update the predicted position of the spacecraft.
	
NASA took the entire responsibility for having vaporized about 300~M\$ in the Martian atmosphere, mainly for failing to make the appropriate checks and tests that would have caught this unit discrepancy~\cite{bib:mars}.	
\end{curiosity}

\subsubsection{Extrapolation}

If we believe the relation between our variables stays the same ($f(t)$ still linear), we can use the same formula to \emph{extrapolate} values \emph{outside} the range of the sample. For example if we keep the same constant velocity in our trip we could check the distance traveled after 3 hours:

\begin{ipython}
t = 180
w = (t - t_1)/(t_2 - t_1)
s = (1 - w)*s_1 + w*s_2
print (f"{s:.1f} km")
\end{ipython}
\begin{ioutput}
309.1 km
\end{ioutput}

In the given example the extrapolation failed since after minute 150 the traveled space ceased to be a linear function of time.

Notice that \texttt{numpy.interp} has \textbf{not} been designed for extrapolation, so if you ask for a value outside the range of sampled data it returns the closer existing point (the interval ends)

\begin{ipython}
import numpy as np
	
t = [15, 100, 150]
s = [25.75, 171.7, 257.7]
	
np.interp(180, t, s)
\end{ipython}
\begin{ioutput}
257.7
\end{ioutput}

Pay attention to this aspect, for example by adding checks on the interpolation parameters, since the program works fine but could lead to weird results.

\subsection{Log-linear Interpolation}
\label{log-linear-interpolation}
When the function $f$ that we want to interpolate is an exponential we can fall back to the previous case by a simple variable transformation. 
Assume the following relationship between $p$ and $h$:

\begin{equation}
p = \mathrm{exp}(c \cdot h)
\end{equation}
Applying the logarithm to both sides of the equation gives:

\begin{equation}
s = \mathrm{log}(p) = \mathrm{log}(\mathrm{exp}(c \cdot h)) = c \cdot h
\end{equation}
so there is linear relation between the new variable $s$ and $h$. At this point we can use the results of the previous Section to interpolate for values of $s$, just remember to exponentiate the final result to get the correct $p$. In formulas:

\begin{align}
\label{eq:log_interp}
\begin{gathered}
w = \frac{h - h_1}{h_2 - h_1} \\
s = (1 - w)\cdot s_1 + w \cdot s_2\qquad (\textrm{now } s = \textrm{log}(p))\\
p = \textrm{exp}(s)
\end{gathered}
\end{align}

Let's see an example. Atmospheric pressure decreases with the altitude (i.e. the highest you flight the lower is the pressure) following an exponential law:

\begin{equation}
p = p_0\cdot e^{-\alpha h}
\end{equation}
where
\begin{itemize}
\tightlist
\item $h$ is the altitude
\item $p_0$ is the pressure at sea level
\item $\alpha$ is a constant
\end{itemize}

Taking the logarithm of each side of the equation we get a linear relation which can be interpolated as seen before:

\begin{equation}
s = \mathrm{log}(p) = \mathrm{log}(p_0\cdot e^{-\alpha h})\propto - \alpha \cdot h
\end{equation}

Now assume that we have measured
$p_1 = 90~\mathrm{kPa}\;(h_1 = 1000~\mathrm{m})$ and $p_2 = 40~\mathrm{kPa}\;(h_1 = 7000~\mathrm{m})$ what will be the atmospheric pressure on top of Mont Blanc ($4812~\mathrm{m}$) ? and on top of Mount Everest ($8848~\mathrm{m}$) ?

\begin{ipython}
# pressure on top of the Mont Blanc (interpolation)
from math import log, exp
import numpy as np

# first we take the logarithm of our measurements to use the linear
# relation to interpolate
h = [1000, 7000] # height in meters
s = [log(p) for p in [90, 40]] # logarithm of the pressure

s = np.interp(4812, h, s)
print (f"{exp(s):.1f} kPa")
\end{ipython}
\begin{ioutput}
53.8 kPa
\end{ioutput}

If you want to extrapolate you need to use the homemade version of the interpolation algorithm
\begin{ipython}
h = 8848
h_1 = 1000
h_2 = 7000
s_1 = log(90)
s_2 = log(40)
w = (h - h_1)/(h_2 - h_1)
s = (1 - w)*s_1 + w*s_2

print (f"{exp(s):.1f} kPa")
\end{ipython}
\begin{ioutput}
31.2 kPa
\end{ioutput}

In this case we check our results by plotting the found pressures on top of the Wikipedia plot, see Fig~\ref{fig:Pvsh}.

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{figures/Atmospheric_Pressure_vs._Altitude.png}
\caption{Atmospheric pressure versus altitude (Wikipedia). Green points represent our measurements, red points represent interpolation/extrapolation.}
\label{fig:Pvsh}
\end{figure}

\subsection{Limitations of Interpolation}
Interpolation is just an approximation and works well when either the function $f$ is linear or we are trying to interpolate between two points that are close enough to believe that $f$ is almost linear in that interval.

It can be easily demonstrated that the linear approximation between two points of a given function $f(x)$ gets worse with the second derivative of the function that is approximated ($f''(x)$). This is intuitively correct: the "curvier" the function is, the worse the approximation made with simple linear interpolation becomes, see Fig.~\ref{fig:sine_interp} where we try to interpolate a sine function.

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{figures/wrong_interp.png}
  \caption{Trying to approximate a sine function with a line is clearly not going to work unless the interpolation interval is very small.}
  \label{fig:sine_interp}
\end{figure}

To improve the approximation accuracy with complicated curves, an higher order polynomial can be used ($p(x)=a_0 + a_1\cdot x + a_2\cdot x^2+\cdots$), for example in the evaluation of natural logarithm or trigonometric functions. It has to be clear however that going to higher degrees does not always help~\cite{bib:runge}.

\section{Discount Curve Interpolation}
\label{discount-curve-interpolation}
With $D(T)$ (or $D(0,T)$) it is represented the discount factor corresponding to a spot rate $r$, and a time to cash flow $T$ (in years).

Discount factors are usually presented as curves (\emph{discount curves}) where each point represents a discount factor relative to a future date. Figure~\ref{fig:example_discount_curve} shows an example of discount curve.

\begin{figure}[htbp]
    \centering
	\includegraphics[width=0.7\linewidth]{figures/discount_curve}
	\caption{Example of discount curve.}
	\label{fig:example_discount_curve}
\end{figure}

Since discount curves are made of a discrete set of discount factors derived at some dates, we may need to find the factor at some different times; this is a typical financial application of interpolation.

\begin{finmarkets}
Since discount factors are an essential part for every financial calculation and we will keep using them everywhere, a \texttt{python} class which manages discount factors and curves is develop, using an object oriented approach.

This class, that we name \texttt{DiscountCurve}, should have as attributes
\begin{itemize}
	\tightlist
    \item an observation date which corresponds to $t=0$;
	\item a list of pillars dates specifying the value dates of the given discount factors, $t_0,...,t_{n-1}$;
	\item a list of given discount factors, $D(t_0),...,D(t_{n-1})$.
\end{itemize}

and at least a method to interpolate discount factors at a generic date. The input argument to this function will be the value date at which we want to interpolate. Since the discount factor can be expressed as an exponential the log-linear interpolation can be used:

\begin{equation}
	\begin{gathered}
		d(t_i)=\mathrm{ln}(D(t_i))\\
		d(t) = (1-w)d(t_i) + wd(t_{i+1});\quad w=\frac{t-t_i}{t_{i+1}-t_i}\\
		D(t) = \mathrm{exp}(d(t))
	\end{gathered}
\end{equation}
where $i$ is such that $t_i \le t \le t_{i+1}$

When dealing with discount factors we need to be careful though. \texttt{numpy.interp} only accepts list of numbers as argument (i.e. it doesn't know how to interpolate them). So we need to convert them before passing the dates to the interpolation function. This transformation will be implemented directly in the class constructor by replacing each date with the number of days from the observation date ($t_0$).
Furthermore we also attempted a simple code optimization: compute the input discount factors logarithm directly in the constructor in order to save some computation time with respect to doing the log at every call of the interpolation method. 
\end{finmarkets}

\begin{ipython}
import numpy as np
from datetime import date

class DiscountCurve:
    def __init__(self, obs_date, pillar_dates, discount_factors):
        self.obs_date = obs_date
        self.pillar_dates = [obs_date] + pillar_dates
        self.discount_factors = np.insert(np.array(discount_factors), 0, 1)
        self.log_discount_factors = [np.log(discount_factor) for discount_factor in self.discount_factors]
        self.pillar_days = [(pillar_date - obs_date).days for pillar_date in self.pillar_dates]
        
    def df(self, d):
        if d < self.obs_date or d > self.pillar_dates[-1]:
            print (f"Cannot extrapolate discount factors (date: {d}).")
            return None
        d_days = (d - self.obs_date).days
        interpolated_log_discount_factor = np.interp(d_days, self.pillar_days, self.log_discount_factors)
        return np.exp(interpolated_log_discount_factor)
\end{ipython}

Using the discount curve data in \href{https://github.com/matteosan1/finance_course/raw/master/input_files/discount_factors_2022-10-05.xlsx}{\texttt{discount\_factors.xlsx}} instantiate the corresponding object and compute a discount factor.

\begin{finmarkets}
The \texttt{finmarkets} module is currently in the test repository of PyPi, the official collection of \texttt{python} modules. 
To install it in your working area just type 

\begin{ioutput}
pip install --index-url https://test.pypi.org/simple finmarkets
\end{ioutput}

(if you want to install it on Colab just prepend an exclamation mark to the previous command). The tool \texttt{pip} will take care of picking up the latest version of the package and of all the dependencies. You can explore the module with \texttt{help} command and in your program just import what you need with

\begin{ipython}
from finmarkets import DiscountCurve
\end{ipython}
\end{finmarkets}

\begin{ipython}
import pandas as pd
from datetime import date
from finmarkets import DiscountCurve
from dateutil.relativedelta import relativedelta

df = pd.read_excel("discount_factors.xlsx")

obs_date = date.today()
pillars = [today + relativedelta(months=i) for i in df['months']]
dfs = df['dfs'].values
dc = DiscountCurve(obs_date, pillars, dfs)
df_date = obs_date + relativedelta(days=195) #6.5 months
df0 = dc.df(df_date)
print (f"discount factor at {df_date}: {df0:.4f}")
\end{ipython}
\begin{ioutput}
discount factor at 2023-04-21: 0.9902
\end{ioutput}

A very useful way to check the correctness of a result is by plotting it. So let's see what the discount factor and the discount curve look like, Fig.~\ref{fig:linear_discount_curve}.

\begin{ipython}
from matplotlib import pyplot as plt

plt.plot(pillars[:10], dfs[:10], marker='o', markersize=10, 
         label="discount factors")
plt.scatter(df_date, df0, marker='X', s=100, color='red', 
            label='interp. discount factor')
plt.xticks(rotation=45)
plt.grid(True)
plt.legend()
plt.show()
\end{ipython}

%\begin{figure}[htb]
%	\centering
%	\includegraphics[width=0.7\textwidth]{figures/log_discount_curve}
%	\caption{Plot of the discount curve defined in the text and of the two computed discount factors with semi-log scale.}
%	\label{fig:log_discount_curve}
%\end{figure}
%\noindent
%Let's see what it looks like when plotted on a linear graph too, Fig.~\ref{fig:linear_discount_curve}.
%\begin{ipython}
%plt.plot(pillar_dates, discount_factors, marker='o')
%plt.plot(d0, df0, marker='X')
%plt.plot(d1, df1, marker='X')
%plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))
%plt.gca().xaxis.set_major_locator(mdates.YearLocator())
%plt.grid(True)
%plt.show()
%\end{ipython}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/linear_discount_curve}
	\caption{Plot of the discount curve defined in the text and of the discount factor with linear scale.}
	\label{fig:linear_discount_curve}
\end{figure}

\section{Forward Rates}
\label{calculating-forward-rates}
A forward rate is an interest rate applicable to a financial transaction that will take place in the future. It can be considered as the market's expectation for future prices and can serve as an indicator of how it believes will perform.

Contrary the \emph{spot rate} is used by buyers and sellers looking to make an immediate purchase or sale, and it cannot be an indicator of market expectations.

Forward rates are calculated from the spot rate by exploiting the no arbitrage condition which states that investing at rate $r_1$ for the period $(0, T_1)$ and then \emph{re-investing} at rate $r_{1,2}$ for the time period $(T_1, T_2)$ is equivalent to invest at rate $r_2$ for the full time period $(0, T_2)$. Essentially two investors shouldn't be able to earn money from arbitraging between different interest periods. That said:

\begin{equation}
(1+r_1 T_1)[1+r_{1,2}(T_2 - T_1)] = 1 + r_2 T_2
\label{eq:no_arbitrage_r}
\end{equation}
Solving for $r_{1,2}$ leads to

\begin{equation}
F(T_1, T_2) = r_{1,2} = \frac{1}{T_2 - T_1}\Big(\frac{1+r_2 T_2}{1+r_1 T_1} - 1 \Big)
\label{eq:forward_rate_simple}
\end{equation}
\vspace{1cm}
The same expression in terms of the discount factor of Eq.~\ref{eq:discount_factor} becomes
\begin{equation}
F(T_1, T_2) = \frac{1}{T_2 - T_1}\Big(\frac{D(0, T_1)}{D(0, T_2)} - 1 \Big)
\end{equation}
Considering continuously compounded rates instead Eq.~\ref{eq:no_arbitrage_r} can be written as
\begin{equation}
\begin{gathered}
e^{r_{2}T_{2}}=e^{r_{1}T_{1}}\cdot \ e^{r_{1,2} (T_{2}-T_{1})} \\
\textrm{log}\left(e^{r_{2}T_{2}}\right)=\textrm{log}\left(e^{r_{1}T_{1}+ r_{1,2} (T_{2}-T_{1})}\right) \\
r_{2}T_{2}=r_{1}T_{1}+r_{1,2}(T_{2}-T_{1})\implies r_{1,2} = \cfrac{r_2 T_2 - r_1 T_1}{T_2 - T_1} 
\end{gathered}
\end{equation}
and the corresponding expression for the forward rate is
\begin{equation}
F(T_1, T_2) = r_{1,2} = \frac {1}{T_{2}-T_{1}}(\ln D(0,T_{1})-\ln D(0,T_{2}))
\quad(\textrm{since now } D(0, T_i)=e^{-r_i T_i})
\label{eq:forward_rate_continous}
\end{equation}

\begin{finmarkets}
The \texttt{ForwardRateCurve} class of the \texttt{finmarkets} module computes forward rates at any arbitrary date, given a set of spot rates. This class is quite similar to \texttt{DiscountCurve}, it has two methods: one to interpolate spot rates, another to actually compute the forward rates.

In order to successfully interpolate the rates, dates need to be converted to numbers by evaluating the number of days since a reference date (the observation date in this implementation). Also the interpolation date is checked to avoid extrapolations, if it is outside the known range a warning will be printed out and the calculation stopped.
\end{finmarkets}

\begin{ipython}
import numpy as np

class ForwardRateCurve:
    def __init__(self, obs_date, pillars, rates):
        self.obs_date = obs_date
        self.pillars = pillars
        self.pillar_days = [(p - obs_date).days/365 for p in pillars]
        self.rates = rates

    def interp_rate(self, d):
        d_frac = (d - self.obs_date).days/365
        if d < self.obs_date or d_frac > self.pillar_days[-1]:
            print (f"Cannot extrapolate rates (date: {d}).")
            return None, None
        else:
            return d_frac, np.interp(d_frac, self.pillar_days, self.rates)

    def forward_rate(self, d1, d2):
        d1_frac, r1 = self.interp_rate(d1)
        d2_frac, r2 = self.interp_rate(d2)
        if d1_frac is None or d2_frac is None:
            return None
        else:
            return (r2*d2_frac - r1*d1_frac)/(d2_frac - d1_frac)
\end{ipython}

As an example let's compute a forward rate.
\begin{ipython}
from datetime import date
from dateutil.relativedelta import relativedelta

obs_date = data.today()

pillar_dates = [obs_date,
                obs_date + relativedelta(months=12),
                obs_date + relativedelta(months=30)]
rates = [0.0221, 0.0241, 0.025]

fc = ForwardRateCurve(obs_date, pillar_dates, rates)
t1 = obs_date + relativedelta(months=12)
t2 = obs_date + relativedelta(months=24)
print (f"F({t1}, {t2}) = {fc.forward_rate(t1, t2):.4f}")
\end{ipython}
\begin{ioutput}
F(2021-01-01, 2022-01-01) = 0.0253
\end{ioutput}

\section{Multi-curve Framework}
\label{sec:financial-crisis}

% aggiungere un pezzettino dell'articolo di Mercurio

Prior to the 2008 financial crisis, inter-bank deposits posed little credit/liquidity issues, inter-bank lending rates (e.g. LIBOR, EURIBOR) were essentially a good proxy for risk free rates. Basis swap spreads were negligible and thereby neglected. 

Looking at the historical series of the EURIBOR (6M) rate versus the EONIA Overnight Indexed Swap (OIS-6M) rate over the time interval 2006-2011 in Fig.~\ref{fig:credit_crunch} it becomes apparent how before August 2007 the two rates display strictly overlapping trends differing of no more than 6 bps.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.9\linewidth]{figures/credit_crunch.png}
	\caption{Historical series of EURIBOR 6M rate versus EONIA OIS 6M rate. The corresponding spread 
		is shown on the right axis (Jan. 06 - Dec. 10 window, source: Bloomberg).}
	\label{fig:credit_crunch}
\end{figure}

A single yield curve constructed out of selected deposit, FRA and swap rates, served both the cash flow projection and discounting purposes.

During the 2008 financial crisis, the failure of some banks however proved that inter-bank lending rates were not risk-free. Meanwhile there was also significant counter-party credit risk arising from derivative transactions that were not subjected to collateral. Basis swap spreads greatly widened, and persist to this day. 

Still looking at Fig.~\ref{fig:credit_crunch} it is clear how in August 2007 a sudden increase of the EURIBOR rate and a simultaneous decrease of the OIS rate led to the explosion of the corresponding basis spread, touching the peak of 222 bps in October 2008, when Lehman Brothers filed for bankruptcy. Successively the basis has sensibly reduced and stabilized between 40 and 60 bps (notice that the pre-crisis level has never been recovered). The same effect is observed for other similar couples of series, e.g. EURIBOR 3M vs OIS 3M.

The existence of such significant basis swap spread reflects the fact that after the crisis interest rate market has been segmented into subareas corresponding to instruments with different underlying rate tenors, characterized by different rate dynamics. 

Traditional single curve based pricing approach ignores these differences. It mixes different underlying rate tenors and incorporates different rate dynamics, eventually leading to inconsistency.
%After the crisis, the market practice has thus evolved to take into account the new market information (e.g. the basis swap spreads, collateralization, etc.), that translate into the additional requirement of homogeneity and funding. The homogeneity requirement means that interest rate derivatives with a given underlying rate tenor must be priced and hedged using vanilla interest rate market instruments with the same underlying. The funding requirement means that the discount rate of any cash flow generated by the derivative must be consistent, by no-arbitrage, with the funding rate associated with that cash flow. 

Driven by the crisis, many derivative contracts have been updated to include permissible credit mitigants for a transaction, such as netting and collateralization in cash. Since standard agreements stipulate daily margination on collateral and the cash collateral earns a return at overnight rate, overnight rate becomes a natural choice for the risk-free discount rate or the funding rate. This is referred to as \emph{OIS discounting}.

Due to the large spread between risk free rate and inter-bank lending rate during and after 2008 financial crisis it is not possible anymore to use a single curve for discounting and derivative valuation. The traditional single curve used for both cash flow projection and discounting turned out to be obsolete. The markets have since nearly switched to \emph{multi-curve framework}. 

For example, if we want to calculate the net present value (NPV) of a forward 6-month EURIBOR coupon, we need to simultaneously use two different discount curves: 

\begin{itemize}
\tightlist
\item the 6-month EURIBOR curve for determining the forward rate;
\item the \euro STR curve for discounting the expected cash flow.
\end{itemize}

%The reason of the abrupt divergence between the Euribor and OIS rates can be explained by considering both the monetary policy decisions adopted by international authorities in response to the financial turmoil, and the impact of the credit crunch on both credit and liquidity risk perception of the market, coupled with the different financial meaning and dynamics of these rates.

%\begin{itemize}
%\tightlist
%\item
%  The Euribor rate is the reference rate for over-the-counter (OTC)
%  transactions in the Euro area. It is defined as the rate at which
%  Euro inter-bank deposits are being offered within the EMU zone by one
%  prime bank to another at 11:00 a.m. Brussels time. The rate fixings
%  for a strip of 15 maturities (from one day to one year) are
%  constructed as the average of the rates submitted (excluding the
%  highest and lowest 15\% tails) by a panel of 42 banks, selected
%  among the EU banks with the highest volume of business in the Euro
%  zone money markets, plus some large international bank from non-EU
%  countries with important euro zone operations. \emph{Thus, Euribor
%  rates reflect the average cost of funding of banks in the inter bank
%  market at each given maturity. During the crisis the solvency and
%  solidity of the whole financial sector was brought into question and
%  the credit and liquidity risk and uremia associated to inter-bank
%  counter-parties sharply increased.} The Euribor rates immediately
%  reflected these dynamics and raise to their highest values over more
%  than 10 years. As seen in the plot above, the Euribor 6M rate suddenly
%  increased on August 2007 and reached 5.49\% on 10th October 2008.
%\item
%  The EONIA rate is the reference rate for overnight OTC transactions in
%  the Euro area. It is constructed as the average rate of the overnight
%  transactions (one day maturity deposits) executed during a given
%  business day by a panel of banks on the inter-bank money market,
%  weighted with the corresponding transaction volumes. \emph{The EONIA
%  Contribution Panel coincides with the Euribor Contribution Panel, thus
%  EONIA rate includes information on the short term (overnight)
%  liquidity expectations of banks in the Euro money market. It is also
%  used by the European Central Bank (ECB) as a method of effecting and
%  observing the transmission of its monetary policy actions. During the
%  crisis the central banks were mainly concerned about stabilizing the
%  level of liquidity in the market, thus they reduced the level of the
%  official rates.} Furthermore, the daily tenor of the EONIA rate makes
%  negligible the credit and liquidity risks reflected on it: for this
%  reason the OIS rates are considered the best proxies available in the
%  market for the risk-free rate.
%\end{itemize}

%Our financial library has to implement the following calculation
%
%\[\mathrm{NPV} = D_{\mathrm{EONIA}}(T_1) \cdot \frac{1}{T_2-T_1}\Big(\frac{D_{\mathrm{LIBOR}}(T_1)}{D_{\mathrm{LIBOR}}(T_2)} - 1 \Big)\]
%\noindent
%In order to do so we can extend the \texttt{DiscountCurve} class with a \texttt{forward\_rate} method
%
%\begin{ipython}
%class DiscountCurve:
%    ...
%    def forward_rate(self, d1, d2):
%        return (self.df(d1) / self.df(d2) - 1.0) * \
%            (365.0 / ((d2 - d1).days))
%\end{ipython}

As an example let's define \euro STR and EURIBOR curves and compute the net present value of the forward 6-month EURIBOR coupon mentioned before.

\begin{ipython}
from dateutil.relativedelta import relativedelta
from datetime import date

obs_date = date.today()
t1 = obs_date + relativedelta(months=3)
t2 = obs_date + relativedelta(months=9)
pillar_dates_estr = [obs_date, 
                     obs_date + relativedelta(months=12),
                     obs_date + relativedelta(months=34)]
estr_rates = [1.0, 0.97, 0.72]
pillar_dates_euribor = [obs_date, 
                        obs_date + relativedelta(months=5), 
                        obs_date + relativedelta(months=12)]
euribor = [0.005, 0.01, 0.015]

estr_curve = DiscountCurve(obs_date, pillar_dates_estr, estr_rates) 
euribor_curve = ForwardRateCurve(obs_date, pillar_dates_euribor, euribor) 

C = estr_curve.df(t1) * euribor_curve.forward_rate(t1, t2)
t1_frac, r1 = euribor_curve.interp_rate(t1)
C_pre2008 = np.exp(-r1*t1_frac) * euribor_curve.forward_rate(t1, t2)

print (f"C post 2008: {C:.5f} EUR")
print (f"C pre 2008: {C_pre2008:.5f} EUR")
\end{ipython}
\begin{ioutput}
C post 2008: 0.01513 EUR
C pre 2008: 0.01522 EUR
\end{ioutput}

%\subsection{Transitioning away from LIBOR~\cite{bib:str}}
%A working group on euro risk-free rates was established to identify and recommend risk free rates that could serve as a basis for an alternative to current benchmarks used in a variety of financial instruments and contracts in the euro area, such as the euro overnight index average (EONIA) and the euro inter-bank offered rate (EURIBOR). 
%
%The group recommended on September 2018 that the euro short-term rate (\euro STR) be used as the risk-free rate for the euro area and is now focused on supporting the market with transitioning.
%The ECB published the \euro STR for the first time on 2nd October 2019, reflecting trading activity on 1st October 2019.
%
%The working group recommends that market participants should gradually replace EONIA with the \euro STR as a reference rate for all products and contracts and make all necessary adjustments for using the \euro STR as their standard benchmark The working group recommends the \euro STR plus a fixed spread of 8.5
%basis points as the EONIA fallback rate for all products and purposes. The working group recommends that market participants should: consider, whenever feasible and appropriate, no longer entering into new contracts referencing EONIA, in particular new contracts maturing after 31 December 2021, as EONIA will cease to exist after that date.
%
%%The working group is also looking at identifying fallbacks for
%%EURIBOR based on the STR. Both backward and forward-looking
%%options are being considered. As part of its work on forward-looking
%%options, in March 2019 the working group recommended a
%%methodology based on (tradable) overnight index swap (OIS) quotes
%%for calculating a STR-based forward-looking term structure and later
%%invited benchmark administrators to express their interest in
%%producing such a term structure.

\section*{Exercises}
\input{discount_ex_text}

\begin{thebibliography}{9}
	%  %\bibitem{survey2019} StackOverflow \emph{The TEXbook}, Addison-Wesley, Reading,Massachusetts, second edition, 1984,
	\bibitem{bib:mars}\href{https://en.wikipedia.org/wiki/Mars_Climate_Orbiter}{\emph{Mars Climate Orbiter}}, Wikipedia [Online]
	\bibitem{bib:runge} \href{https://en.wikipedia.org/wiki/Runge\%27s_phenomenon}{\emph{Runge's phenomenon}}, Wikipedia [Online]
	\bibitem{bib:forward_rate}\href{https://www.investopedia.com/ask/answers/042315/what-difference-between-forward-rate-and-spot-rate.asp}{\emph{Forward Rate vs. Spot Rate: What's the Difference?}}, Investopedia [Online]
	\bibitem{bib:libor} \href{https://www.ig.com/it/glossario-trading/definizione-di-libor}{\emph{LIBOR}} [Online]
	\bibitem{bib:2008crisis} \href{https://www.investopedia.com/articles/economics/09/financial-crisis-review.asp}{\emph{The 2007-2008 Financial Crisis Review}}, Investopedia [Online]
	\bibitem{bib:str}
	B. Guggenheim and A. Schrimpf, 
	\href{https://www.bis.org/publ/work891.htm}{\emph{At the crossroads in the transition away from LIBOR - from overnight to term rates}}, BIS Working Papers No 891, 09 October 2020 [Online]
\end{thebibliography}
