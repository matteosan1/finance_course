{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Transformation\n",
    "\n",
    "Distribution transformation is a very useful tool which will be extensively used with the copula concept that we discuss in the next Section.\n",
    "The technique transforms every random variables from uniform to any distribution and vice versa and is called \\emph{probability integral transform} or (percentile-to-percentile transform). \n",
    "\n",
    "Computationally, this method involves computing the quantile function of the distribution, in other words, computing the cumulative distribution function (CDF) of the distribution (which maps a number in the domain to a probability between 0 and 1) and then inverting that function. We won't go into the details but we will just show few examples of how this can be done in $\\tt{python}$.\n",
    "\n",
    "For example, imagine that $\\mathbb{P}(X)$ is the standard normal distribution with mean zero and standard deviation one. If we want to convert uniformly distributed samples to standard normal we need to apply the inverse of CDF to each sample. Below few examples which exploit $\\tt{scipy.stats}$ which defines many useful statistical distributions.\n",
    "\n",
    "(Remember that the Uniform samples have to be interpreted as cumulative probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unif.\t\tStd. Normal\n",
      "0.5000000\t0.00000000\n",
      "0.9750000\t1.95996398\n",
      "0.9950000\t2.57582930\n",
      "0.9999990\t4.75342431\n"
     ]
    }
   ],
   "source": [
    "# convert uniform distribution values to gaussian\n",
    "from scipy.stats import uniform, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same transformation may be applied directly on the entire sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define uniform transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we apply $\\tt{ppf}$ to transform directly uniform to normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform uniform to normal and plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot them togheter in a 2D plot we can get a sense of what is going on when using the inverse CDF transformation:\n",
    "\n",
    "<img src=\"uniform_to_gauss_2d.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse CDF stretches the outer regions of the uniform to yield a normal distribution. \n",
    "\n",
    "The nice thing of the technique is that it can be used with any arbitrary (univariate) probability distributions, like for example [t-Student](https://en.wikipedia.org/wiki/Student%27s_t-distribution) or [Gumbel](https://en.wikipedia.org/wiki/Gumbel_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat with t-student(4)\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lesson6_files/lesson6_9_0.png\">\n",
    "\n",
    "Clearly to do the opposite transformation from an arbitray distribution to the uniform(0, 1) we can just apply the inverse of the inverse CDF, which is the CDF itself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire chain uniform->gauss->uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lesson6_files/lesson6_11_0.png\">\n",
    "\n",
    "## Copula\n",
    "\n",
    "In probability theory a *copula* $C(U_1, U_2, \\ldots, U_n, \\rho)$ is a multivariate (multidimensional) cumulative distribution function for which the marginal probability distribution (the probability distribution of each dimension) of each variable is uniform on the interval $[0, 1]$ ($U_i \\approx$~Uniform(0,1)). $\\rho$ represent the correlation between each variable. \n",
    "\n",
    "*Sklar's theorem* states that any multivariate joint distribution can be written in terms of univariate marginal distribution functions and a copula which describes the dependence structure between the variables.\n",
    "\n",
    "Copulas are used to describe the dependence between random variables and have been used widely in quantitative finance to model risk.\n",
    "\n",
    "Despite the obscure and daunting definition the concept of copula is quite simple so let's try to clarify it a bit with a practical example.\n",
    "\n",
    "### Example Problem Case\n",
    "Imagine to measure two variables that are correlated. For example, we look at various rivers and for every river we look at its maximum water level, and also count how many months each river caused flooding. \n",
    "\n",
    "For the probability distribution of the maximum level of the river we know that maximums are Gumbel distributed, while the number of flooding can be modelled according to a [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution).\n",
    "\n",
    "Clearly it is pretty reasonable to assume that the maximum level and the number of floodings is going to be correlated, however we don't know how we could model that correlated probability distribution. Above we only specified the distributions for individual variables, irrespective of the other one (i.e. the marginals), in reality we are dealing with the joint distribution of both of these together. \n",
    "\n",
    "And here is where copulas come to our rescue.\n",
    "\n",
    "Copulas essentially allow to decompose a joint probability distribution into their marginals (which by definition have no correlation) and a function which couples (hence the name) them together and thus allows us to specify the correlation separately. The copula is that coupling function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Correlation with Gaussian Copulas\n",
    "We are actually almost done indeed, we saw before how to convert anything uniformly distributed to an arbitrary probability distribution. So that means we need to generate uniformly distributed data with the correlation we want and then transform the marginals into the desired distributions. \n",
    "\n",
    "How do we do that ? \n",
    "\n",
    "* simulate from a multivariarte Gaussian with the specific corrrelation structure (since we know very well how to do it);\n",
    "* transform each Gaussian marginal to uniform;\n",
    "* finally transform the uniforms to whatever we like.\n",
    "\n",
    "So let's sample from a multivariate normal (2D) with a 0.5 correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# throw random numbers from multivariate gaussian and plot it\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use what we have just seen to tranform the marginals to uniform using the $\\tt{cdf}$ function of the normal distribution ($x$ is a 2D vector in this case, but tranformation will be applied separately on each component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with CDF go back to normal for each component to find the copula and plot it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"copula_3d.png\" width=400></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "These plots above is usually how copulas are visualized.\n",
    "\n",
    "Finally we can just transform the marginals again from uniform to what we want (i.e. Gumbel and Beta in our river example): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform uniform to gumbel and beta with ppf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see that it is actually working as expected we should now compare our scatter plot with correlation to the joint distribution of the same marginals without correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show corr vs uncorr\n",
    "# sample from Gumbel\n",
    "\n",
    "# sample from Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the uniform distribution as a common base for our transformations we can easily introduce correlations and flexibly construct complex probability distributions. Clearly this is directly extendeable to higher dimensional distributions as well.\n",
    "\n",
    "### Generate Correlated Distributions\n",
    "Let's now see how copulas can be used to generate numbers from correlated distributions. These are the steps to follow:\n",
    "\n",
    "* generate a random vector $\\mathbf{x}=(x_1, x_2,\\ldots)$ from a multivariate distribution with the desired correlation;\n",
    "* determine the single $U_i(x_i)$ by applying $\\tt{cdf}$ to each $x_i$;\n",
    "* transform again each $U_i(x_i)$ to the desired marginal distributions using $\\tt{ppf}$.\n",
    "\n",
    "Each component of the vector $\\mathbf{x}$ is now transformed as it was drawn from the desired marginals with the appropriate correlation.\n",
    "\n",
    "A practical application concerns the probability of default. Imagine there are three companies (A, B and C) which have a cumulative probability of defaulting within the next two years of 10%.\n",
    "\n",
    "Let’s try to compute the probabilities to have the three of them all defaulting within the next two years in the cases with independent and correlated default probabilities.\n",
    "\n",
    "In the first case (independent probabilities), the odds to get three defaults within two years is the product of the single probabilities, hence:\n",
    "$$\\mathbb{P}_{\\mathrm{uncorr}}= 10\\%\\cdot 10\\%\\cdot 10\\% = 0.1\\%$$\n",
    "\n",
    "We can verify this in $\\tt{python}$ by applying the Monte Carlo algorithm outlined above: generate a random sample from an uncorrelated multivariate normal distribution, then transform each sample\n",
    "( $[ x_A , x_B , x_C ]$ ) into the uniform distribution with the $\\tt{norm.cdf}$ function (i.e. we convert the samples into probabilities) and then count how many times the three of them are lower than 10%. The final probability will be the ratio of the numer of successes by the total trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaults w/o correlation: 0.10%\n"
     ]
    }
   ],
   "source": [
    "# check all to default without correlation\n",
    "from scipy.stats import multivariate_normal, uniform, norm\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we repeat the same Monte Carlo experiment with perfectly correlated default probabilities\n",
    "we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaults w/o correlation: 9.96%\n"
     ]
    }
   ],
   "source": [
    "# check all to default without correlation\n",
    "from scipy.stats import multivariate_normal, uniform, norm\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the result is 10%, like we had only one single company, indeed being perfectly\n",
    "correlated either there is no default or three \"simultaneous\" defaults with 10% probability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
