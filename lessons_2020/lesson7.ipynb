{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collateralized Debt Obligation\n",
    "\n",
    "A Collateralized Debt Obligation (CDO) is a credit derivative where the issuer, typically investment banks, gather risky assets and repackage them into discrete classes (*tranches*) based on the level of credit risk assumed by the investor. These tranches of securities become the final investment product.\n",
    "\n",
    "Tranches are named to reflect their risk profile: senior, mezzanine and subordinated/equity and are delimited by the attachment ($L$) and detachment points ($U$), which represent the percentages of the total principal defining their boundaries. \n",
    "For example, a 5-10% tranche has an attachment point of 5% and a detachment point of 10%. \n",
    "\n",
    "<!----When the accumulated loss of the reference pool is no more than 5% of the total initial notional of the pool, the tranche will not be affected. However, when the loss has exceeded 5%, any further loss will be deducted from the tranche's notional until the detachment point, 10%, is reached.-->\n",
    "\n",
    "Each of these tranches has a different level of seniority relative to the others in the sense that a senior tranche has coupon\n",
    "and principal payment priority over a mezzanine tranche, while a mezzanine tranche has\n",
    "coupon and principal payment priority over an equity tranche. \n",
    "\n",
    "Indeed they receive returns using a set of rules known as *waterfall*. Incomes of the portfolio are first used to provide returns to the most senior tranche, then to the next and so on.\n",
    "So the senior tranches are generally safest because they have the first claim on the collateral, although they'll offer lower coupon rates.\n",
    "\n",
    "It is important to note\n",
    "that a CDO only redistributes the total risk associated with the underlying pool of assets\n",
    "to the priority ordered tranches. It neither reduces nor increases the total risk associated\n",
    "with the pool.\n",
    "\n",
    "There are various kind of CDOs:\n",
    "\n",
    "* in a **Cash CDO** the reference portfolio consists of corporate bonds owned by the CDO issuer. Cash flows from collateral are used to pay principal and interest to investors. If such cash flows prove inadequate, principal and interest is paid to tranches according to their seniority. \n",
    "\n",
    "<img src=\"cdo_structure.png\">\n",
    "\n",
    "* in a **Synthetic CDO** the underlying reference portfolio is no longer a physical portfolio of bonds or loans, instead it is a *fictitious* portfolio consisting of a number of names each with an associated notional amount. The value of a synthetic CDO usually comes from insurance premiums of credit default swaps paid for by investors. The seller assumes the underlying assets will perform while the investor, on the other hand, assumes the underlying assets will default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash CDO Expected Losses\n",
    "\n",
    "Consider a Cash CDO with a maturity of 1 year, made of 125 bonds. Each bond pays a coupon of one unit after 1 year and it has not yet defaulted (the recovery rate $R$ is assumed 0). We are interested in the following three tranches: equity ([0, 3] defaults), mezzanine ([4, 6] defaults) and senior ([7, 9] defaults), (note that now tranches are identified through the number of defaults and not percentages of the principal). \n",
    "\n",
    "<img src=\"ex_cdo_1.png\">\n",
    "\n",
    "We also assume that the probability of default within 1 year are identical for each bond ($Q$) and that the correlation between each pair is also identical and equal to $\\rho$.\n",
    "\n",
    "Under these assumptions we are in the position to use the Gaussian Copula Model and the derivation of the expected losses results quite simple.\n",
    "\n",
    "The probability of having $l$ defaults, conditional to the market parameter $M$ will follow a binomial distribution given by\n",
    "\n",
    "$$p(l|M) = \\binom{N}{l}Q_M^l (1-Q_M)^{N-l}$$\n",
    "\n",
    "where $N$ is the number of bonds in the portfolio and \n",
    "\n",
    "$$Q_M = \\Phi\\left(\\cfrac{\\Phi^{-1}(Q)-\\sqrt{\\rho}M}{\\sqrt{1-\\rho}}\\right)$$\n",
    "where $\\Phi$ is the standard normal CDF and $Q$ the probability of default within 1 year of a single name.\n",
    "\n",
    "From the definition of each tranche with have that the expected losses are\n",
    "\n",
    "* $\\mathbb{E}_{\\textrm{equity loss}}(l, Q_M)=3\\cdot p(l\\ge 3|M) + \\sum_{k=1}^{2}k\\cdot p(l=k|M)$\n",
    "* $\\mathbb{E}_{\\textrm{mezzanine loss}}(l, Q_M)=3\\cdot p(l\\ge 6|M) + \\sum_{k=1}^{2}k\\cdot p(l=k+3|M)$\n",
    "* $\\mathbb{E}_{\\textrm{senior loss}}(l, Q_M)=3\\cdot p(l\\ge 9|M) + \\sum_{k=1}^{2}k\\cdot p(l=k+6|M)$\n",
    "\n",
    "Each probability $\\mathbb{P}$ can be calculated by integrating the above with respect to $M$\n",
    "\n",
    "$$ \\mathbb{E}_{\\mathrm{tranche}} = \\int_{-\\infty}^{\\infty}{\\mathbb{E}_{\\mathrm{tranche}}(l, Q_M) f_M(m)dm} $$\n",
    "\n",
    "Let's see the corresponding $\\tt{python}$ implementation.\n",
    "First we import the necessary modules and define the needed constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom, norm \n",
    "from scipy.integrate import quad \n",
    "import numpy as np\n",
    "\n",
    "N = 125 \n",
    "Q = 0.02\n",
    "C = 1\n",
    "R = 0\n",
    "tranches = [[1,3],[4, 6],[7,9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we define a function $\\tt{p}$ which implements the expected losses for each tranche.\n",
    "The function depends on the parameter $\\tt{M}$, and takes as inputs the correlation $\\tt{rho}$ and the tranche attach-detach limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_factor_model(M, rho, lims):\n",
    "    QM = norm.cdf((norm.ppf(Q)-np.sqrt(rho)*M)/np.sqrt(1-rho))\n",
    "    pN = binom(N, QM)\n",
    "    loss = 3 * (1 - pN.cdf(lims[1]-1))\n",
    "    for i in range(lims[0], lims[1]):\n",
    "        l = i - lims[0] + 1\n",
    "        loss += l * pN.pmf(i)\n",
    "    \n",
    "    return norm.pdf(M)*loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we loop over a range of possible values for the correlation on each tranche to draw the plot of the expected losses vs the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [[], [], []]\n",
    "\n",
    "for i in range(len(tranches)):\n",
    "    for rho in np.arange(0, 1.10, 0.10): \n",
    "        if rho == 1.0:\n",
    "            rho = 0.9999\n",
    "        v = quad(one_factor_model, -np.inf, np.inf, \n",
    "                 args=(rho, tranches[i])) \n",
    "        res[i].append(v[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"losses_vs_rho.png\">\n",
    "\n",
    "Some considerations can be done from these results. First of all, as expected, the equity tranche is the riskier, producing the highest level of loss. The \n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{\\textrm{equity loss}}\\ge \\mathbb{E}_{\\textrm{mezzanine loss}} \\ge \\mathbb{E}_{\\textrm{senior loss}}\n",
    "$$ \n",
    "\n",
    "relation holds only if each tranche has the same notional exposure (in our example 3).\n",
    "\n",
    "Then we can notice that in the equity tranche losses are decreasing in $\\rho$. When the correlation is low indeed the probability to have few defaults is higher than that of many. As the correlation increases, there will be more and more \"simultaneous\" defaults so also other tranches start to suffer losses. In the extreme case of correlation equal to 1 all the tranches are the same (indeed the expected losses curves join together). \n",
    "\n",
    "When considering all the tranches covering the entire number of names, the last tranche (the one with detachment point of 100\\%) is always increasing in $\\rho$. Again this can be explained with the correlated defaults. \n",
    "Also, the total expected losses on the three tranches is independent of $\\rho$. This is not an accident but it is due to the fact that every default scenario is now categorized in one of the plotted tranches while before this was not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic CDO Valuation\n",
    "\n",
    "Imagine a CDO made of $N$ names in the reference portfolio. The total notional of the protfolio is $F$.\n",
    "When the $i^{th}$ name defaults, then the portfolio incurs in a loss of $F/N(1-R)$ (the recovery rate is assumed to be fixed for all entities of the portfolio).\n",
    "\n",
    "The tranche loss function $TL^{L,U}(l)$ for a given time $t$ is a function of the number of defaults $l$ occurred up to that time and is given by\n",
    "\n",
    "$$TL_{t}^{L,U}=\\mathrm{max}(\\mathrm{min}(l/N\\cdot F(1-R), U)-L, 0)$$\n",
    "\n",
    "where $l/N\\cdot F(1-R)$ is the total portfolio loss, if it is greater than $U$ then the tranche loss is $U$. Conversely if it is lower than $L$ there is no loss.\n",
    "\n",
    "So for example suppose $L=3\\%$ and $U=7\\%$ and suppose also that the portfolio loss is $5\\%$. Then the tranche loss is 2\\% of the total portfolio notional (or 50\\% of the tranche notional $=7\\%-3\\%=4\\%$).\n",
    "\n",
    "When an investor *sells protection* on a tranche she is guaranteeing to reimburse any realized losses on the tranche to the *protection buyer*. To better understand this concept it is useful to think of the protection as an *insurance*. \n",
    "\n",
    "In return, the protection seller receives a premium at regular intervals (typically every three months) from the protection buyer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premium Leg\n",
    "As seen above the premium leg represents the payments that are done periodically by the protection buyer to the protection seller.\n",
    "\n",
    "These payments are made at the end of each time interval and are proportional to the **remaining notional** in the tranche (this is an important difference with respect to CDS, where the contract ends as soon as a default occurs).\n",
    "\n",
    "We can then write the NPV of the premium leg as\n",
    "\n",
    "$$\\mathrm{NPV}_{\\mathrm{premium}}^{L,U}=S\\sum^{n}_{i=1}D(d_i)\\cfrac{(d_i - d_{i-1})}{360}\\left(F(U-L)-\\mathbb{E}[TL_{d-1}^{L,U}]\\right)$$\n",
    "where $n$ is the number of payment dates, $D(d_i)$ is the discount factor, $S$ is the annualized premium. The expected value represents the expected notional remaining in the tranche at time \n",
    "$d_{i-1}$.\n",
    "Note that for simplicity we are ignoring that the default may take place at any time between each payment date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Leg\n",
    "The default leg represents the cash flows paid to the protection buyer upon losses occurring in the considered tranche. \n",
    "\n",
    "The NPV of the leg can be expressed as\n",
    "$$\\mathrm{NPV}_{\\mathrm{default}}^{L,U}=\\sum_{i=1}^{n}D(d_i)\\left(\\mathbb{E}[TL_{d_i}^{L,U}]-\\mathbb{E}[TL_{d_{i-1}}^{L,U}]\\right)$$\n",
    "where the argument in parenthesis is the expected losses between time $d_{i-1}$ up to $d_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the key ingredient for the valuation of a CDO is the calculation of $\\mathbb{E}[TL_{d_i}^{L,U}]$ which appears in both legs.\n",
    "Using the Gaussian copula it is relatively easy to compute it. \n",
    "Indeed we know that \n",
    "\n",
    "$$TL_{t}^{L,U}=\\mathrm{max}(\\mathrm{min}(l/N\\cdot F(1-R), U)-L, 0)$$\n",
    "\n",
    "where the only random variable is the number of defaults $l$. We also know that \n",
    "\n",
    "$$\\mathbb{E}[TL_{t}^{L,U}] = \\sum_{l=0}^{N}TL_{t}^{L,U}\\cdot \\int_{-\\infty}^{\\infty} Q(l_{t|M}=j) \\phi(M)dM$$\n",
    "\n",
    "And has we have already seen this calculation can be carried on without too much effort.\n",
    "The large popularity of the Gaussian copula just resides in this, it allows to compute very quickly very complicated contracts like CDOs which usually involve a large number of correlated names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDO Fair Value\n",
    "The *fair value* of a CDO tranche is that value of the premium $S^*$ for which the expected value of the premium leg equals the expected value of the default leg and for what we have seen depends on the expected value of the tranche loss function.\n",
    "\n",
    "$$ S^* = \\cfrac{\\mathrm{NPV_{default}}^{L,U}}{\\sum^{n}_{i=1}D(d_i)\\cfrac{(d_i - d_{i-1})}{360}\\left(F(U-L)-\\mathbb{E}[TL_{d-1}^{L,U}]\\right)}$$\n",
    "\n",
    "This equation defines the CDO fair value, but can also be used to calibrate the implied correlation parameter from the market.\n",
    "This can be obtained by plugging into the equation the market premium value and solve for the correlation parameter $\\rho$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual let's implement a $\\tt{python}$ class to represent CDOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finmarkets import DiscountCurve, CreditCurve, generate_swap_dates\n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import norm, binom\n",
    "import numpy as np\n",
    "from numpy import exp, sqrt\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "class CollDebtObligation:\n",
    "    def __init__(self, notional, names, tranches, rho, cc,\n",
    "                 start_date, spreads,\n",
    "                 maturity, tenor=3, recovery=0.4):\n",
    "        self.notional = notional\n",
    "        self.names = names\n",
    "        self.tranches = tranches\n",
    "        self.payment_dates = generate_swap_dates(start_date, maturity * 12, tenor)\n",
    "        self.spreads = spreads\n",
    "        self.rho = rho\n",
    "        self.recovery = recovery\n",
    "        self.cc = cc\n",
    "\n",
    "    def one_factor_model(self, M, Q, l, L, U):\n",
    "        P = norm.cdf((norm.ppf(Q) - sqrt(self.rho) * M) / (sqrt(1 - self.rho)))\n",
    "        b = binom(self.names, P)\n",
    "        return b.pmf(l) * norm.pdf(M) * max(min(l/self.names * \n",
    "                                                self.notional * \n",
    "                                                (1 - self.recovery), U) - L, 0)\n",
    "        \n",
    "    def expected_tranche_loss(self, d, L, U):\n",
    "        Q = 1 - self.cc.ndp(d)\n",
    "        v = 0\n",
    "        for l in range(self.names+1):\n",
    "            i = quad(self.one_factor_model, -np.inf, np.inf, \n",
    "                     args=(Q, l, L, U))[0]\n",
    "            v += i\n",
    "        return v\n",
    "\n",
    "    def npv_premium(self, tranche, dc):\n",
    "        L = self.tranches[tranche][0] * self.notional\n",
    "        U = self.tranches[tranche][1] * self.notional\n",
    "        v = 0\n",
    "        for i in range(1, len(self.payment_dates)):\n",
    "            ds = self.payment_dates[i - 1]\n",
    "            de = self.payment_dates[i]\n",
    "            D = dc.df(de)\n",
    "            ETL = self.expected_tranche_loss(ds, L, U)\n",
    "            v += D * (de - ds).days / 360 * max((U - L) - ETL, 0)\n",
    "        return v * self.spreads[tranche]\n",
    "\n",
    "    def npv_default(self, tranche, dc):\n",
    "        U = self.tranches[tranche][1] * self.notional\n",
    "        L = self.tranches[tranche][0] * self.notional\n",
    "        v = 0\n",
    "        for i in range(1, len(self.payment_dates)):\n",
    "            ds = self.payment_dates[i - 1]\n",
    "            de = self.payment_dates[i]\n",
    "            ETL1 = self.expected_tranche_loss(ds, L, U)\n",
    "            ETL2 = self.expected_tranche_loss(de, L, U)\n",
    "            v += dc.df(de) * (ETL2 - ETL1)\n",
    "        return v\n",
    "\n",
    "    def npv(self, tranche, dc):\n",
    "        return self.npv_default(tranche, dc) - self.npv_premium(tranche, dc)\n",
    "\n",
    "    def fair_value(self, tranche, dc):\n",
    "        num = self.npv_default(tranche, dc)\n",
    "        den = self.npv_premium(tranche, dc) / self.spreads[tranche]\n",
    "        return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranche 0 ([0.0, 0.03]): 0.15942\n",
      "Tranche 1 ([0.03, 0.06]): 0.02505\n",
      "Tranche 2 ([0.06, 0.09]): 0.00773\n",
      "Tranche 3 ([0.09, 1.0]): 0.00017\n"
     ]
    }
   ],
   "source": [
    "pillar_dates = []\n",
    "df = []\n",
    "observation_date = date.today()\n",
    "\n",
    "for i in range(2):\n",
    "    pillar_dates.append(observation_date + relativedelta(years=i))\n",
    "    df.append(1 / (1 + 0.05) ** i)\n",
    "dc = DiscountCurve(observation_date, pillar_dates, df)\n",
    "\n",
    "cc = CreditCurve([observation_date + relativedelta(years=i) for i in range(5)],\n",
    "                 [1, 0.99, 0.97, 0.95, 0.93])\n",
    "\n",
    "tranches = [[0.0, 0.03], [0.03, 0.06], [0.06, 0.09], [0.09, 1.0]]\n",
    "spreads = [0.15, 0.07, 0.03, 0.01]\n",
    "\n",
    "cdo = CollDebtObligation(100e6, 125, tranches, 0.3, cc,\n",
    "                         observation_date, spreads, 1, 12)\n",
    "for i in range(len(tranches)):\n",
    "    print (\"Tranche {} ({}): {:.5f}\".format(i, tranches[i], cdo.fair_value(i, dc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit VaR\n",
    "\n",
    "Credit VaR is defined in the usual way Value at Risk measures are defined (i.e. as percentile of a loss distribution). \n",
    "\n",
    "In this case we are concerned with the default risk associated to one or multiple counterparties in a specific portfolio, and the loss is defined on the overall exposure to all the counter-parties involved.\n",
    "\n",
    "The exposure $EE$ at the default date $\\tau$ is defined as the sum of the discounted cash flows; the corresponding loss is then given by:\n",
    "$$ L(\\tau, \\hat{T}, T) = (1 − R)\\cdot EE(\\tau)$$\n",
    "where $\\hat{T}$ is the risk horizon and $L$ is non-zero only in scenarios of early default of the counter-party. \n",
    "\n",
    "Given the above definitions we can express the Cr-VaR as the q-quantile of $L(\\tau, \\hat{T}, T)$.\n",
    "In this case the horizon is usually one year and the standard percentile is the 99.9th, so that the returned loss is exceeded only in 1 case out of 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit Var and MC Simulation\n",
    "Credit VaR can be calculated through a simulation of the basic financial variables underlying the portfolio up to the risk horizon. The simulation also includes the default of the counter-parties.\n",
    "\n",
    "At the risk horizon, the portfolio is priced in every simulated scenario of the basic financial variables, including defaults, obtaining a number of scenarios for the portfolio value at the risk horizon.\n",
    "\n",
    "It is then straightforward to derive the Credit VaR from the distribution of the losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from finmarkets import DiscountCurve, CreditCurve, generate_swap_dates\n",
    "from scipy.stats import uniform\n",
    "\n",
    "bonds = 20\n",
    "S = [(1-0.01*i) for i in range(bonds)]\n",
    "N = [100 for _ in range(20)]\n",
    "R = 0.4\n",
    "r = 0.01\n",
    "obs_date = date.today()\n",
    "\n",
    "pillars = [obs_date+relativedelta(years=i) for i in range(2)]\n",
    "dfs = [1/(1+r)**i for i in range(2)]\n",
    "dc = DiscountCurve(obs_date, pillars, dfs)\n",
    "ccs = []\n",
    "for i in range(bonds):\n",
    "    ccs.append(CreditCurve(pillars, [1, S[i]]))\n",
    "\n",
    "scenarios = 100000\n",
    "losses = []\n",
    "for _ in range(scenarios):\n",
    "    loss = 0\n",
    "    unif = uniform.rvs(size=bonds)\n",
    "    for i in range(bonds):\n",
    "        if unif[i] > ccs[i].ndp(pillars[-1]):\n",
    "            loss += (1 - R)*N[i]*dc.df(pillars[-1]) \n",
    "    losses.append(loss)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.hist(losses, bins=70, range=(0, 700))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[415.84158416]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print (np.percentile(losses, [99.9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be now clear that all the consideration done previously on correlated defaults have an impact also here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit VaR and One Factor Copula Model\n",
    "\n",
    "Consider a portfolio made of similar assets. As an approximation assume that the probability of default is the same for each counter-party and that the correlation between each pair is the same and equal to $\\rho$. \n",
    "\n",
    "If we use the One Factor Copula model to describe the default correlations\n",
    "\n",
    "$$ DP=\\Phi\\left(\\cfrac{\\Phi^{-1}[Q(T)]-M\\sqrt{\\rho}}{\\sqrt{1-\\rho}}\\right)$$\n",
    "\n",
    "gives us the percentage of defaults by time $T$ given the parameter $M$. \n",
    "Indeed if you a have $n$ counter-parties with the same default probability $DP(t)$ the **percentage of defaults** at time $t$ is $DP$ itself\n",
    "\n",
    "$$\\textrm{% of defaults} = \\textrm{nDefaults}/n = (n\\cdot DP)/n$$\n",
    "\n",
    "Since $M$ is distributed according to a standard normal we can be $X\\%$ certain that its value will be greater than $\\Phi^{-1}(1−X) = -\\Phi^{-1}(X)$, where the last equality holds due to the symmetry of the Gaussian distribution.\n",
    "\n",
    "<img src=\"certain_for_X.png\">\n",
    "\n",
    "But once $T$ has been fixed the only random variable in $DP$ is $M$, therefore we can say that we are $X\\%$ certain that the percentage of losses over $T$ years on a large portfolio will be less than $V(X, T)$ where\n",
    "\n",
    "$$ V(X, T)=\\Phi\\left(\\cfrac{\\Phi^{-1}[Q(T)]+\\Phi^{-1}(X)\\sqrt{\\rho}}{\\sqrt{1-\\rho}}\\right)$$\n",
    "\n",
    "When $X\\%$ confidence level is used and the time horizon is $T$, a rough estimate of the Credit VaR is therefore $P ( 1 − R ) V ( X, T )$ , where $P$ is the size of the portfolio and $R$ is the recovery rate.\n",
    "\n",
    "Suppose that a bank has a total of €100 million of retail exposures. \n",
    "The 1-year probability of default averages to 2% and the recovery rate averages to 60%. The copula correlation parameter is estimated as 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cr-VaR: 5130000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from math import sqrt\n",
    "\n",
    "X = 0.999\n",
    "rho = 0.1\n",
    "R = 0.6\n",
    "DP = 0.02\n",
    "exposure = 100e6\n",
    "\n",
    "num = norm.ppf(DP) + sqrt(rho)*norm.ppf(X)\n",
    "den = sqrt(1-rho)\n",
    "V = norm.cdf(num/den)\n",
    "cr_var = exposure*V*(1-R)\n",
    "\n",
    "print (\"Cr-VaR: {:.0f}\".format(round(cr_var, -4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CreditMetrics\n",
    "\n",
    "Another popular approach to compute Credti VaR is CreditMetrics. It involves estimating a probability distribution of credit losses by carrying out Monte Carlo simulations of the credit rating changes of all counter-parties.\n",
    "\n",
    "Imagine we would like to determine the probability distribution of losses over 1-year period.\n",
    "On each simulation, the credit rating changes and default of each counter-party is computed.\n",
    "\n",
    "The portfolio value is than computed to determine the eventual losses.\n",
    "\n",
    "<img src=\"pippo\">\n",
    "\n",
    "Clearly credit rate changes cannot be assumed independent, hence a copula approach can be\n",
    "implemented also here. As an example suppose to simulate rating change of a portfolio of 9 bonds with various ratings over 1-year period. The correlation between them is 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126.]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal, norm\n",
    "import numpy\n",
    "\n",
    "# AAA, AA, A, BBB, BB, B, CCC, Def\n",
    "table = [[90.81, 8.33, 0.68, 0.06, 0.08, 0.02, 0.01, 0.01],\n",
    "         [0.70, 90.65, 7.79, 0.64, 0.06, 0.13, 0.02, 0.01],\n",
    "         [0.09, 2.27, 91.05, 5.52, 0.74, 0.26, 0.01, 0.06],\n",
    "         [0.02, 0.33, 5.95, 85.93, 5.30, 1.17, 1.12, 0.18],\n",
    "         [0.03, 0.14, 0.67, 7.73, 80.53, 8.84, 1.00, 1.06],\n",
    "         [0.01, 0.11, 0.24, 0.43, 6.48, 83.46, 4.07, 5.20],\n",
    "         [0.21, 0, 0.22, 1.30, 2.38, 11.24, 64.86, 19.79]]\n",
    "\n",
    "#able_gauss = []\n",
    "#for i in range(len(table)):\n",
    "#    temp = []\n",
    "#    s = 0\n",
    "#    for j in range(8):\n",
    "#        s += table[i][j]/100\n",
    "#        if s>1:\n",
    "#            s = 1\n",
    "#        temp.append(norm.ppf(s))\n",
    "#    table_gauss.append(temp)\n",
    "\n",
    "t = numpy.array(table)\n",
    "table_gauss = norm.ppf(np.cumsum(t/100., axis=1))\n",
    "table_gauss[:, -1] = np.inf\n",
    "\n",
    "N = [100, 95, 92, 85, 80, 70, 60]\n",
    "portfolio = [2, 3, 3, 4, 5, 6, 3, 4, 2]\n",
    "R = 0.4\n",
    "\n",
    "p0 = 0\n",
    "for i in portfolio:\n",
    "    p0 += N[i]\n",
    "\n",
    "numpy.random.seed(1)\n",
    "mvnorm = multivariate_normal(mean=[0 for _ in range(9)],\n",
    "                             cov=[[1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "                                  [0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "                                  [0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "                                  [0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "                                  [0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2, 0.2],\n",
    "                                  [0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2, 0.2],\n",
    "                                  [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2, 0.2],\n",
    "                                  [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1, 0.2],\n",
    "                                  [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1]])\n",
    "\n",
    "trials = 1000000\n",
    "x_prob = mvnorm.rvs(size=trials)\n",
    "\n",
    "dp = []\n",
    "for x in x_prob:\n",
    "    p = 0\n",
    "    for j in range(len(portfolio)):\n",
    "        ip = 0\n",
    "        while x[j] > table_gauss[portfolio[j], ip]:\n",
    "            ip += 1\n",
    "        if ip == 7:\n",
    "            p += N[portfolio[j]]*(1-R)\n",
    "        else:\n",
    "            p += N[ip]\n",
    "\n",
    "    r = max(0, -(p - p0))\n",
    "    if r != 0:\n",
    "        dp.append(r)\n",
    "        \n",
    "crvar = numpy.percentile(dp, [99.9])\n",
    "print (crvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"credit_metrics.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit Valuation Adjustment\n",
    "\n",
    "Suppose you have a portfolio of derivatives with a counter-party. If the counter-party defaults and the present value of the portfolio at default is positive to the surviving party, then the surviving party only gets a recovery fraction of the portfolio value from the defaulted entity. \n",
    "\n",
    "If however the present value is negative to the surviving party, it has to pay it in full to the liquidators of the defaulted entity. This creates and asymmetry that, once one has done all calculations, says that the value of the deal under counter-party risk is the value without counter-party risk minus a positive adjustment, called Credit Valuation Adjustment (CVA).\n",
    "\n",
    "It can be expressed in the following way:\n",
    "\n",
    "$$\\textrm{CVA} = ( 1 − R )\\int^{T}_{0} D(t)\\cdot EE(t) dP(t) $$\n",
    "\n",
    "where $T$ is the latest maturity in the portfolio, $D$ is the discount factor, $EE$ is the expected exposure or $\\mathbb{E}[ \\textrm{max(0, NPV portfolio)}]$. \n",
    "\n",
    "For an easier computation it is natural to discretize the above integral and use a time grid going from 0 to the maturity of the portfolio:\n",
    "\n",
    "$$\\textrm{CVA} = ( 1 − R ) \\sum_i D(t_i)\\cdot EE(t_i) P(t_{i − 1}, t_i)$$\n",
    "\n",
    "Let us say that Credit VaR measures the risk of losses you face due to the possible default of some counter-parties you are having business with. CVA measures the pricing component of this risk, i.e. the adjustment to the price of a product due to this risk.\n",
    "\n",
    "### Debit Valuation Adjustment\n",
    "\n",
    "The adjustment seen from the point of view of our counter-party is positive, and is called Debit Valuation Adjustment, DVA. It is positive because the early default of the client itself would imply a discount on the client payment obligations, and this means a gain in a way. So the client marks a positive adjustment over the risk free price by adding the positive amount called DVA.\n",
    "\n",
    "Basically when both parties have the possibility to default, they consistently include both defaults into the valuation. Hence every party needs to include its own default besides the default of the counter-party into the valuation. So they will mark a positive CVA to be subtracted and a positive DVA to be added to the default risk free price of the deal. The CVA of one party will be the DVA of the other one and viceversa.\n",
    "\n",
    "$$\\textrm{price = default risk free price + DVA - CVA}$$\n",
    "\n",
    "Now, since\n",
    "$$\\textrm{default risk free price(A) = − default risk free price(A)}$$\n",
    "$$\\textrm{DVA(A) = CVA(B)}$$\n",
    "$$\\textrm{DVA(B) = CVA(A)}$$\n",
    "\n",
    "we get that eventually\n",
    "$$\\textrm{price(A) = − price(B)}$$\n",
    "\n",
    "so that both parties agree on the price, or, we could say, there is money conservation.\n",
    "\n",
    "### CVA Computation\n",
    "The computation of the CVA is easily carried on with Monte Carlo simulation. First simulate the development of your derivatives portfolio (its NPV) at each time point for each MC scenario. Then calculate the CVA using Eone of the previous definitions. Finally average the CVA of all the scenarios to get its best estimate.\n",
    "\n",
    "In case of bonds the computation of the CVA can be further simplified. Indeed in this case the exposure of the investor is equal to the notional of the bond, so it is enough to loop through each days from the observation date to the maturity of the bond and compute the CVA. \n",
    "\n",
    "Imagine a 3-years bond with a notional N = €100. The bond provides yearly coupons of 6%.\n",
    "The bond issuer has the following default probabilities 10%, 20% and 30% for 1, 2 and 3 years respectively (the recovery rate is 40%). The risk free rate is 3%.\n",
    "\n",
    "To compute CVA we need to first define a discount curve and the credit curve corresponding\n",
    "to the issuer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVA: 17.23\n"
     ]
    }
   ],
   "source": [
    "###### from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from finmarkets import DiscountCurve, CreditCurve\n",
    "\n",
    "T = 3 \n",
    "C = 0.06\n",
    "r = 0.03\n",
    "R = 0.4\n",
    "N = 100\n",
    "\n",
    "obs_date = date.today()\n",
    "pillars = [obs_date+relativedelta(years=i) for i in range(T+1)]\n",
    "dfs = [1/(1+r)**i for i in range(T+1)]\n",
    "dc = DiscountCurve(obs_date, pillars, dfs)\n",
    "S = [1, 0.9, 0.8, 0.7]\n",
    "cc = CreditCurve(pillars, S)\n",
    "\n",
    "cva = 0\n",
    "d = obs_date\n",
    "while d <= pillars[-1]:\n",
    "    cva += dc.df(d)*(cc.ndp(d) - cc.ndp(d+relativedelta(days=1)))\n",
    "    d += relativedelta(days=1)\n",
    "\n",
    "cva = cva * (1-R) * N\n",
    "print (\"CVA: {:.2f}\".format(cva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bond Price: 91.50\n"
     ]
    }
   ],
   "source": [
    "default_free_price = 0\n",
    "for i in range(1, len(pillars)):\n",
    "    default_free_price += (N * ((pillars[i] - pillars[i-1]).days / 360) * \n",
    "          dc.df(pillars[i]) * C )\n",
    "                    \n",
    "default_free_price += N * dc.df(pillars[-1])\n",
    "             \n",
    "print (\"Bond Price: {:.2f}\".format(default_free_price - cva))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
