{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Correlation between Risks\n",
    "In credit derivative valuation and credit risk management, one of the most important issue is the estimate of default probabilities and their correlations. \n",
    "\n",
    "Default correlation measures the tendency of two companies to default at about the same time. For this, generally speaking, there are two ways: using historical default data or using mathematical models, like copulas. \n",
    "\n",
    "Historical default data has played an important role in the estimation of default probabilities. However, because default events are rare, there is very limited default data available. Moreover, historical data reflects the historical default pattern only and it may not be a proper indicator of the future. This makes the estimation of default probabilities from historical data difficult and inexact. To use this same data to estimate default correlations is even more difficult and more inexact. \n",
    "\n",
    "On the other hand mathematical models don't rely on historical default data. We have already seen how it is possible to derive default probabilities from market data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Copula Model\n",
    "\n",
    "While there are several types of copula function models, the first\n",
    "introduced was the \\emph{one-factor Gaussian copula model}. This model has,\n",
    "above all, the advantage that can be solved semi-analytically.\n",
    "\n",
    "Consider a portfolio of $N$ bonds and assume that the marginal\n",
    "probabilities of default are known for each issuer. Define:\n",
    "\n",
    "* $t_i$, the time of default of the $i^{th}$ company:\n",
    "* $Q_i(t)$, the cumulative probability that company $i$ will default before time $t$; that is, the probability that $t_i \\le t$.\n",
    "\n",
    "To generate a one-factor model for the $t_i$ we define random\n",
    "variables $X_i$ $(1\\le i \\le N)$\n",
    "\n",
    "$$X_i = a_i M + \\sqrt{1-a_i^2}Z_i,\\qquad i = 1, 2,\\ldots, N$$\n",
    "\n",
    "where $M$ and the $Z_i$ are independent zero-mean unit-variance  distributions (hence $X_i$ are also distributed with zero-mean and unit standard-deviation) and $-1 \\le a_i \\lt 1$.\n",
    "\n",
    "The previous equation defines a correlation structure between the\n",
    "$X_i$ which are dependent on a single common factor $M$. The $Z_i$ term is usually \n",
    "called the idiosincratic component of default. \n",
    "The correlation between $X_i$ and $X_j$ is\n",
    "\n",
    "$$\\mathrm{Corr}(X_i, X_j) = \\cfrac{\\mathbb{E}[(X_i-\\mu_i)(X_j-\\mu_j)]}{\\sigma_{X_i}\\sigma_{X_j}} =\\mathbb{E}[X_i X_j] = a_i a_j \\mathbb{E}[M^2] = a_i a_j\n",
    "$$\n",
    "where we just exploit the definition of $X_i$ and its properties.\n",
    "\n",
    "%Assume that the $i^{th}$ company has defaulted by the time $t_i$ if $X_i$ is below a threshold value $\\bar{x}_i(t_i)$.\n",
    "If $F$ is the cumulative distribution function of the $X_i$,\n",
    "with a percentile to percentile transformation we can map the $X_i$ to the $t_i$, so that $Q_i(t_i) = \\mathbb{P}(X_i\\le x)=F(x)$.\n",
    "Therefore the point $X_i = x$ is transformed to $t_i = t$ where\n",
    "$x = F_i^{-1}[Q_i(t)]$.\n",
    "\n",
    "Let's note that, *conditional* on $M$, the $N$ default events are independent. So we can write\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "Q_i(t_i|M) = \\mathbb{P}(X_i\\le x|M) &= \\mathbb{P}(a_i M + \\sqrt{1-a_i^2}Z_i\\le x) =\\\\\n",
    "&= \\mathbb{P}\\left(Z_i\\le \\cfrac{x-a_i M}{\\sqrt{1-a_i^2}}\\right)\n",
    "=H_i\\left(\\cfrac{F^{-1}[Q(t_i)]-a_i M}{\\sqrt{1-a_i^2}}\\right)\n",
    "\\end{split}\n",
    "$$\n",
    "where $H_i$ is the cumulative distribution function of the $Z_i$.\n",
    "\n",
    "Although in principle any distribution could be used for $M$'s and the\n",
    "$Z$'s (provided they have zero mean and unit variance), one common\n",
    "choice is to let them be standard normal distributions (resulting in a\n",
    "Gaussian copula).\n",
    "So we can specialize the previous equation as\n",
    "\n",
    "$$\n",
    "Q_i(t_i|M) = \\Phi\\left(\\cfrac{\\Phi^{-1}[Q(t_i)]-a_i M}{\\sqrt{1-a_i^2}}\\right)\n",
    "$$\n",
    "where $\\Phi$ denotes the cumulative distribution function of the standard normal distribution.\n",
    "\n",
    "If we call $\\mathcal{C}(t_1,\\ldots,t_N)$ the joint distribution of the default times of the $N$ bonds  in the portfolio then\n",
    "\n",
    "$$\n",
    "\\mathcal{C}(t_1,\\ldots,t_N)=\\Phi_{A}(\\Phi^{-1}(Q_1(t_1)),\\ldots,\\Phi^{-1}(Q_N(t_N)))\n",
    "$$\n",
    "where $A$ is the correlation matrix of the default probabilities, is the one factor Gaussian copula model (one factor because there is only a random variable, $M$, which determines the correlation between $X_i$).\n",
    "\n",
    "Clearly different choices of distributions result in different copula models, and in different natures of the default dependence. For example, copulas where the \\(M\\)'s have heavy tails generate models where there is a\n",
    "greater likelihood of a clustering of early defaults for several\n",
    "companies.\n",
    "\n",
    "### Standard Market Model\n",
    "\n",
    "Assume the following two assumptions are made:\n",
    "\n",
    "* all the companies have the same default intensity (hazard rates), i.e, $\\lambda_i = \\lambda$ (which means they all have the same default probabilities);\n",
    "* the pairwise default correlations are the same, i.e $a_i = a$; in other words the contribution of the market \tcomponent $M$ is the same for all the companies and the correlation between any two companies is constant, $\\rho = a^2$.\n",
    "\n",
    "Under these assumptions, given the market situation $M = m$, all the\n",
    "companies have the same cumulative default probability\n",
    "$DP_{t|m}=Q_i(t_i|m)=\\mathbb{P}(X_i < x|m)$. \n",
    "Moreover, for a given value of the\n",
    "market component $M$, the defaults are mutually independent for all\n",
    "the underlying companies. \n",
    "\n",
    "Letting $l_{t|m}$ be the total defaults that\n",
    "have occurred by time $t$ conditional on the market condition\n",
    "$M = m$, then $l_{t|m}$ follows a binomial distribution and\n",
    "\n",
    "$$DP(l_{t|m} = j) = \\cfrac{N!}{j!(N-j)!}DP^j_{t|m}(1-DP_{t|m})^{N-j},\\qquad  j=0, 1, 2,\\ldots,N$$\n",
    "\n",
    "The probability that there will be exactly $j$ defaults by time $t$\n",
    "is\n",
    "$$\n",
    "DP(l_{t} = j) = \\int_{-\\infty}^{\\infty}{DP(l_{t|m} = j)f_M(m)dm}\n",
    "$$\n",
    "where $f_M(m)$ is the probability density function (PDF) of the random\n",
    "variable $M$.\n",
    "\n",
    "With the assumption that have been made the one factor model is also called *Market Standard Model*.\n",
    "\n",
    "If the default probabilities are not the same for each company then it is possible through an iterative procedure to determine $DP(l_{t|M}=j)$ and proceed with the integration of the previous equation.\n",
    "\n",
    "### Extensions of the One Factor Copula Model\n",
    "Many other one-factor model have been tried: Student t copula, Clayton copula and many others. In general we can define a new model by simply choosing particular functions for $M$ and $Z_i$ provided they are with mean zero and standard deviation 1. \n",
    "\n",
    "If instead of the single factor $M$ there are two or more\n",
    "\n",
    "$$\n",
    "X_i = a_1 M_1 + a_2 M_2 + \\sqrt{1 - a_1^2 - a^2_2}Z_i\n",
    "$$\n",
    "and similarly\n",
    "$$\n",
    "Q(t|M_1, M_2) = \\Phi\\left(\\cfrac{\\Phi^{-1}[Q(t)]-a_1 M_1 - a_2 M_2}{\\sqrt{1 - a_1^2 - a^2_2}}\\right)\n",
    "$$\n",
    "This kind of models are proportionally slower with the increase of the number of factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basket Default Swaps\n",
    "A basket default swap is a credit derivative on a portfolio of reference\n",
    "entities. The simplest basket default swaps are first-to-default,\n",
    "second-to-default, or nth-to-default swaps. \n",
    "\n",
    "This kind of contracts are very similar to normal CDS except for the protection they offer.\n",
    "With respect to a basket of reference entities, a first-to-default swap provides insurance for only the first default, a second-to-default swap provides insurance\n",
    "for only the second default, and a nth-to-default swap provides insurance for only the $n^{th}$ default. \n",
    "\n",
    "For example, in the last case, the\n",
    "seller does not make a payment to the protection buyer for\n",
    "the first $n-1$ defaulted reference entities, and makes a payment only for the\n",
    "$n^{th}$ defaulted reference entity. Once there has been this payment the swap terminates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating nth-to-default Probabilities\n",
    "\n",
    "The valuation of a basket default swap comes down to the calculation of relevant default probabilities. So let's see how we can compute them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlated Defaults\n",
    "When the default probabilities of the companies are correlated the copula approach can be used like in the example shown above.\n",
    "\n",
    "Suppose we would like to simulate the defaults for the next 5 years for 6 companies. The copula default correlation between each company is 0.2 and the cumulative probability of default during the next 1,2,3,4 5 years is 1%, 3%, 6%, 10%, 13% respectively for each company.\n",
    "\n",
    "When a Gaussian copula is used in order to simulate the defaults we need to sample from a multivariate normal distribution a vector $\\mathbf{x}$, transform then each $x_i$ into the corresponding default probability $p_i$.\n",
    "\n",
    "Let's check the 3rd-to-default probabilities for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd-to-default probabilies\n",
      "0: 0.0000\n",
      "1: 0.0003\n",
      "2: 0.0033\n",
      "3: 0.0109\n",
      "4: 0.0250\n",
      "5: 0.0267\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "p_default = [0, 0.01, 0.03, 0.06, 0.10, 0.13]\n",
    "\n",
    "mvnorm = multivariate_normal(mean=[0]*6,\n",
    "                             cov = [[1, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "                                    [0.2, 1, 0.2, 0.2, 0.2, 0.2],\n",
    "                                    [0.2, 0.2, 1, 0.2, 0.2, 0.2],\n",
    "                                    [0.2, 0.2, 0.2, 1, 0.2, 0.2],\n",
    "                                    [0.2, 0.2, 0.2, 0.2, 1, 0.2],\n",
    "                                    [0.2, 0.2, 0.2, 0.2, 0.2, 1]])\n",
    "\n",
    "trials = 100000\n",
    "result = [0., 0., 0., 0., 0., 0.]\n",
    "x = mvnorm.rvs(size=trials)\n",
    "\n",
    "for n in range(len(x)):\n",
    "    p = sorted(norm.cdf(x[n]))\n",
    "    for i in range(1, len(p_default)):\n",
    "        if p_default[i-1] <= p[2] <= p_default[i]:\n",
    "            result[i] += 1\n",
    "\n",
    "print (\"3rd-to-default probabilies\")\n",
    "for i in range(len(p_default)):\n",
    "    print (\"{}: {:.4f}\".format(i, result[i]/trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basket CDS Valuation under Market Standard Model\n",
    "We now present some numerical results for an $n$th to default basket. We assume that the\n",
    "principals and expected recovery rates are the same for all underlying reference assets.\n",
    "The valuation procedure is similar to that for a regular CDS where there is only one\n",
    "reference entity.\n",
    "\n",
    "In a regular CDS indeed its valuation is based on the probability that a default\n",
    "occured between times $t1$ and $t2$. Here instead the valuation will be based on the probability that the\n",
    "$n$th default was between times $t1$ and $t2$.\n",
    "\n",
    "We assume the buyer of protection makes quarterly payments at a specified rate\n",
    "until the $n$th default occurs or the end of the life of the contract is reached. \n",
    "\n",
    "In the event of the $n$th default occurring, the seller pays $N\\cdot(1-R)$. \n",
    "The contract can be valued by calculating the expected present value\n",
    "of payments and the expected present value of payoffs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finmarkets_tot import CreditCurve, CreditDefaultSwap, generate_swap_dates\n",
    "from scipy.stats import norm, binom\n",
    "from math import sqrt, exp\n",
    "from scipy.integrate import quad\n",
    "import numpy as np\n",
    "\n",
    "class BasketDefaultSwaps:\n",
    "    def __init__(self, notional, start_date, spread, maturity, tenor, n_cds, rho):\n",
    "        self.n_cds = n_cds\n",
    "        self.rho = rho\n",
    "        self.cds = CreditDefaultSwap(notional, start_date, spread, maturity)\n",
    "        self.pillar_dates = generate_swap_dates(start_date, maturity*12, tenor) \n",
    "\n",
    "    def one_factor_model(self, M, f, Q, dc, ndefaults):\n",
    "            P = norm.cdf((norm.ppf(Q) - sqrt(self.rho)*M)/(sqrt(1-self.rho)))\n",
    "            b = binom(self.n_cds, P)\n",
    "            S = (1-b.cdf(self.n_cds)-b.cdf(ndefaults-1))\n",
    "            cc = CreditCurve(self.pillar_dates, S)\n",
    "            return f(dc, cc)*norm.pdf(M)\n",
    "        \n",
    "    def breakeven(self, dc, ndefaults, Q):\n",
    "        s = quad(self.one_factor_model, -np.inf, np.inf, args=(self.cds.breakevenRate, Q, dc, ndefaults))\n",
    "        return s[0]\n",
    "    \n",
    "    def npv(self, dc, ndefaults, Q):\n",
    "        s = quad(self.one_factor_model, -np.inf, np.inf, args=(self.cds.npv, Q, dc, ndefaults))\n",
    "        return s[0]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider first a 5-year $n$th to default CDS on a basket of 10 reference entities in the\n",
    "situation where the copula correlation is 0.3 and the expected recovery rate, $R$, is $40\\%$. The term structure of interest rates\n",
    "is assumed to be flat at 5%. The default probabilities for the 10 entities are generated by\n",
    "Poisson processes with constant default intensities (hazard rates), $\\lambda_i$, $(1 \\le i \\le 10)$ so that \n",
    "\n",
    "$$ DP(t) = 1 - e^{-\\lambda t} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017089585684271914\n"
     ]
    }
   ],
   "source": [
    "from finmarkets_tot import DiscountCurve\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "n_cds = 10\n",
    "rho = 0.3\n",
    "l = 0.01\n",
    "pillar_dates = []\n",
    "df = []\n",
    "observation_date = date.today()\n",
    "\n",
    "for i in range(6):\n",
    "    pillar_dates.append(observation_date + relativedelta(years=i))\n",
    "    df.append(1/(1+0.05)**i)\n",
    "dc = DiscountCurve(observation_date, pillar_dates, df)\n",
    "\n",
    "Q = [1-exp(-(l*t)) for t in range(6)]\n",
    "\n",
    "ndefaults = 1\n",
    "basket = BasketDefaultSwaps(1, observation_date, 0.01, 5, 12, n_cds, rho)\n",
    "print(basket.breakeven(dc, ndefaults, Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collateralized Debt Obligation\n",
    "\n",
    "A Collateralized Debt Obligation (CDO) is a credit derivative where the issuer, typically investment banks, gather risky assets and repackage them into discrete classes (*tranches*) based on the level of credit risk assumed by the investor. These tranches of securities become the final investment product.\n",
    "\n",
    "Tranches are named to reflect their risk profile: senior, mezzanine and subordinated/equity and are delimited by the attachment ($L$) and detachment points ($U$), which represent the percentages of the total principal defining their boundaries. \n",
    "\n",
    "Each of these tranches has a different level of seniority relative to the others in the sense that a senior tranche has coupon\n",
    "and principal payment priority over a mezzanine tranche, while a mezzanine tranche has\n",
    "coupon and principal payment priority over an equity tranche. \n",
    "Indeed they receive returns using a set of rules known as *waterfall*. Incomes of the portfolio are first used to provide returns to the most senior tranche, then to the next and so on.\n",
    "So the senior tranches are generally safest because they have the first claim on the collateral, although they'll offer lower coupon rates.\n",
    "\n",
    "<img src=\"cdo_structure.png\">\n",
    "\n",
    "It is important to note\n",
    "that a CDO only redistributes the total risk associated with the underlying pool of assets\n",
    "to the priority ordered tranches. It neither reduces nor increases the total risk associated\n",
    "with the pool.\n",
    "\n",
    "There are various kind of CDOs:\n",
    "\n",
    "* in a **Cash CDO** the reference portfolio consists of corporate bonds owned by the CDO issuer. To reduce the capital requirements to cover any potential loss,  the portfolio can be converted into a series of tranches and sold to investors. The equity tranche is usually kept by the issuer being the riskier but also the more rewarded.\n",
    "* in a **Synthetic CDO** the underlying reference portfolio is no longer a physical portfolio of bonds or loans, instead it is a *fictitious* portfolio consisting of a number of names each with an associated notional amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash CDO Expected Losses\n",
    "\n",
    "Consider a Cash CDO with a maturity of 1 year, made of 125 bonds. Each bond pays a coupon of one unit after 1 year and it has not yet defaulted (the recovery rate $R$ is assumed 0). We are interested in the following three tranches: equity ([0, 3] defaults), mezzanine ([4, 6] defaults) and senior ([7, 9] defaults), (note that now tranches are identified through the number of defaults and not percentages of the principal). \n",
    "\n",
    "<img src=\"ex_cdo_1.png\">\n",
    "\n",
    "We also assume that the probability of default within 1 year are identical for each bond ($Q$) and that the correlation between each pair is also identical and equal to $\\rho$.\n",
    "\n",
    "Under these assumptions we are in the position to use the Gaussian Copula Model and the derivation of the expected losses results quite simple.\n",
    "\n",
    "The probability of having $l$ defaults, conditional to the market parameter $M$ will follow a binomial distribution given by\n",
    "\n",
    "$$p(l|M) = \\binom{N}{l}Q_M^l (1-Q_M)^{N-l}$$\n",
    "\n",
    "where $N$ is the number of bonds in the portfolio and \n",
    "\n",
    "$$Q_M = \\Phi\\left(\\cfrac{\\Phi^{-1}(Q)-\\sqrt{\\rho}M}{\\sqrt{1-\\rho}}\\right)$$\n",
    "where $\\Phi$ is the standard normal CDF and $Q$ the probability of default within 1 year of a single name.\n",
    "\n",
    "From the definition of each tranche with have that the expected losses are\n",
    "\n",
    "* $\\mathbb{E}(\\textrm{equity loss})=3\\cdot\\mathbb{P}(l\\ge 3) + \\sum_{k=1}^{2}{k\\cdot\\mathbb{P}(l=k)}$\n",
    "* $\\mathbb{E}(\\textrm{mezzanine loss})=3\\cdot\\mathbb{P}(l\\ge 6) + \\sum_{k=1}^{2}{k\\cdot\\mathbb{P}(l=k+3)}$\n",
    "* $\\mathbb{E}(\\textrm{senior loss})=3\\cdot\\mathbb{P}(l\\ge 9) + \\sum_{k=1}^{2}{k\\cdot\\mathbb{P}(l=k+6)}$\n",
    "\n",
    "Each probability $\\mathbb{P}$ can be calculated by integrating the above with respect to $M$.\n",
    "\n",
    "Let's see the corresponding $\\tt{python}$ implementation.\n",
    "First we import the necessary modules and define the needed constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom, norm \n",
    "from scipy.integrate import quad \n",
    "import numpy as np\n",
    "\n",
    "N = 125\n",
    "C=1\n",
    "R=0\n",
    "q = 0.02\n",
    "tranches = [[1,3],[4, 6],[7,9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we define a function $\\tt{p}$ which implements the expected losses for each tranche.\n",
    "The function depends on the parameter $\\tt{M}$, and takes as inputs the correlation $\\tt{rho}$ and the tranche attach-detach limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(M, rho, lims):\n",
    "    qM = norm.cdf((norm.ppf(q)-np.sqrt(rho)*M)/(np.sqrt(1-rho))) \n",
    "    pN = binom(N, qM)\n",
    "    prob = 3*(pN.cdf(N) - pN.cdf(lims[1]-1))\n",
    "    for i in range(lims[0], lims[1]):\n",
    "        index = i-lims[0]+1\n",
    "        prob += index*pN.pmf(i) \n",
    "    return norm.pdf(M)*prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we loop over a range of possible values for the correlation on each tranche to draw the plot of the expected losses vs the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [[],[],[]]\n",
    "for i in range(len(tranches)):\n",
    "    for rho in np.arange(0, 1.05, 0.05): \n",
    "        if rho == 1.0:\n",
    "            rho = 0.99\n",
    "        v = quad(p, -np.inf, np.inf, args=(rho, tranches[i])) \n",
    "    res[i].append(v[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some considerations can be done from these results. First of all, as expected, the equity tranche is the riskier, producing the highest level of loss. The \n",
    "$$\n",
    "\\mathbb{E}(\\mathrm{equity})\\ge \\mathbb{E}(\\mathrm{mezzanine}) \\ge \\mathbb{E}(\\mathrm{senior})\n",
    "$$ \n",
    "relation holds only if each tranche has the same notional exposure (in our example 3).\n",
    "\n",
    "Then we can notice that in the equity tranche losses are decreasing in $\\rho$. When the correlation is low indeed the probability to have few defaults is higher than that of many. As the correlation increases, there will be more and more \"simultaneous\" defaults so also other tranches start to suffer losses. In the extreme case of correlation equal to 1 all the tranches are the same (indeed the expected losses curves join together). \n",
    "\n",
    "When considering all the tranches covering the entire number of names, the last tranche (the one with detachment point of 100\\%) is always increasing in $\\rho$. Again this can be explained with the correlated defaults. \n",
    "Also, the total expected losses on the three tranches is independent of $\\rho$. This is not an accident but it is due to the fact that every default scenario is now categorized in one of the plotted tranches while before this was not the case.\n",
    "\n",
    "<img src=\"losses_vs_rho.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic CDO Valuation\n",
    "\n",
    "Imagine a CDO made of $N$ names in the reference portfolio. Each name has a notional amount $F$.\n",
    "When the $i^{th}$ name defaults, then the portfolio incurs in a loss of $F(1-R)$ (the recovery rate is assumed to be fixed for all entities of the portfolio).\n",
    "\n",
    "The tranche loss function $TL^{L,U}(l)$ for a given time $t$ is a function of the number of defaults $l$ occurred up to that time and is given by\n",
    "\n",
    "$$TL_{t}^{L,U}=\\mathrm{max}(\\mathrm{min}(lF(1-R), U)-L, 0)$$\n",
    "where $lF(1-R)$ is the total portfolio loss, if it is greater than $U$ then the tranche loss is $U$. Conversely if it is lower than $L$ there is no loss.\n",
    "\n",
    "So for example suppose $L=3\\%$ and $U=7\\%$ and suppose also that the portfolio loss is $lF(1-R)=5\\%$. Then the tranche loss is 2\\% of the total portfolio notional (or 50\\% of the tranche notional $=7\\%-3\\%=4\\%$).\n",
    "\n",
    "When an investor *sells protection* on a tranche she is guaranteeing to reimburse any realized losses on the tranche to the *protection buyer*. To better understand this concept it is useful to think of the protection as an *insurance*. \n",
    "\n",
    "In return, the protection seller receives a premium at regular intervals (typically every three months) from the protection buyer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premium Leg\n",
    "As seen above the premium leg represents the payments that are done periodically by the protection buyer to the protection seller.\n",
    "\n",
    "These payments are made at the end of each time interval and are proportional to the **remaining notional** in the tranche (this is an important difference with respect to CDS, where the contract ends as soon as a default occurs).\n",
    "\n",
    "We can then write the NPV of the premium leg as\n",
    "\n",
    "$$\\mathrm{NPV}_{\\mathrm{premium}}^{L,U}=S\\sum^{n}_{i=1}D(d_i)\\cfrac{(d_i - d_{i-1})}{360}\\left((U-L)-\\mathbb{E}[TL_{d-1}^{L,U}]\\right)$$\n",
    "where $n$ is the number of payment dates, $D(d_i)$ is the discount factor, $S$ is the annualized premium. The expected value represents the expected notional remaining in the tranche at time \n",
    "$d_{i-1}$.\n",
    "Note that for simplicity we are ignoring that the default may take place at any time between each payment date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Leg\n",
    "The default leg represents the cash flows paid to the protection buyer upon losses occurring in the considered tranche. \n",
    "\n",
    "The NPV of the leg can be expressed as\n",
    "$$\\mathrm{NPV}_{\\mathrm{default}}^{L,U}=\\sum_{i=1}^{n}D(d_i)\\left(\\mathbb{E}[TL_{d_i}^{L,U}]-\\mathbb{E}[TL_{d_{i-1}}^{L,U}]\\right)$$\n",
    "where the argument in parenthesis is the expected losses between time $d_{i-1}$ up to $d_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the key ingredient for the valuation of a CDO is the calculation of $\\mathbb{E}[TL_{d_i}^{L,U}]$ which appears in both legs.\n",
    "Using the Gaussian copula it is relatively easy to compute it. \n",
    "Indeed we know that \n",
    "\n",
    "$$TL_{t}^{L,U}=\\mathrm{max}(\\mathrm{min}(lF(1-R), U)-L, 0)$$\n",
    "\n",
    "where the only random variable is the number of defaults $l$. We also know that \n",
    "\n",
    "$$\\mathbb{E}[TL_{t}^{L,U}] = \\sum_{l=0}^{N}TL_{t}^{L,U}\\cdot DP(l_t=j)$$\n",
    "\n",
    "with \n",
    "\n",
    "$$DP(l_t=j)=\\int_{-\\infty}^{\\infty} DP(l_{t|M}=j) \\phi(M)dM$$\n",
    "\n",
    "And has we have already seen this calculation can be carried on without too much effort.\n",
    "The large popularity of the Gaussian copula just resides in this, it allows to compute very quickly very complicated contracts like CDOs which usually involve a large number of correlated names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDO Fair Value\n",
    "The *fair value* of a CDO tranche is that value of the premium $S^*$ for which the expected value of the premium leg equals the expected value of the default leg and for what we have seen depends on the expected value of the tranche loss function.\n",
    "\n",
    "$$ S^* = \\cfrac{\\mathrm{NPV_{default}}^{L,U}}{\\sum^{n}_{i=1}D(d_i)\\cfrac{(d_i - d_{i-1})}{360}\\left((U-L)-\\mathbb{E}[TL_{d-1}^{L,U}]\\right)}$$\n",
    "\n",
    "This equation defines the CDO fair value, but can also be used to calibrate the implied correlation parameter from the market.\n",
    "This can be obtained by plugging into the equation the market premium value and solve for the correlation parameter $\\rho$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranche 0 ([0.0, 0.03]): 0.15942\n",
      "Tranche 1 ([0.03, 0.06]): 0.02505\n",
      "Tranche 2 ([0.06, 0.09]): 0.00773\n",
      "Tranche 3 ([0.09, 1.0]): 0.00017\n"
     ]
    }
   ],
   "source": [
    "from finmarkets_tot import DiscountCurve, CreditCurve, generate_swap_dates\n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import norm, binom\n",
    "import numpy as np\n",
    "from numpy import exp, sqrt\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "class CollDebtObligation:\n",
    "    def __init__(self, notional, names, tranches, rho, cc,\n",
    "                 start_date, spreads,\n",
    "                 maturity, tenor=3, recovery=0.4):\n",
    "        self.notional = notional\n",
    "        self.names = names\n",
    "        self.tranches = tranches\n",
    "        self.payment_dates = generate_swap_dates(start_date, maturity * 12, tenor)\n",
    "        self.spreads = spreads\n",
    "        self.rho = rho\n",
    "        self.recovery = recovery\n",
    "        self.cc = cc\n",
    "\n",
    "    def expected_tranche_loss(self, d, L, U):\n",
    "        def func(M, Q, l, L, U):\n",
    "            P = norm.cdf((norm.ppf(Q) - sqrt(self.rho) * M) / (sqrt(1 - self.rho)))\n",
    "            b = binom(self.names, P)\n",
    "            return b.pmf(l) * norm.pdf(M) * max(min(l/self.names * self.notional * (1 - self.recovery), U) - L, 0)\n",
    "\n",
    "        Q = 1 - self.cc.ndp(d)\n",
    "        v1 = 0\n",
    "        for l in range(self.names+1):\n",
    "            i = quad(func, -np.inf, np.inf, args=(Q, l, L, U))[0]\n",
    "            #print (i)\n",
    "            v1 += i\n",
    "            #print (\"v1 \", v1)\n",
    "        return v1\n",
    "\n",
    "    def npv_premium(self, tranche, dc):\n",
    "        L = self.tranches[tranche][0] * self.notional\n",
    "        U = self.tranches[tranche][1] * self.notional\n",
    "        v = 0\n",
    "        for i in range(1, len(self.payment_dates)):\n",
    "            ds = self.payment_dates[i - 1]\n",
    "            de = self.payment_dates[i]\n",
    "            D = dc.df(de)\n",
    "            ETL = self.expected_tranche_loss(ds, L, U)\n",
    "            #print (U, L, ETL, D)\n",
    "            v += D * (de - ds).days / 360 * max((U - L) - ETL, 0)\n",
    "        #print (v)\n",
    "        return v * self.spreads[tranche]\n",
    "\n",
    "    def npv_default(self, tranche, dc):\n",
    "        U = self.tranches[tranche][1] * self.notional\n",
    "        L = self.tranches[tranche][0] * self.notional\n",
    "        v = 0\n",
    "        for i in range(1, len(self.payment_dates)):\n",
    "            ds = self.payment_dates[i - 1]\n",
    "            de = self.payment_dates[i]\n",
    "            ETL1 = self.expected_tranche_loss(ds, L, U)\n",
    "            ETL2 = self.expected_tranche_loss(de, L, U)\n",
    "            #print(ETL2, ETL1)\n",
    "            v += dc.df(de) * (ETL2 - ETL1)\n",
    "        return v\n",
    "\n",
    "    def npv(self, tranche, dc):\n",
    "        return self.npv_default(tranche, dc) - self.npv_premium(tranche, dc)\n",
    "\n",
    "    def fair_value(self, tranche, dc):\n",
    "        num = self.npv_default(tranche, dc)\n",
    "        den = self.npv_premium(tranche, dc) / self.spreads[tranche]\n",
    "        return num / den\n",
    "\n",
    "\n",
    "pillar_dates = []\n",
    "df = []\n",
    "observation_date = date.today()\n",
    "\n",
    "for i in range(2):\n",
    "    pillar_dates.append(observation_date + relativedelta(years=i))\n",
    "    df.append(1 / (1 + 0.05) ** i)\n",
    "dc = DiscountCurve(observation_date, pillar_dates, df)\n",
    "\n",
    "cc = CreditCurve([observation_date + relativedelta(years=i) for i in range(5)],\n",
    "                 [1, 0.99, 0.97, 0.95, 0.93])\n",
    "\n",
    "tranches = [[0.0, 0.03], [0.03, 0.06], [0.06, 0.09], [0.09, 1.0]]\n",
    "spreads = [0.15, 0.07, 0.03, 0.01]\n",
    "\n",
    "cdo = CollDebtObligation(1, 125, tranches, 0.2, cc,\n",
    "                         observation_date, spreads, 1, 12)\n",
    "for i in range(len(tranches)):\n",
    "    print (\"Tranche {} ({}): {:.5f}\".format(i, tranches[i], cdo.fair_value(i, dc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
