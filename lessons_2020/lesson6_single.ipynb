{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Transformation\n",
    "\n",
    "Distribution transformation is a very useful tool which will be extensively used with the copula concept that we discuss in the next Section.\n",
    "The technique transforms every random variables from uniform to any distribution and vice versa and is called *probability integral transform* or (*percentile-to-percentile transform*). \n",
    "\n",
    "Computationally, this method involves computing the quantile function of the distribution, in other words, computing the cumulative distribution function (CDF) of the distribution (which maps a number in the domain to a probability between 0 and 1) and then inverting that function. We won't go into the details but we will just show few examples of how this can be done in $\\tt{python}$.\n",
    "\n",
    "For example, imagine that $\\mathbb{P}(X)$ is the standard normal distribution with mean zero and standard deviation one. If we want to convert uniformly distributed samples to standard normal we need to apply the inverse of CDF to each sample. Below few examples which exploit $\\tt{scipy.stats}$ which defines many useful statistical distributions.\n",
    "\n",
    "(Remember that the Uniform samples have to be interpreted as cumulative probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000 -> -0.5244\n",
      "0.50000 -> 0.0000\n",
      "0.90000 -> 1.2816\n",
      "0.99999 -> 4.2649\n"
     ]
    }
   ],
   "source": [
    "# make table uniform to gauss\n",
    "from scipy.stats import norm\n",
    "\n",
    "x_unif = [0.3, 0.5, 0.9, 0.99999]\n",
    "\n",
    "for x in x_unif:\n",
    "    print (\"{:.05f} -> {:.4f}\".format(x, norm.ppf(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same transformation may be applied directly on the entire sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from uniform\n",
    "from scipy.stats import uniform\n",
    "\n",
    "x_unif = uniform.rvs(size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we apply $\\tt{ppf()}$ to the list of $x$ directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to gaus\n",
    "x_transf = norm.ppf(x_unif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"uniform_gauss.png\">\n",
    "\n",
    "If we plot them togheter in a 2D plot we can get a sense of what is going on when using the inverse CDF transformation:\n",
    "\n",
    "<img src=\"uniform_to_gauss_2d.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse CDF stretches the outer regions of the uniform to yield a normal distribution. \n",
    "\n",
    "The nice thing of the technique is that it can be used with any arbitrary (univariate) probability distributions, like for example [t-Student](https://en.wikipedia.org/wiki/Student%27s_t-distribution) or [Gumbel](https://en.wikipedia.org/wiki/Gumbel_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same with t-student\n",
    "from scipy.stats import t\n",
    "\n",
    "x_trans2 = t(4).ppf(x_unif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"uniform_tstudent_2d.png\">\n",
    "\n",
    "Clearly to do the opposite transformation from an arbitray distribution to the uniform(0, 1) we can just apply the inverse of the inverse CDF, which is the CDF itself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make uniform to gauss to uniform\n",
    "x_trans3 = norm.ppf(x_unif)\n",
    "x_unif2 = norm.cdf(x_trans3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"full_chain.png\">\n",
    "\n",
    "## Copula\n",
    "\n",
    "In probability theory a *copula* $\\mathcal{C}(F_1, F_2, \\ldots, F_n)$ is a multivariate (multidimensional) cumulative distribution function whose marginal probability distributions (the probability distribution of each dimension) is uniform on the interval $[0, 1]$ ($U_i \\approx$ Uniform(0,1)). \n",
    "\n",
    "Copulas are used to describe the dependencies between random variables and have been widely used in quantitative finance to model risk. Copulas are popular since they allow to easily model and estimate the distribution of random vectors by representing marginals and their correlation separately. Essentially we can split complicated problems into simpler components so that copula results to be very handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Problem Case\n",
    "Imagine to measure two variables that are correlated. For example, we look at various rivers and for every river we look at its maximum water level, and also count how many months each river caused flooding. \n",
    "\n",
    "For the probability distribution of the maximum level of the river we know that maximums are Gumbel distributed, while the number of floods can be modelled according to a [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution).\n",
    "\n",
    "Clearly it is pretty reasonable to assume that the maximum level and the number of floodings is going to be correlated, however we don't know how we could model that correlated probability distribution. Above we only specified the distributions for individual variables, irrespective of the other one (i.e. the marginals), in reality we are dealing with the joint distribution of both of these together. \n",
    "\n",
    "And here is where copulas come to our rescue.\n",
    "\n",
    "Copulas essentially allow to decompose a joint probability distribution into their marginals (which by definition have no correlation) and a function which couples (hence the name) them together and thus allows to specify the correlation separately. \n",
    "\n",
    "Copula is that coupling function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Correlation with Gaussian Copulas\n",
    "\n",
    "So let's continue with our example even if we are actually almost done.\n",
    "Indeed, we saw before how to convert pretty much everything from and to uniform distribution. So that means we can generate uniformly distributed data with the correlation we want and then transform the marginals into the desired distributions. \n",
    "\n",
    "How do we do that ? \n",
    "\n",
    "* simulate from a multivariate Gaussian with the specific corrrelation structure;\n",
    "* transform each Gaussian marginal to uniform;\n",
    "* finally transform the uniforms to whatever we like.\n",
    "\n",
    "So let's sample from a multivariate normal (2D) with a 0.5 correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from multi-normal with corr\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "mvnorm = multivariate_normal(mean=[0, 0], cov=[[1, 0.5],\n",
    "                                               [0.5 , 1]])\n",
    "\n",
    "x = mvnorm.rvs(size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"multivariate_2d.png\">\n",
    "\n",
    "Now use what we have just seen to tranform the marginals to uniform using the $\\tt{cdf}$ function of the normal distribution ($x$ is a 2D vector in this case, but tranformation will be applied separately on each component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each component\n",
    "from scipy.stats import norm\n",
    "\n",
    "x_unif = norm.cdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"copula_2d.png\" width=300></td>\n",
    "        <td><img src=\"copula_3d.png\" width=300></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "These plots above is usually how copulas are visualized. **Since we used a multivariate stadard normal to model correlation this is also called a Gaussian Copula.**\n",
    "\n",
    "Finally we can just transform the marginals again from uniform to what we want (i.e. Gumbel and Beta in our river example): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert again to gumbel e beta\n",
    "from scipy.stats import gumbel_l, beta\n",
    "\n",
    "gumbel = gumbel_l()\n",
    "b = beta(a=4, b=10)\n",
    "\n",
    "x1 = gumbel.ppf(x_unif[:][0])\n",
    "x2 = b.ppf(x_unif[:][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see that it is actually working as expected we should now compare our scatter plot with correlation to the joint distribution of the same marginals without correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from Gumbel\n",
    "# sample from Beta\n",
    "m1 = gumbel.rvs(size=10000)\n",
    "m2 = b.rvs(size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"gumbel_beta_corr.png\" width=300></td>\n",
    "        <td><img src=\"gumbel_beta_uncorr.png\" width=300></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Using the uniform distribution as a common base for our transformations we can easily introduce correlations and flexibly construct complex probability distributions. Clearly this is directly extendeable to higher dimensional distributions as well.\n",
    "\n",
    "### Generate Correlated Distributions\n",
    "Let's now see how copulas can be used to generate numbers from correlated distributions. These are the steps to follow:\n",
    "\n",
    "* generate a random vector $\\mathbf{x}=(x_1, x_2,\\ldots)$ from a multivariate distribution with the desired correlation;\n",
    "* determine the single $U_i(x_i)$ by applying $\\tt{cdf}$ to each $x_i$;\n",
    "* transform again each $U_i(x_i)$ to the desired marginal distributions using $\\tt{ppf}$.\n",
    "\n",
    "Each component of the vector $\\mathbf{x}$ is now transformed as it was drawn from the desired marginals with the appropriate correlation.\n",
    "\n",
    "A practical application concerns the probability of default. Imagine there are three companies (A, B and C) which have a cumulative probability of defaulting within the next two years of 10%.\n",
    "\n",
    "Let’s try to compute the probabilities to have the three of them all defaulting within the next two years in the cases with independent and correlated default probabilities.\n",
    "\n",
    "In the first case (independent probabilities), the odds to get three defaults within two years is the product of the single probabilities, hence:\n",
    "$$\\mathbb{P}_{\\mathrm{uncorr}}= 10\\%\\cdot 10\\%\\cdot 10\\% = 0.1\\%$$\n",
    "\n",
    "We can verify this in $\\tt{python}$ by applying the Monte Carlo algorithm outlined above: generate a random sample from an uncorrelated multivariate normal distribution, then transform each sample\n",
    "( $[ x_A , x_B , x_C ]$ ) into the uniform distribution with the $\\tt{norm.cdf}$ function (i.e. we convert the samples into probabilities) and then count how many times the three of them are lower than 10%. The final probability will be the ratio of the numer of successes by the total trials.\n",
    "\n",
    "I am not interested in the real distribution of the marginals since I just want to work with cumulative probabilities so the uniforms are sufficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00105\n"
     ]
    }
   ],
   "source": [
    "# test default probabilities of three companies (no corr)\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "\n",
    "mvnorm = multivariate_normal(mean=[0]*3, cov=[[1, 0, 0],\n",
    "                                              [0, 1, 0],\n",
    "                                              [0, 0, 1]])\n",
    "trials=100000\n",
    "success = 0.\n",
    "x = mvnorm.rvs(size=trials)\n",
    "x_unif = norm.cdf(x)\n",
    "\n",
    "for v in x_unif:\n",
    "    if max(v) < 0.1:\n",
    "        success += 1\n",
    "        \n",
    "print (success/trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we repeat the same Monte Carlo experiment with perfectly correlated default probabilities\n",
    "we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09814\n"
     ]
    }
   ],
   "source": [
    "# test default probabilities of three companies (perfect corr)\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "\n",
    "mvnorm = multivariate_normal(mean=[0]*3, cov=[[1, 0.9999, 0.9999],\n",
    "                                              [0.9999, 1, 0.9999],\n",
    "                                              [0.9999, 0.9999, 1]])\n",
    "trials=100000\n",
    "success = 0.\n",
    "x = mvnorm.rvs(size=trials)\n",
    "x_unif = norm.cdf(x)\n",
    "\n",
    "for v in x_unif:\n",
    "    if max(v) < 0.1:\n",
    "        success += 1\n",
    "        \n",
    "print (success/trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the result is 10%, like we had only one single company, indeed being perfectly\n",
    "correlated either there is no default or three \"simultaneous\" defaults with 10% probability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
