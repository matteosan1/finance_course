\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for grffile with XeLaTeX
    \def\Gread@@xetex#1{%
      \IfFileExists{"\Gin@base".bb}%
      {\Gread@eps{\Gin@base.bb}}%
      {\Gread@@xetex@aux#1}%
    }
    \makeatother

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{copula}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        \ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{quantile-function}{%
\subsection{Quantile Function}\label{quantile-function}}

In probability theory and statistics, the \emph{cumulative distribution
function} (CDF) \(F\) of a random variable \(X\), evaluated at \(x\), is
the probability that \(X\) will take a value less than or equal to \(x\)

\[F_X(x) = \mathbb{P}(X \le x)\qquad\mathrm{or equivalently}~\int_{-\infty}^{x}{f(X)dX}\]
so it gives the area under the probability density function \(f\) from
minus infinity to \(x\).

The probability that \(X\) lies in the interval \((a,b]\) is therefore

\[\mathbb{P}(a\lt X \le b)=F_{X}(b)-F_{X}(a)\qquad\mathrm{or}~\int_a^b{f(X)dX}\]

With reference to a continuous and strictly monotonic distribution
function, for example the cumulative distribution function \(F_X\), the
\emph{quantile function} \(Q\) returns a threshold value \(x\) below
which random draws from the given CDF would fall \(p\) percent of the
time.

In terms of the distribution function \(F\), the quantile function \(Q\)
returns the value \(x_p\) such that \$
F\_\{X\}(x\_p):=\mathbb{P}(X\le x\_p)=p\$

So the quantile function does the opposite of the cumulative
distribution function: given a probability \(p\) (or a value of the CDF)
it returns the \(x\) at which the CDF reaches this probability (or this
value) \[Q=F^{-1}\]

In Fig.\textasciitilde{}\ref{fig:percentile} an example related to the
Gaussian distribution is shown. On the left the Gaussian PDF is drawn,
the red area represent the 30\% of the total area (which is 1 since the
PDF is normalized). On the right the corresponding CDF is represented,
in the plot it is also highlighted the point at which the CDF reaches
30\%. The corresponding quantile value is also indicated and is -0.5244.

The computation of CDF and quantiles is quite simple in \(\tt{python}\).
Many distribution implementations are available in \(\tt{scipy.stats}\)
module and for each of them the methods \(\tt{cdf(x)}\) and
\(\tt{ppf(x)}\) are available to evaulate CDF and quantile respectively.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{norm}
\PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{pyplot} \PY{k}{as} \PY{n}{plt}
\PY{n}{plt}\PY{o}{.}\PY{n}{style}\PY{o}{.}\PY{n}{use}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{seaborn}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{quantile} \PY{o}{=} \PY{n}{norm}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mf}{0.3}\PY{p}{)}
\PY{n}{cdf} \PY{o}{=} \PY{n}{norm}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{n}{quantile}\PY{p}{)}

\PY{n+nb}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{30}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZhy{}quantile of standard normal is }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{quantile}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{CDF value at }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{quantile}\PY{p}{,} \PY{n}{cdf}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
30\%-quantile of standard normal is -0.5244005127080409
CDF value at -0.5244005127080409: 0.29999999999999993
    \end{Verbatim}

    If instead of a distribution you have a dataset the quantile can be
determined using the function \(\tt{numpy.percentile}\) (this will be
useful when estimating VaR). Notice that in this case we are talking
about \emph{percentile} which is the \emph{quantile} times 100
(e.g.~50-percentile is equivalent to 0.5-quantile).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{numpy}
\PY{n}{dist} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{,} \PY{l+m+mi}{7}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{9}\PY{p}{]}

\PY{c+c1}{\PYZsh{} first argument the dataset}
\PY{c+c1}{\PYZsh{} second argument a list of percentiles}
\PY{n}{perc} \PY{o}{=} \PY{n}{numpy}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{dist}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{]}\PY{p}{)}

\PY{n+nb}{print} \PY{p}{(}\PY{n}{perc}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[1.08 5.  ]
    \end{Verbatim}

    \hypertarget{distribution-transformation}{%
\subsubsection{Distribution
Transformation}\label{distribution-transformation}}

Distribution transformation is a very useful tool which will be
extensively used with the copula concept that we discuss in the next
Section. The technique we are going to outline transforms every random
variables to uniform and viceversa and is called
\emph{probability integral transform} or (percentile-to-percentile
transform).

Computationally, this method involves computing the quantile function of
the distribution --- in other words, computing the cumulative
distribution function (CDF) of the distribution (which maps a number in
the domain to a probability between 0 and 1) and then inverting that
function. We won't go into the details but we will just show few
examples of how this can be done in \(\tt{python}\).

The transformation takes uniform samples of a number \(u\) between 0 and
1, interpreted as a probability, and then returns the largest number
\(x\) from the domain of the distribution \(\mathbb{P}(X)\) such that
\(\mathbb{P}(-\infty <X<x)\le u\). For example, imagine that
\(\mathbb{P}(X)\) is the standard normal distribution with mean zero and
standard deviation one. The table below shows samples taken from the
uniform distribution and their representation on the standard normal
distribution.

Transformation from uniform sample to normal:

\begin{longtable}[]{@{}cc@{}}
\toprule
\(u\) & \(F^{-1}(u)\)\tabularnewline
\midrule
\endhead
0.5 & 0\tabularnewline
.975 & 1.95996\tabularnewline
.995 & 2.5758\tabularnewline
.999999 & 4.75342\tabularnewline
\(1-2^{-52}\) & 8.12589\tabularnewline
\bottomrule
\end{longtable}

Let's first sample uniformly distributed values between 0 and 1:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
\PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{pyplot} \PY{k}{as} \PY{n}{plt}

\PY{n}{x} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{style}\PY{o}{.}\PY{n}{use}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{seaborn}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{copula_files/copula_5_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Next we want to transform these samples so that instead of uniform they
are normally distributed. As we have seen the transform that does this
is the inverse of the cumulative density function (CDF) of the normal
distribution the \((\tt{ppf(x))}\).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{norm} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{distributions}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{p}{)} 
\PY{n}{x\PYZus{}trans} \PY{o}{=} \PY{n}{norm}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{n}{x}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x\PYZus{}trans}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{copula_files/copula_7_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    If we plot them togheter in a 2D plot we can get a sense of what is
going on using the inverse CDF transformation:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}

\PY{c+c1}{\PYZsh{} definitions for the axes}
\PY{n}{left}\PY{p}{,} \PY{n}{width} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{bottom}\PY{p}{,} \PY{n}{height} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{spacing} \PY{o}{=} \PY{l+m+mf}{0.005}

\PY{n}{rect\PYZus{}scatter} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{n}{height}\PY{p}{]}
\PY{n}{rect\PYZus{}histx} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom} \PY{o}{+} \PY{n}{height} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{]}
\PY{n}{rect\PYZus{}histy} \PY{o}{=} \PY{p}{[}\PY{n}{left} \PY{o}{+} \PY{n}{width} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{height}\PY{p}{]}

\PY{c+c1}{\PYZsh{} start with a rectangular Figure}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}scatter} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}scatter}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{top}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{right}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{ax\PYZus{}histx} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histx}\PY{p}{)}
\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelbottom}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{ax\PYZus{}histy} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histy}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelleft}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} the scatter plot:}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{x\PYZus{}trans}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{k+kc}{True}\PY{p}{)}

\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.1}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x\PYZus{}trans}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{orientation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{horizontal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}xlim}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}ylim}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{copula_files/copula_9_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The inverse CDF stretches the outer regions of the uniform to yield a
normal distribution. The nice thing of the technique is that it can be
done for any arbitrary (univariate) probability distributions, like for
example
\textbackslash{}href\{https://en.wikipedia.org/wiki/Student\%27s\_t-distribution\}\{t-Student\}
or \href{https://en.wikipedia.org/wiki/Gumbel_distribution}{Gumbel}:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{tstudent} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{distributions}\PY{o}{.}\PY{n}{t}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{)}
\PY{n}{x\PYZus{}trans} \PY{o}{=} \PY{n}{tstudent}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{n}{x}\PY{p}{)}

\PY{c+c1}{\PYZsh{} definitions for the axes}
\PY{n}{left}\PY{p}{,} \PY{n}{width} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{bottom}\PY{p}{,} \PY{n}{height} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{spacing} \PY{o}{=} \PY{l+m+mf}{0.005}

\PY{n}{rect\PYZus{}scatter} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{n}{height}\PY{p}{]}
\PY{n}{rect\PYZus{}histx} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom} \PY{o}{+} \PY{n}{height} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{]}
\PY{n}{rect\PYZus{}histy} \PY{o}{=} \PY{p}{[}\PY{n}{left} \PY{o}{+} \PY{n}{width} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{height}\PY{p}{]}

\PY{c+c1}{\PYZsh{} start with a rectangular Figure}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}scatter} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}scatter}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{top}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{right}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{ax\PYZus{}histx} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histx}\PY{p}{)}
\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelbottom}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{ax\PYZus{}histy} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histy}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelleft}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} the scatter plot:}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{x\PYZus{}trans}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{k+kc}{True}\PY{p}{)}

\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.1}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{6}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x\PYZus{}trans}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,} \PY{n}{orientation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{horizontal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}xlim}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}ylim}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{copula_files/copula_11_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Clearly to do the opposite transformation from an arbitray distribution
to the uniform(0, 1) we can just apply the inverse of the inverse CDF,
the CDF itself\ldots{}

    \hypertarget{copula}{%
\subsection{Copula}\label{copula}}

In probability theory a \emph{copula} \(C(U_1, U_2, \ldots, U_n, \rho)\)
is a multivariate (multidimensional) cumulative distribution function
for which the marginal probability distribution (the probability
distribution of each dimension) of each variable is uniform on the
interval \([0, 1]\) (\(U_i \approx\)\textasciitilde{}Uniform(0,1)).
\(\rho\) represent the correlation between each variable.

\emph{Sklar's theorem} states that any multivariate joint distribution
can be written in terms of univariate marginal distribution functions
and a copula which describes the dependence structure between the
variables.

Copulas are used to describe the dependence between random variables and
have been used widely in quantitative finance to model and minimize tail
risk and portfolio-optimization applications. Copulas are popular since
they allow one to easily model and estimate the distribution of random
vectors by estimating marginals and copulae separately.

Despite the obscure and daunting definition the conceptof copula is
quite simple so let's try to clarify it a bit with a practical example.
Later we will see what role copulas played in the 2008 financial crisis.

\hypertarget{example-problem-case}{%
\subsubsection{Example Problem Case}\label{example-problem-case}}

Imagine we measure two variables that are non-normally distributed and
correlated. For example, we look at various rivers and for every river
we look at the maximum water level of that river over a certain
time-period. In addition, we also count how many months each river
caused flooding.

For the probability distribution of the maximum level of the river we
know that maximums are Gumbel distributed, while the number of flooding
can be modelled according to a
\href{https://en.wikipedia.org/wiki/Beta_distribution}{\emph{Beta}}
distribution.

Clearly it is pretty reasonable to assume that the maximum level and the
number of floodings is going to be correlated, however we don't know how
we could model that correlated probability distribution. Above we only
specified the distributions for individual variables, irrespective of
the other one (i.e.~the marginals), in reality we are dealing with a
joint distribution of both of these together.

And here is where copulas come to our rescue.

Copulas essentially allow to decompose a joint probability distribution
into their marginals (which by definition have no correlation) and a
function which couples (hence the name) them together and thus allows us
to specify the correlation separately. The copula is that coupling
function.

    \hypertarget{adding-correlation-with-gaussian-copulas}{%
\subsection{Adding Correlation with Gaussian
Copulas}\label{adding-correlation-with-gaussian-copulas}}

How does this help us with our problem of creating a custom joint
probability distriution ?

We are actually almost done already, we saw before how to convert
anything uniformly distributed to an arbitrary probability distribution.
So that means we need to generate uniformly distributed data with the
correlation we want and then transform the marginals into the desired
distributions.

How do we do that ?

\begin{itemize}
\tightlist
\item
  simulate from a multivariarte Gaussian with the specific corrrelation
  structure;
\item
  transform so that the marginals are uniform
\item
  finally transform the uniform marginals to whatever we like.
\end{itemize}

So let's sample from a multivariate normal (2D) with a 0.5 correlation.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} this import is for plotting}
\PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{colors}

\PY{n}{mvnorm} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{multivariate\PYZus{}normal}\PY{p}{(}\PY{n}{mean}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]} \PY{p}{,} \PY{n}{cov}\PY{o}{=}\PY{p}{[}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{]}\PY{p}{,}
                                                      \PY{p}{[}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}
\PY{n}{x} \PY{o}{=} \PY{n}{mvnorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{l+m+mi}{100000}\PY{p}{)}

\PY{c+c1}{\PYZsh{} definitions for the axes}
\PY{n}{left}\PY{p}{,} \PY{n}{width} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{bottom}\PY{p}{,} \PY{n}{height} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{spacing} \PY{o}{=} \PY{l+m+mf}{0.005}

\PY{n}{rect\PYZus{}scatter} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{n}{height}\PY{p}{]}
\PY{n}{rect\PYZus{}histx} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom} \PY{o}{+} \PY{n}{height} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{]}
\PY{n}{rect\PYZus{}histy} \PY{o}{=} \PY{p}{[}\PY{n}{left} \PY{o}{+} \PY{n}{width} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{height}\PY{p}{]}

\PY{c+c1}{\PYZsh{} start with a rectangular Figure}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}scatter} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}scatter}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{top}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{right}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{ax\PYZus{}histx} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histx}\PY{p}{)}
\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelbottom}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{ax\PYZus{}histy} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histy}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelleft}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} the scatter plot:}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{hist2d}\PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{x}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{norm}\PY{o}{=}\PY{n}{colors}\PY{o}{.}\PY{n}{LogNorm}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GnBu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{4}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{orientation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{horizontal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}xlim}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}ylim}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{copula_files/copula_15_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Now use what we have just seen to \emph{uniformify} the marginals using
the \(\tt{cdf}\) function of the normal distribution (\(x\) is a 2D
vector, but in the code we can treat it as a vector, \(\tt{cdf}\) will
be applied separately on each component):

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{norm} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{p}{)}
\PY{n}{x\PYZus{}unif} \PY{o}{=} \PY{n}{norm}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{n}{x}\PY{p}{)}

\PY{c+c1}{\PYZsh{} definitions for the axes}
\PY{n}{left}\PY{p}{,} \PY{n}{width} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{bottom}\PY{p}{,} \PY{n}{height} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{spacing} \PY{o}{=} \PY{l+m+mf}{0.005}

\PY{n}{rect\PYZus{}scatter} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{n}{height}\PY{p}{]}
\PY{n}{rect\PYZus{}histx} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom} \PY{o}{+} \PY{n}{height} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{]}
\PY{n}{rect\PYZus{}histy} \PY{o}{=} \PY{p}{[}\PY{n}{left} \PY{o}{+} \PY{n}{width} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{height}\PY{p}{]}

\PY{c+c1}{\PYZsh{} start with a rectangular Figure}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}scatter} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}scatter}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{top}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{right}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{ax\PYZus{}histx} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histx}\PY{p}{)}
\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelbottom}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{ax\PYZus{}histy} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histy}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelleft}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} the scatter plot:}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{hist2d}\PY{p}{(}\PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{norm}\PY{o}{=}\PY{n}{colors}\PY{o}{.}\PY{n}{LogNorm}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GnBu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.1}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.1}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{orientation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{horizontal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}xlim}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}ylim}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{copula_files/copula_17_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
     These plots above is usually how copulas are visualized. Finally we can
just transform the marginals again from uniform to what we want
(i.e.~Gumbel and Beta in our river example):

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{m1} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{gumbel\PYZus{}l}\PY{p}{(}\PY{p}{)}
\PY{n}{m2} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{beta}\PY{p}{(}\PY{n}{a}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{b}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}

\PY{c+c1}{\PYZsh{} transform U1 into Gumbel}
\PY{n}{x1\PYZus{}trans} \PY{o}{=} \PY{n}{m1}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\PY{c+c1}{\PYZsh{}transform U2 into Beta}
\PY{n}{x2\PYZus{}trans} \PY{o}{=} \PY{n}{m2}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} definitions for the axes}
\PY{n}{left}\PY{p}{,} \PY{n}{width} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{bottom}\PY{p}{,} \PY{n}{height} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{spacing} \PY{o}{=} \PY{l+m+mf}{0.005}

\PY{n}{rect\PYZus{}scatter} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{n}{height}\PY{p}{]}
\PY{n}{rect\PYZus{}histx} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom} \PY{o}{+} \PY{n}{height} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{]}
\PY{n}{rect\PYZus{}histy} \PY{o}{=} \PY{p}{[}\PY{n}{left} \PY{o}{+} \PY{n}{width} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{height}\PY{p}{]}

\PY{c+c1}{\PYZsh{} start with a rectangular Figure}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}scatter} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}scatter}\PY{p}{)}

\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{top}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{right}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{ax\PYZus{}histx} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histx}\PY{p}{)}
\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelbottom}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{ax\PYZus{}histy} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histy}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelleft}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} the scatter plot:}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{hist2d}\PY{p}{(}\PY{n}{x1\PYZus{}trans}\PY{p}{,} \PY{n}{x2\PYZus{}trans}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{norm}\PY{o}{=}\PY{n}{colors}\PY{o}{.}\PY{n}{LogNorm}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GnBu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mf}{2.5}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{(}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x1\PYZus{}trans}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x2\PYZus{}trans}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{orientation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{horizontal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}xlim}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}ylim}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{copula_files/copula_19_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    To see that it is actually working as expected we should now compare our
scatter plot with correlation to the joint distribution of the same
marginals without correlation:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} sample from Gumbel}
\PY{n}{x1} \PY{o}{=} \PY{n}{m1}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{)}
\PY{c+c1}{\PYZsh{} sample from Beta}
\PY{n}{x2} \PY{o}{=} \PY{n}{m2}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{)}

\PY{c+c1}{\PYZsh{} definitions for the axes}
\PY{n}{left}\PY{p}{,} \PY{n}{width} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{bottom}\PY{p}{,} \PY{n}{height} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{0.65}
\PY{n}{spacing} \PY{o}{=} \PY{l+m+mf}{0.005}

\PY{n}{rect\PYZus{}scatter} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{n}{height}\PY{p}{]}
\PY{n}{rect\PYZus{}histx} \PY{o}{=} \PY{p}{[}\PY{n}{left}\PY{p}{,} \PY{n}{bottom} \PY{o}{+} \PY{n}{height} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{width}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{]}
\PY{n}{rect\PYZus{}histy} \PY{o}{=} \PY{p}{[}\PY{n}{left} \PY{o}{+} \PY{n}{width} \PY{o}{+} \PY{n}{spacing}\PY{p}{,} \PY{n}{bottom}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{height}\PY{p}{]}

\PY{c+c1}{\PYZsh{} start with a rectangular Figure}
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}scatter} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}scatter}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{top}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{right}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{ax\PYZus{}histx} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histx}\PY{p}{)}
\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelbottom}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{ax\PYZus{}histy} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{axes}\PY{p}{(}\PY{n}{rect\PYZus{}histy}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{direction}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{in}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{labelleft}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{c+c1}{\PYZsh{} the scatter plot:}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{hist2d}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{x2}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{norm}\PY{o}{=}\PY{n}{colors}\PY{o}{.}\PY{n}{LogNorm}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GnBu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{k+kc}{True}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mf}{2.5}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{(}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{x2}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{orientation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{horizontal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{histtype}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{stepfilled}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{ec}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkblue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightblue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}

\PY{n}{ax\PYZus{}histx}\PY{o}{.}\PY{n}{set\PYZus{}xlim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}xlim}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n}{ax\PYZus{}histy}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{n}{ax\PYZus{}scatter}\PY{o}{.}\PY{n}{get\PYZus{}ylim}\PY{p}{(}\PY{p}{)}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{copula_files/copula_21_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Using the uniform distribution as a common base for our transformations
we can easily introduce correlations and flexibly construct complex
probability distributions. Clearly this is directly extendeable to
higher dimensional distributions as well.

\hypertarget{generate-correlated-distributions}{%
\subsubsection{Generate Correlated
Distributions}\label{generate-correlated-distributions}}

If we need to generate numbers from correlated distribution we can
follow the same steps as before:

\begin{itemize}
\tightlist
\item
  generate a random vector \(\mathbf{x}=(x_1, x_2,\ldots)\) from the
  original multivariate distribution;
\item
  determine the single \(U_i(x_i)\) by applying \(\tt{cdf}\) to each
  \(x_i\);
\item
  transform again each \(U_i(x_i)\) to the desired marginal
  distributions using \(\tt{ppf}\);
\item
  each component of the vector \(\mathbf{x}\) will be converted to a set
  of random numbers drawn from the desired distributions, with the
  appropriate correlation.
\end{itemize}

    \hypertarget{application-to-finance}{%
\subsection{Application to Finance}\label{application-to-finance}}

In credit derivative valuation and credit risk management, one of the
most important issue is the estimate of default probabilities and their
correlations. Default correlation measures the tendency of two companies
to default at about the same time. For this, generally speaking, there
are two ways: using historical default data or using mathematical
models, like copulas.

Historical default data has played an important role in the estimation
of default probabilities. However, because default events are rare,
there is very limited default data available. Moreover, historical data
reflects the historical default pattern only and it may not be a proper
indicator of the future. This makes the estimation of default
probabilities from historical data difficult and inexact. To use this
same data to estimate default correlations is even more difficult and
more inexact.

On the other hand mathematical models don't rely on historical default
data. In Chapter\textasciitilde{}\ref{} we have seen how it is possible
to derive default probabilities from market data. Before going into the
details of the application of the copula to default probabilities let's
introduce two more kind of contracts.

\hypertarget{basket-default-swaps}{%
\subsection{Basket Default Swaps}\label{basket-default-swaps}}

A basket default swap is a credit derivative on a portfolio of reference
entities. The simplest basket default swaps are first-to-default swaps,
second-to-default swaps, and nth-to-default swaps.

With respect to a basket of reference entities, a first-to-default swap
provides insurance for only the first default, a second-to-default swap
provides insurance for only the second default, an nth-to-default swap
provides insurance for only the nth default.

For example, in an nth-to-default swap, the protection seller does not
make a payment to the protection buyer for the first n1 defaulted
reference entities, and makes the payment only for the nth defaulted
reference entity. Once there is a payment upopn the default of the a
defaulted reference entity, the swap terminates.

\hypertarget{calculating-nth-to-default-probabilities}{%
\subsubsection{Calculating nth-to-default
Probabilities}\label{calculating-nth-to-default-probabilities}}

The valuation of a basket default swap comes down to the calculation of
relevant default probabilities. So let's see how we can compute them.

\hypertarget{independent-defaults}{%
\paragraph{Independent Defaults}\label{independent-defaults}}

If the default times of the names of a basket are independent,
first-to-default, nth-to-default, all-to-default probabilities can be
calculated through multiplication and integration of the default
probability curves of each basket components.

As an example, we consider the second-to-default probability of a 3-name
basket. Let \(\tau_i\) be the default time of name \(i\) and \(F_i(t)\)
its distribution. Then the probability that name 1 defaults second in
the basket before time \(t\):

\[
\begin{align*}
&P((\tau_2\lt\tau_1)\cap (\tau_1\lt t)\cap (\tau_1\lt\tau_3)) +
P((\tau_3\lt\tau_1)\cap (\tau_1\lt t)\cap (\tau_1\lt\tau_2)) = \\
&\int_0^t{F_2 (s)\cdot (1-F_3 (s))~dF_1(s)} +  \int_0^t{F_3 (s)\cdot (1-F_2 (s))~dF_1(s)}
\end{align*}
\]

The formula for nth-to-default probability in a general basket can be
derived similarly, however, complexity increases as the number of names
increases.

Suppose the default probabilities of three companies, A, B and C are
given as in the following table:

\begin{longtable}[]{@{}cccc@{}}
\toprule
time in years & A & B & C\tabularnewline
\midrule
\endhead
0 & 0 & 0 & 0\tabularnewline
1 & 0.022032 & 0.0317 & 0.035\tabularnewline
2 & 0.046242 & 0.0655 & 0.075\tabularnewline
3 & 0.07266 & 0.1022 & 0.121\tabularnewline
4 & 0.101233 & 0.142 & 0.153\tabularnewline
5 & 0.131885 & 0.1752 & 0.205\tabularnewline
\bottomrule
\end{longtable}

and suppose that the default events of the three companies are
independent.

The default probabilities are linear in each time interval so the
integral above can be solved by substitution:

\[ \int_{x_0}^{x_1}{(1-F_B(x))(1-F_C(x))dF_A(x)}\]

Setting \(t=m_A x + q_A\) it becomes with \(m_A, q_A\) are the
parameters of the line joining the default probabilities of company A:

\[ \int_{m_A x_0 + q_A}^{m_A x_1 + q_A}{(1-F_B(x(t)))(1-F_C(x(t)))dt}\qquad\textrm{, with}~x(t) = \cfrac{t -q_A}{m_A} \]
and similarly for company B and C.

To convert it into python we can use \(\tt{scipy.integrate.quad}\) to
perform the integral and \(\tt{numpy.interp}\) to determine the
intermediate default probabilities.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{integrate} \PY{k}{import} \PY{n}{quad}
\PY{k+kn}{from} \PY{n+nn}{numpy} \PY{k}{import} \PY{n}{interp}

\PY{n}{default\PYZus{}rates} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.022032}\PY{p}{,} \PY{l+m+mf}{0.046242}\PY{p}{,} \PY{l+m+mf}{0.07266}\PY{p}{,} \PY{l+m+mf}{0.101233}\PY{p}{,} \PY{l+m+mf}{0.131885}\PY{p}{)}\PY{p}{,} \PY{c+c1}{\PYZsh{} company A}
                 \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{B}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.0317}\PY{p}{,} \PY{l+m+mf}{0.0655}\PY{p}{,} \PY{l+m+mf}{0.1022}\PY{p}{,} \PY{l+m+mf}{0.142}\PY{p}{,} \PY{l+m+mf}{0.1752}\PY{p}{)}\PY{p}{,} \PY{c+c1}{\PYZsh{} company B}
                 \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{C}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.035}\PY{p}{,} \PY{l+m+mf}{0.075}\PY{p}{,} \PY{l+m+mf}{0.121}\PY{p}{,} \PY{l+m+mf}{0.153}\PY{p}{,} \PY{l+m+mf}{0.205}\PY{p}{)}\PY{p}{\PYZcb{}} \PY{c+c1}{\PYZsh{} company C}

\PY{k}{def} \PY{n+nf}{func}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{default}\PY{p}{,} \PY{n}{companies}\PY{p}{,} \PY{n}{t}\PY{p}{)}\PY{p}{:}
    \PY{n}{m} \PY{o}{=} \PY{n}{default}\PY{p}{[}\PY{n}{companies}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{[}\PY{n}{t}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{default}\PY{p}{[}\PY{n}{companies}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{[}\PY{n}{t}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
    \PY{n}{q} \PY{o}{=} \PY{n}{default}\PY{p}{[}\PY{n}{companies}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{[}\PY{n}{t}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{m} \PY{o}{*} \PY{p}{(}\PY{n}{t}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{t} \PY{o}{=} \PY{p}{(}\PY{n}{x}\PY{o}{\PYZhy{}}\PY{n}{q}\PY{p}{)}\PY{o}{/}\PY{n}{m}
    \PY{n}{F2} \PY{o}{=} \PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{interp}\PY{p}{(}\PY{n}{t}\PY{p}{,} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{default}\PY{p}{[}\PY{n}{companies}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{default}\PY{p}{[}\PY{n}{companies}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}
    \PY{n}{F3} \PY{o}{=} \PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{interp}\PY{p}{(}\PY{n}{t}\PY{p}{,} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{default}\PY{p}{[}\PY{n}{companies}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{default}\PY{p}{[}\PY{n}{companies}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{]}\PY{p}{)}
    \PY{k}{return} \PY{n}{F2}\PY{o}{*}\PY{n}{F3}

\PY{k}{def} \PY{n+nf}{integral}\PY{p}{(}\PY{n}{default}\PY{p}{,} \PY{n}{companies}\PY{p}{,} \PY{n}{t}\PY{p}{)}\PY{p}{:}
    \PY{k}{return} \PY{n}{quad}\PY{p}{(}\PY{n}{func}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{n}{default}\PY{p}{[}\PY{n}{companies}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{]}\PY{p}{[}\PY{n}{t}\PY{p}{]}\PY{p}{,} \PY{n}{args}\PY{o}{=}\PY{p}{(}\PY{n}{default}\PY{p}{,} \PY{n}{companies}\PY{p}{,} \PY{n}{t}\PY{p}{)}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                 
\PY{k}{for} \PY{n}{companies} \PY{o+ow}{in} \PY{p}{[}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{B}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{C}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{B}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{C}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{C}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{A}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{B}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{]}\PY{p}{:}
    \PY{n}{prob} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{k}{for} \PY{n}{t} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{:}
        \PY{n}{prob} \PY{o}{=} \PY{n}{integral}\PY{p}{(}\PY{n}{default\PYZus{}rates}\PY{p}{,} \PY{n}{companies}\PY{p}{,} \PY{n}{t}\PY{p}{)}
        \PY{n+nb}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{First to default prob at time (}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{) for company }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{: }\PY{l+s+si}{\PYZob{}:.5f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{t}\PY{p}{,} \PY{n}{companies}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{prob}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{correlated-defaults}{%
\paragraph{Correlated Defaults}\label{correlated-defaults}}

When the default probabilities of the companies are correlated the
copula approach can be used.

Suppose we would like to simulate the defaults for the next 5 years for
10 companies. The copula default correlation between each company is 0.2
and the cumulative probability of default during the next 1,2,3,4 5
years is 1\%, 3\%, 6\%, 10\%, 13\% respectively for each company.

When a Gaussian copula is used in order to simulate the defaults we need
to sample from a multivariate normal distribution a vector
\(\mathbf{x}\), transform then each \(x_i\) into the default time
\(t_i\).

    In this simple example company 10 would have defaulted during first year
(\(\mathbb{P}(t_{10}) \le 1\%\), companies 8 and 9 during the second
(both have \(3\% \le \mathbb{P}(t_{8,9}) \le 6\%\)) and so on.

To determine nth-to-default probabilities it is enough to repeat many
sampling from the multivariate normal distributions and count how many
times we have n defaults before each year.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{multivariate\PYZus{}normal}\PY{p}{,} \PY{n}{norm}

\PY{n}{default\PYZus{}rates} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.022032}\PY{p}{,}\PY{l+m+mf}{0.046242}\PY{p}{,}\PY{l+m+mf}{0.07266}\PY{p}{,}\PY{l+m+mf}{0.101233}\PY{p}{,}\PY{l+m+mf}{0.131885}\PY{p}{]}\PY{p}{,}
                 \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.0317}\PY{p}{,}\PY{l+m+mf}{0.0655}\PY{p}{,}\PY{l+m+mf}{0.1022}\PY{p}{,}\PY{l+m+mf}{0.142}\PY{p}{,}\PY{l+m+mf}{0.1752}\PY{p}{]}\PY{p}{,}
                 \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.035}\PY{p}{,}\PY{l+m+mf}{0.075}\PY{p}{,}\PY{l+m+mf}{0.121}\PY{p}{,}\PY{l+m+mf}{0.153}\PY{p}{,}\PY{l+m+mf}{0.205}\PY{p}{]}\PY{p}{,}
                 \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.008}\PY{p}{,}\PY{l+m+mf}{0.013}\PY{p}{,}\PY{l+m+mf}{0.019}\PY{p}{,}\PY{l+m+mf}{0.03}\PY{p}{,}\PY{l+m+mf}{0.05}\PY{p}{]}\PY{p}{]}

\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{mvnorm} \PY{o}{=} \PY{n}{multivariate\PYZus{}normal}\PY{p}{(}\PY{n}{mean}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]} \PY{p}{,} \PY{n}{cov}\PY{o}{=}\PY{p}{[}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+m+mf}{0.7}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{]}\PY{p}{,}
                                                      \PY{p}{[}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{,} \PY{l+m+mf}{0.25}\PY{p}{]}\PY{p}{,}
                                                      \PY{p}{[}\PY{l+m+mf}{0.7}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{]}\PY{p}{,}
                                                      \PY{p}{[}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{l+m+mf}{0.25}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}

\PY{n}{tot} \PY{o}{=} \PY{l+m+mi}{1000000}
\PY{n}{x} \PY{o}{=} \PY{n}{mvnorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{n}{size}\PY{o}{=}\PY{n}{tot}\PY{p}{)}
\PY{n}{x\PYZus{}unif} \PY{o}{=} \PY{n}{norm}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{n}{x}\PY{p}{)}

\PY{n}{succ} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{,} 
        \PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{,} 
        \PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{,} 
        \PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{,} 
        \PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{,} 
        \PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{]}

\PY{n}{nth\PYZus{}default} \PY{o}{=} \PY{l+m+mi}{1}

\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{tot}\PY{p}{)}\PY{p}{:}
    \PY{n}{x\PYZus{}s} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
    \PY{k}{for} \PY{n}{c} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{x\PYZus{}s}\PY{p}{[}\PY{n}{nth\PYZus{}default}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{==} \PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{c}\PY{p}{]}\PY{p}{:}
            \PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{:}
                \PY{n}{temp} \PY{o}{=} \PY{k+kc}{True}
                \PY{k}{if} \PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{c}\PY{p}{]} \PY{o}{\PYZlt{}} \PY{n}{default\PYZus{}rates}\PY{p}{[}\PY{n}{c}\PY{p}{]}\PY{p}{[}\PY{n}{y}\PY{p}{]}\PY{p}{:}
                    \PY{n}{succ}\PY{p}{[}\PY{n}{y}\PY{p}{]}\PY{p}{[}\PY{n}{c}\PY{p}{]} \PY{o}{+}\PY{o}{=} \PY{l+m+mf}{1.}

\PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{:}
     \PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{succ}\PY{p}{[}\PY{n}{y}\PY{p}{]}\PY{p}{)} \PY{o}{/} \PY{n+nb}{float}\PY{p}{(}\PY{n}{tot}\PY{p}{)}\PY{p}{)}\PY{p}{,}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
0.0
0.076723
0.145731
0.213026
0.274272
0.342925
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{default\PYZus{}rates} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.022032}\PY{p}{,}\PY{l+m+mf}{0.046242}\PY{p}{,}\PY{l+m+mf}{0.07266}\PY{p}{,}\PY{l+m+mf}{0.101233}\PY{p}{,}\PY{l+m+mf}{0.131885}\PY{p}{]}\PY{p}{,}
                 \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.0317}\PY{p}{,}\PY{l+m+mf}{0.0655}\PY{p}{,}\PY{l+m+mf}{0.1022}\PY{p}{,}\PY{l+m+mf}{0.142}\PY{p}{,}\PY{l+m+mf}{0.1752}\PY{p}{]}\PY{p}{,}
                 \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.035}\PY{p}{,}\PY{l+m+mf}{0.075}\PY{p}{,}\PY{l+m+mf}{0.121}\PY{p}{,}\PY{l+m+mf}{0.153}\PY{p}{,}\PY{l+m+mf}{0.205}\PY{p}{]}\PY{p}{,}
                 \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.008}\PY{p}{,}\PY{l+m+mf}{0.013}\PY{p}{,}\PY{l+m+mf}{0.019}\PY{p}{,}\PY{l+m+mf}{0.03}\PY{p}{,}\PY{l+m+mf}{0.05}\PY{p}{]}\PY{p}{]}

\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{mvnorm} \PY{o}{=} \PY{n}{multivariate\PYZus{}normal}\PY{p}{(}\PY{n}{mean}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]} \PY{p}{,} \PY{n}{cov}\PY{o}{=}\PY{p}{[}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                                                      \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                                                      \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                                                      \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}

\PY{n}{tot} \PY{o}{=} \PY{l+m+mi}{1000000}
\PY{n}{x} \PY{o}{=} \PY{n}{mvnorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{n}{size}\PY{o}{=}\PY{n}{tot}\PY{p}{)}
\PY{n}{x\PYZus{}unif} \PY{o}{=} \PY{n}{norm}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{n}{x}\PY{p}{)}

\PY{n}{succ} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{,} 
        \PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{,} 
        \PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{,} 
        \PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{,} 
        \PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{,} 
        \PY{p}{[}\PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{,} \PY{l+m+mf}{0.}\PY{p}{]}\PY{p}{]}

\PY{n}{nth\PYZus{}default} \PY{o}{=} \PY{l+m+mi}{1}

\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{tot}\PY{p}{)}\PY{p}{:}
    \PY{n}{x\PYZus{}s} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
    \PY{k}{for} \PY{n}{c} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{:}
        \PY{k}{if} \PY{n}{x\PYZus{}s}\PY{p}{[}\PY{n}{nth\PYZus{}default}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{==} \PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{c}\PY{p}{]}\PY{p}{:}
            \PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{:}
                \PY{n}{temp} \PY{o}{=} \PY{k+kc}{True}
                \PY{k}{if} \PY{n}{x\PYZus{}unif}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{c}\PY{p}{]} \PY{o}{\PYZlt{}} \PY{n}{default\PYZus{}rates}\PY{p}{[}\PY{n}{c}\PY{p}{]}\PY{p}{[}\PY{n}{y}\PY{p}{]}\PY{p}{:}
                    \PY{n}{succ}\PY{p}{[}\PY{n}{y}\PY{p}{]}\PY{p}{[}\PY{n}{c}\PY{p}{]} \PY{o}{+}\PY{o}{=} \PY{l+m+mf}{1.}

\PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{:}
     \PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{succ}\PY{p}{[}\PY{n}{y}\PY{p}{]}\PY{p}{)} \PY{o}{/} \PY{n+nb}{float}\PY{p}{(}\PY{n}{tot}\PY{p}{)}\PY{p}{)}\PY{p}{,}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
0.0
0.092454
0.182155
0.271455
0.35076
0.437701
    \end{Verbatim}

    \hypertarget{collateralized-debt-obligation}{%
\subsubsection{Collateralized Debt
Obligation}\label{collateralized-debt-obligation}}

A collateralized debt obligation (CDO) is a security backed by a
diversified pool of one or more kinds of debt obligations such as bonds,
loans, credit default swaps or structured products (mortgage-backed
securities, asset-backed securities, and even other CDOs). A CDO can be
initiated by one or more of the following: banks, nonbank financial
institutions, and asset management companies, is referred to as the
sponsor. The sponsor of a CDO creates a company so-called the special
purpose vehicle (SPV). The SPV works as an independent entity. In this
way, CDO investors are isolated from the credit risk of the sponsor.
Moreover, the SPV is responsible for the administration. The SPV obtains
the credit risk exposure by purchasing debt obligations (bonds or
residential and commercial loans) or selling CDSs; it transfers the
credit risk by issuing debt obligations (tranches/credit-linked notes).
The investors in the tranches of a CDO have the ultimate credit risk
exposure to the underlying reference entities. The SPV issues four kinds
of tranches. Each tranche has an attachment percentage and a detachment
percentage. When the cumulative percentage loss of the portfolio reaches
the attachment percentage, investors in the tranche start to lose their
principal, and when the cumulative percentage loss of principal reaches
the detachment percentage, the investors in the tranche lose all their
principal and no further loss can occur to them.

In the literature, tranches of a CDO are classified as
subordinate/equity tranche, mezzanine tranches, and senior tranches
according to their subordinate levels. Because the equity tranche is
extremely risky, the sponsor of a CDO holds the equity tranche and the
SPV sells other tranches to investors.

\hypertarget{role-of-correlation-in-basket-cds-and-cdo}{%
\subsubsection{Role of Correlation in Basket CDS and
CDO}\label{role-of-correlation-in-basket-cds-and-cdo}}

The cost of protection in a nth-to-default CDS or a trancehe of a CDO is
critically dependent on default correlation. Suppose that a basket of a
1000 reference entities is used to define a 5-year nth-to-default CDS
and that each reference entity has a probability of 2\% of defaulting
during the 5 years. When the default corralation between the reference
entities is zero the binomial distribution (see
Appendix\textasciitilde{}\ref{appendix1}) shows that the probability of
one or more defaults during the 5 years is 86.7\% and the probability of
10 or more defaults is 0.00034\%. A first-to-default CDS is therefore
quite valuable wereas a 10th-to-default CDS is worth almost nothing.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{binom}

\PY{n}{b} \PY{o}{=} \PY{n}{binom}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mf}{0.02}\PY{p}{)}
\PY{n+nb}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P(x\PYZgt{}=1) : }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{b}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{b}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{P(x\PYZgt{}=10): }\PY{l+s+si}{\PYZob{}:.6f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{b}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{b}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    As the default correlation increases the probability of one or more
defaults declines and the probability of 10 or more defaults increases.
In the limit where the default correlation between the reference
entities is perfect the probability of one or more defaults equals the
probability of ten or more defaults and is 2\%. This is because in this
extreme situation the reference entities are essentially the same:
either they all default (with probability 2\%) or none of them default
(with probability 98\%).

    \hypertarget{standard-market-model}{%
\subsubsection{Standard Market Model}\label{standard-market-model}}

The critical input into pricing CDO tranches or Basket CDS is an
estimate of the default dependence (default correlation) between the
underlying assets.

One popular method for estimating the dependence structure is using
copula functions, a method first applied in actuarial science. While
there are several types of copula function models, the first introduced
was the one-factor Gaussian copula model. These models have the
advantage that can be solved semianalyticly.

Consider a portfolio of \(N\) companies and assume that the marginal
probabilities of default are known for each company. Define:

\begin{itemize}
\tightlist
\item
  \(t_i\), the time of default of the \(i\)th company:
\item
  \(Q_i(t)\), the cumulative probability that company \(i\) will default
  before time \(t\); that is, the probability that \(t_i \le t\);
\item
  \(S_i(t) = 1  Q_i(t)\), the probability that company \(i\) will
  survive beyond time \(t\); that is, the probability that \(t_i > t\).
\end{itemize}

To generate a one-factor model for the \(t_i\) we define random
variables \(x_i\) \((1\le i \le N)\)

\[X_i = a_i M + \sqrt{1-a_i^2 Z_i},\qquad i = 1, 2,\ldots, n\]

where \(M\) and the \(Z_i\) have independent zero-mean unit-variance
distributions and \(1 \le a_i \lt 1\). Equation (1) defines a
correlation structure between the \(x_i\) dependent on a single common
factor \(M\). The correlation between \(x_i\) and \(x_j\) is
\(a_i a_j\). Let \(F_i\) be the cumulative distribution of \(x_i\).
Under the copula model the \(x_i\) are mapped to the \(t_i\) using a
\emph{percentile-to-percentile} transformation. The five-percentile
point in the probability distribution for \(x_i\) is transformed to the
five-percentile point in the probability distribution of \(t_i\); the
ten-percentile point in the probability distribution for \(x_i\) is
transformed to the ten-percentile point in the probability distribution
of \(t_i\); and so on. In general the point \(x_i = x\) is transformed
to \(t_i = t\) where \(t = Q_i^{1}[F_i(x)]\).

Let \(H\) be the cumulative distribution of the \(Z_i\). It follows from
Equation (1) that

\[\mathbb{P}(x_i < x|M) = H\left(\cfrac{x-a_i M}{\sqrt{1-a_i^2}}\right)\]

When \(x = F_i^{1}[Q_i(t)]\),
\(\mathbb{P}(t_i < t) = \mathbb{P}(x_i < x)\). Hence

\[\mathbb{P}(t_i < t|M) = H\left\{\cfrac{F_i^{1}[Q_i(t)]-a_i M}{\sqrt{1-a_i^2}}\right\}\]

The conditional probability that the \(i\)th bond will survive beyond
time T is therefore

\[S_i(T|M) = 1 - H\left\{\cfrac{F_i^{1}[Q_i(t)]-a_i M}{\sqrt{1-a_i^2}}\right\}\]

The model we have presented can be extended to many factors quite easily
but we won't do it in these lectures.

The advantage of the copula model is that it creates a tractable
multivariate joint distribution for a set of variables that is
consistent with known marginal probability distributions for the
variables. One possibility is to let the \(M\)'s and the \(Z\)'s have
standard normal distributions. A Gaussian copula then results. However,
any distributions can be used for \(M\)'s and the \(Z\)'s (providing
they are scaled so that they have zero mean and unit variance). Each
choice of distributions results in a different copula model. The choice
of the copula governs the nature of the default dependence. For example,
as we will see, copulas where the \(M\)'s have heavy tails generate
models where there is a greater likelihood of a clustering of early
defaults for several companies. Later on we will explore the effect of
using normal and t-distributions for the \(M\)'s and \(Z\)'s.

For simplicity, the following two assumptions are made:

\begin{itemize}
\tightlist
\item
  all the companies have the same default intensity, i.e,
  \(\lambda_i = \lambda\);
\item
  the pairwise default correlations are the same, i.e \(a_i = a\).
\end{itemize}

The second assumption means that the contribution of the market
component is the same for all the companies and the correlation between
any two companies is constant, \(\rho = a^2\).

Under these assumptions, given the market situation \(M = m\), all the
companies have the same cumulative default probability
\(D_{t|M}=\mathbb{P}(t_i < t|M)\). Moreover, for a given value of the
market component \(M\), the defaults are mutually independent for all
the underlying companies. Letting \(N_{t|m}\) be the total defaults that
have occurred by time \(t\) conditional on the market condition
\(M = m\), then \(N_{t|m}\) follows a binomial distribution, and

\[\mathbb{P}(N_{t|m} = j) = \cfrac{n!}{j!(n-j)!}D^j_{t|m}(1-D_{t|m})^{n-j},\qquad  j=0, 1, 2,\ldots,n\]
The probability that there will be exactly \(j\) defaults by time \(t\)
is

\[\mathbb{P}(N_{t} = j) = \int_{-\infty}^{\infty}{\mathbb{P}(N_{t|m} = j)f_M(m)dm}\]

where \(f_M(m)\) is the probability density function (PDF) of the random
variable \(M\).

Li (1999, 2000) was the first to suggest that the Gaussian copula could
be employed in credit risk modeling to estimate the correlation default.
In a one-factor Gaussian copula model, the distributions of the common
market component \(M\) and the individual component \(Z_i\) are standard
normal Gaussian distributions. Because the sum of two independent
Gaussian distributions is still a Gaussian distribution, the \(X_i\)
have a standard normal distribution. The one-factor copula Gaussian
copula model under the assumptions outlined above is the \emph{market
standard model}.

    \hypertarget{basket-cds-valuation-under-market-standard-model}{%
\subsubsection{Basket CDS Valuation under Market Standard
Model}\label{basket-cds-valuation-under-market-standard-model}}

Consider a first-to-default basket. If the 1st-to-default probabilities
are known, then the default probability of a basket of entities is
simply the sum of the 1s-to-default probabilities of the individual
entities in the basket. From this one can easily calculate the fair
value of the premium payments of a basket default swap: if the
protection is only for the first entity in the basket only the payoff
value of the 1st defaulted entity needs to be calculated. For an
nth-to-default swap similar arguments also hold.

We now present some numerical results for an nth to default CDS. We
assume that the principals and expected recovery rates are the same for
all underlying reference assets. The valuation procedure is similar to
that for a regular CDS where there is only one reference entity.8 In a
regular CDS the valuation is based on the probability that a default
will occur between times T1 and T2. Here the valuation is based on the
probability that the n th default will occur between times T1 and T2. We
assume the buyer of protection makes quarterly payments in arrears at a
specified rate until the n th default occurs or the end of the life of
the contract is reached. In the event of an n th default occurring the
seller pays the notional principal times 1 -- R. Also, there is a final
accrual payment by the buyer of protection to cover the time elapsed
since the previous payment. The contract can be valued by calculating
the expected present value of payments and the expected present value of
payoffs in a risk-neutral world. The breakeven CDS spread is the one for
which the expected present value of the payments equals the expected
present value of payoffs.9 Consider first a 5-year n th to default CDS
on a basket of 10 reference entities in the situation where the expected
recovery rate, R, is 40\%. The term structure of interest rates is
assumed to be flat at 5\%. The default probabilities for the 10 entities
are generated by Poisson processes with constant default intensities,
i, (1  i  10) so that10

    10 CDS rho = 0.3 R = 40\% rate = 5\% Q(t) = {[}0.02, 0.0396, 0.0588,
0.0776, 0.0961{]}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{47}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{finmarkets} \PY{k}{import} \PY{n}{DiscountCurve}\PY{p}{,} \PY{n}{CreditCurve}\PY{p}{,} \PY{n}{CreditDefaultSwap}
\PY{k+kn}{from} \PY{n+nn}{finmarkets} \PY{k}{import} \PY{n}{GaussianQuadrature}
\PY{k+kn}{from} \PY{n+nn}{datetime} \PY{k}{import} \PY{n}{date}
\PY{k+kn}{from} \PY{n+nn}{dateutil}\PY{n+nn}{.}\PY{n+nn}{relativedelta} \PY{k}{import} \PY{n}{relativedelta}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{norm}\PY{p}{,} \PY{n}{binom}
\PY{k+kn}{from} \PY{n+nn}{math} \PY{k}{import} \PY{n}{sqrt}\PY{p}{,} \PY{n}{exp}

\PY{n}{n\PYZus{}cds} \PY{o}{=} \PY{l+m+mi}{10}
\PY{n}{rho} \PY{o}{=} \PY{l+m+mf}{0.6}
\PY{n}{l} \PY{o}{=} \PY{l+m+mf}{0.01}
\PY{n}{pillar\PYZus{}dates} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{df} \PY{o}{=} \PY{p}{[}\PY{p}{]}
\PY{n}{today} \PY{o}{=} \PY{n}{date}\PY{o}{.}\PY{n}{today}\PY{p}{(}\PY{p}{)}
\PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{:}
    \PY{n}{pillar\PYZus{}dates}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{today} \PY{o}{+} \PY{n}{relativedelta}\PY{p}{(}\PY{n}{years}\PY{o}{=}\PY{n}{i}\PY{p}{)}\PY{p}{)}
    \PY{n}{df}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{/}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{+}\PY{l+m+mf}{0.05}\PY{o}{*}\PY{n}{i}\PY{p}{)}\PY{p}{)}
\PY{n}{dc} \PY{o}{=} \PY{n}{DiscountCurve}\PY{p}{(}\PY{n}{today}\PY{p}{,} \PY{n}{pillar\PYZus{}dates}\PY{p}{,} \PY{n}{df}\PY{p}{)}
\PY{n}{gq} \PY{o}{=} \PY{n}{GaussianQuadrature}\PY{p}{(}\PY{p}{)}
\PY{n}{Q} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{exp}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{l}\PY{o}{*}\PY{n}{t}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{t} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{]}
\PY{c+c1}{\PYZsh{}Q = [0, 0.02, 0.0396, 0.0588, 0.0776, 0.0961]}
\PY{n}{values}\PY{p}{,} \PY{n}{weights} \PY{o}{=} \PY{n}{gq}\PY{o}{.}\PY{n}{M}\PY{p}{(}\PY{l+m+mi}{60}\PY{p}{)}
\PY{n}{cds} \PY{o}{=} \PY{n}{CreditDefaultSwap}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{today}\PY{p}{,} \PY{l+m+mf}{0.01}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}

\PY{k}{for} \PY{n}{ndefault} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{11}\PY{p}{)}\PY{p}{:}
    \PY{n}{S} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    
    \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{values}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{n}{temp} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{:}
            \PY{n}{P} \PY{o}{=} \PY{n}{norm}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{p}{(}\PY{n}{norm}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{n}{Q}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{sqrt}\PY{p}{(}\PY{n}{rho}\PY{p}{)}\PY{o}{*}\PY{n}{values}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{)}\PY{o}{/}
                         \PY{p}{(}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{rho}\PY{p}{)}\PY{p}{)}\PY{p}{)}
            \PY{n}{b} \PY{o}{=} \PY{n}{binom}\PY{p}{(}\PY{n}{n\PYZus{}cds}\PY{p}{,} \PY{n}{P}\PY{p}{)}
            \PY{n}{temp}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{p}{(}\PY{n}{b}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{n}{n\PYZus{}cds}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{b}\PY{o}{.}\PY{n}{cdf}\PY{p}{(}\PY{n}{ndefault}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        \PY{n}{S}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{temp}\PY{p}{)}
    
    \PY{n}{s} \PY{o}{=} \PY{l+m+mi}{0}
    \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{values}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{n}{s} \PY{o}{+}\PY{o}{=} \PY{n}{weights}\PY{p}{[}\PY{n}{j}\PY{p}{]} \PY{o}{*} \PY{n}{cds}\PY{o}{.}\PY{n}{breakevenRate}\PY{p}{(}\PY{n}{dc}\PY{p}{,} 
                                            \PY{n}{CreditCurve}\PY{p}{(}\PY{n}{pillar\PYZus{}dates}\PY{p}{,} 
                                                        \PY{n}{S}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{)}\PY{p}{)}

    \PY{n+nb}{print} \PY{p}{(}\PY{n}{s}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
0.03214370055078652
0.015337587442302281
0.00725616955902986
0.004215577657531996
0.0022014564160901615
0.001225042309192564
0.0006383163501547495
0.0003071509287843383
0.00012742929384463388
3.669614592811156e-05
    \end{Verbatim}

    \begin{verbatim}
0   0.3 0.6
\end{verbatim}

1 153 181 321 2 25 51 153 3 3 18 73 4 0 7 42 5 0 3 22 6 0 0 12 7 0 0 6 8
0 0 3 9 0 0 1 10 0 0 0

\begin{verbatim}
0.01    0.02    0.03
\end{verbatim}

1 181 393 627 2 51 136 238 3 18 57 109 4 7 25 52 5 3 11 25 6 0 5 12 7 0
2 5 8 0 0 2 9 0 0 0 10 0 0 0

    \hypertarget{valuation-of-cdo}{%
\subsubsection{Valuation of CDO}\label{valuation-of-cdo}}

Suppose that the payment date on a CDO tranche are at times \(\tau_i\).
Define \(\mathbb{E}_j\) the expected tranche principal at time \(\tau\)
and \(D(\tau)\) the discount factor at time \(\tau\). Suppose also that
the spread on a particular tranche (i.e.~the number of basis point paid
for protection on the remaining tranche principal) is \(s\).

The present value of the expected regular spread payments on the CDO is
given by \begin{equation}
s\cdot A = s\cdot \sum_{j=1}^{m}(\tau_j - \tau_{j-1})\mathbb{E}_{j}D(\tau_j)
\label{eq:A}
\end{equation} The expected loss between times \(\tau_{j-1}\) and
\(\tau_j\) is \(\mathbb{E}_{j-1}-\mathbb{E}_j\). For simplicity assume
the loss occurs only at the midpoint of the time interval, so the
present value of the expected payoffs on the CDO tranche is
\begin{equation}
C=\sum_{j=1}^{m}(\mathbb{E}_{j-1}-\mathbb{E}_j)D\left(\frac{\tau_{j-1}+\tau_j}{2}\right)
\label{eq:C}
\end{equation} The accrual payment due on the losses is finally given by
\begin{equation}
s\cdot B = s\cdot\sum_{j=1}^{m}\frac{1}{2}(\tau_j - \tau_{j-1})(\mathbb{E}_{j-1}-\mathbb{E}_j)D(\frac{\tau_{j-1}+\tau_j}{2})
\label{eq:B}
\end{equation}

The value of the tranche, valued from the point of view of the
protection buyer is \(C-sA-sB\). The breakeven spread on the tranche
occurs when the present value of the payments equals the present value
of the payoffs so

\[ s = \cfrac{C}{A+B}\]

Suppose that the tranche under consideration covers losses on the
portfolio between \(\alpha_L\) and \(\alpha_H\) and define

\[n_L = \cfrac{\alpha_L n}{1-R}\qquad \mathrm{and}\qquad n_H = \cfrac{\alpha_H n}{1-R}\]
where \(R\) is the recovery rate. Finally define \(m(x)\) as the
smallest integer greater than \(x\). By definition the tranche principal
stays \(N\) while the number of defaults \(k\) is less than \(m(n_L)\),
it is zero when the number of default is greater or equal to \(m(n_H)\),
otherwise is

\[\cfrac{\alpha_H -k(1-R)/n}{\alpha_H - \alpha_L}\]

The expected tranche principal at time \(\tau_j\) conditional of the
value of the factor \(M\) is \[\begin{equation}
\mathbb{E}_j(M) = \sum_{k=0}^{m(n_L)-1}\mathbb{P}(k, \tau_j|M) + \sum_{k=m(n_L)}^{m(n_H)-1}\mathbb{P}(k, \tau_j|M) \cfrac{\alpha_H -k(1-R)/n}{\alpha_H - \alpha_L}
\label{eq:E}
\end{equation}
\]

To compute the breakeven spread it is necessary to substitute
Eq.\textasciitilde{}\ref{eq:E} into
Eq.\textsubscript{\ref{eq:A},}\ref{eq:B} and\textasciitilde{}\ref{eq:C}
and we need to integrate the result over the variable \(M\) (remember
that has a standard normal distribution). The integration is quite
complicated and is best accomplished with a technique called
\emph{Gaussian quadrature} which exploits the approximation

\[\int_{-\infty}^{\infty}{\cfrac{1}{\sqrt{2}}e^{-M^{2}/2}g(M)dM} \approx \sum_{k=1}^{k=L}w_k g(F_k)\]
as \(L\) increases, accuracy increases.

    \hypertarget{complex-correlation-structures-and-the-financial-crisis}{%
\subsection{Complex Correlation Structures and the Financial
Crisis}\label{complex-correlation-structures-and-the-financial-crisis}}

In the example above we have used the multivariate normal which gave
rise to the Gaussian copula.However, we can use other and more complex
copulas as well. For example we might want to assume the correlation is
non-symmetruc which is useful in quant finance where correlations become
very strong during market crashes and returns very negative.

Infact, Gaussian copulas are said to have played a key role in the 2008
financial crisis as tail-correlations were severely underestimated.
Consider a set of mortgages in CDOs (a particular kind of contract that
we are going to see) they are clearly correlated, if one mortgage fails,
the likelihood that another failing is increased. In the early 2000s,
the banks only knew how to model the marginals of the default rates. An
(in)famous paper by Li then suggested to use copulas to model the
correlations between those marginals. Rating agencies relied on thid
model so heaviy, severely underestimating risk and giving false
ratings\ldots{}

If you are interested in the argument read
\href{http://samueldwatts.com/wp-content/uploads/2016/08/Watts-Gaussian-Copula_Financial_Crisis.pdf}{this paper}
for an excellent description of Gaussian copulas and the Financial
Crisis which argues that different copula choices would not have made a
difference but instead the assumed correlation was way too low.


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
