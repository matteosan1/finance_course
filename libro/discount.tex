\chapter{Interpolation, Discount Factors and Forward Rates}
\label{interpolation}

In this Chapter we will start to see some applications of \texttt{python} to financial calculations.
In particular discount curves and forward rates will be involved, and the first utilities that will be added to financial module developed throughout this course will be implemented.
In doing so we will review a widely used mathematical tool: \emph{interpolation}.

\section{Discounting}
\label{discount-factors}

\subsection{Time Value of Money}
Imagine a bank that offers a guaranteed return of 10\% on whichever amount of money a client put in her account as long as that amount stays in the account for one full year (no withdrawals possible). If the client knows that would need \$11000 at the end of one year, how much money does she need to put in today so that the $X$ amount (principal) at the claimed 10\% a year interest rate will grow to \$11000 at the end of year one ?

We know that at 10\%, $X$ dollar today grows to

\begin{equation}
X * (1 + 0.1) = Y
\end{equation}
so the needed investment $X$ can be found by inverting the previous formula:

\begin{equation*}
X \cdot (1 + 10\%) = 11000 \implies X = \cfrac{11000}{(1 + 10\%)}
\end{equation*}

\begin{ipython}
11000 / (1 + 0.1)
\end{ipython}
\begin{ioutput}
10000
\end{ioutput}

What this says is that to have \$11000 in one year from now, the client needs to invest \$10000 at an interest rate of 10\% today.
What about 11000 dollars two years from now ? Taking the approach used above

\begin{equation*}
	X = \cfrac{11000}{\left((1 + 10\%) \cdot (1 + 10\%)\right)} =  \cfrac{11000}{(1+10\%)^ 2}
\end{equation*}

\begin{ipython}
11000 / (1 + 0.1)**2
\end{ipython}
\begin{ioutput}
9090.90909090909
\end{ioutput}

Which means the \$11000 we need two years from now are valued about 9090 dollars today.

What we have just done above is called \emph{discounting}. We are adjusting (i.e. discounting) the value of a payment that will be received at a point in future. Therefore, we are discounting back a future value to bring it to its present value (PV or NPV). The rate used to adjust the future payment is called the \emph{discount rate}.

The idea behind discounting is also known as \emph{time value of money}. Since a dollar at a fixed interest rate will grow in any bank account at that certain rate, if it is invested in an alternative opportunity, it should at least earn that same rate  to even consider the alternative worth thinking about. 

In practice discounting adjusts future payments, investment returns and even return of principal on this basis. The bottom line is that if you fail to earn the discount rate, you have actually lost money, since any bank, would at least have given you the discount rate as return for depositing your money with them. Anything less than that would mean that you have not put your money to its best use.

When we calculate the value of future payments today, we are doing a present value calculation. When we calculate the value of anything in the future we do a \emph{future value} calculation.

A positive NPV denotes that at a certain cost of capital the returns or inflows from an investment opportunity outweigh the outflows or costs of investment, and vice versa. Obviously, when comparing various alternatives available for investment, the option with the most positive NPV or least negative NPV will be favoured or chosen. 

As an example imagine that you have the chance to invest in a project, that will pay \$100 in year 1, and \$200 in year 2. How much are you willing to pay for this opportunity ? (assume an annual discount rate of 10\%).

The answer to the question is that you will be willing to pay at most an amount that is equal to the present value of this stream of payments. To calculate it you need to scale each payment by its respective discount factors ($D(0, T)$ discount factor for year $T$)
\begin{equation}
D(0, T) = \cfrac{1}{(1 + r)^T}
\label{eq:discount_factor}
\end{equation}

\begin{ipython}
d1 = 1/(1 + 0.1)**1
d2 = 1/(1 + 0.1)**2

print ("discount factor for year 1: {:.2f}".format(d1))
print ("discount factor for year 2: {:.2f}".format(d2))

pv = 100*d1 + 200*d2

print ("Total PV: {:.2f}".format(pv))
\end{ipython}
\begin{ioutput}
discount factor for year 1: 0.91
discount factor for year 2: 0.83
Total PV: 256.20
\end{ioutput}
\noindent
Hence, you would be willing to pay \$256.2 for this opportunity.

%If there are $Y$ payments each year the discount factor formula becomes
%
%\begin{equation}
%D(0, T) = \left(1+\cfrac{r}{Y}\right)^{-T}
%\end{equation}
%\noindent
When the continuously-compounded hypothesis is used instead the discount factor becomes

\begin{equation}
D(0, T) = e^{-rT}
\end{equation}

\section{Linear Interpolation}
\label{linear-interpolation}

Consider to have few data points, obtained by sampling or experimenting. These points represent the values of a not well known function \(f(x)\), where \(x\) is an independent variable (e.g. in recording a trip: distances at certain times, \(d = f(t)\)).

It may be necessary to estimate values of the function $f$ at particular $x$ for which samples are not available. Interpolation is a method of "constructing" these "new points" within the range of known data.

Let's clarify the technique with an example.
Assume you are going on holidays by car and that luckily there isn't much traffic so that you can drive at constant speed (which gives a linear relation between traveled space and time i.e.~\(s = v \cdot t\). This means that if you plot the distances \(s\) as a function of the time \(t\) you get a line with slope \(v\)), see Fig.~\ref{fig:samples_for_interpolation}.

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{figures/interp_example1.png}
  \caption{An example of sampling of traveled distances at some time (black points). The blue and red crosses show an interpolated and an extrapolated point. It is clear how the extrapolation failed since after 150 minutes the relation between time and space changed.}
  \label{fig:samples_for_interpolation}
\end{figure}

Given two samples of the traveled distance \(s_1\) and \(s_2\) taken at two different times \(t_1\) and \(t_2\) you can linearly interpolate to find the distance at an intermediate time using the following relations:

\begin{equation}
s = (1 - w)\cdot s_1 + w \cdot s_2
\end{equation}
where $t$ is a generic time at which we want to know the distance $s$ and \(w = \cfrac{t - t_1}{t_2 - t_1}\).

\begin{attention}
\subsubsection{Derivation}
The equation of a line for two points \((t_1, s_1)\) and \((t_2, s_2)\) can be written as:

\begin{equation}
\frac{t - t_1}{t_2 - t_1} = \frac{s - s_1}{s_2 - s_1}
\end{equation}

Setting \(w = \cfrac{t - t_1}{t_2 - t_1}\) and solving for \(s\) we find the desired solution:

\begin{equation}
(s_2 - s_1)\cdot w = s - s_1\quad\implies\quad s = (1 - w)\cdot s_1 + w \cdot s_2
\end{equation}

This formula can also be understood as a weighted average where the weights are inversely related to the distance from the end points to the unknown point ($w_1 = (1 - w) = \cfrac{t_2 - t}{t_2 -t_1}, w_2 = w$), which means that the closer point has more "influence" than the farther point.
\end{attention}

Back to our example, if
\(s_1 = 25.75~\mathrm{km}\;(@t_1 = 15~\mathrm{min})\) and \(s_2 = 171.7~\mathrm{km}\;(@t_2 = 100~\mathrm{min})\) let's find distance traveled in 1 hour (interpolation):

\begin{ipython}
s_1 = 25.75 # distance in km
t_1 = 15 	# elapsed time in minutes
s_2 = 171.7
t_2 = 100

t = 60
w = (t - t_1)/(t_2 - t_1)
s = (1 - w)*s_1 + w*s_2
print ("{:.1f} km".format(s))
\end{ipython}
\begin{ioutput}
103.0 km
\end{ioutput}

Always interpret critically your results to guess if they make sense or not and avoid mistakes. In the previous example we certainly expected something between 25.75 and 171.7~km (our range ends) furthermore since we are looking for the distance at a time which is almost halfway the interval, the result will be somehow in the middle, around 98.6~km. This is indeed more or less what we have got.
This simple kind of reasoning should be applied every time you have a result to quickly judge it.

\begin{curiosity}
\subsubsection{Epic Failure}
The Mars Climate Orbiter \emph{was} a 638~kg (1,407~lb), 326.7~M\$ space probe launched by NASA on December 11, 1998 to study the Martian climate, atmosphere, and surface changes. 

On September 15, 1999, the necessary corrections to speed and direction of the probe were computed in order to place the spacecraft at an optimal position for an orbital insertion maneuver that would bring it around Mars at the proper altitude. 
But one week later communication with the spacecraft was permanently lost as it went into Martian orbital insertion. 

A committee of experts was created to investigate the reasons of 
such failure and they found out that the spacecraft encountered Mars at a lower than foreseen altitude causing either its destruction by atmospheric friction or making it bouncing against the atmosphere re-entering heliocentric orbit after leaving Mars.

The primary cause of this discrepancy was found in one piece of software (supplied by Lockheed Martin) that produced results in "Imperial" units,  while a second system (supplied by NASA) expected those results to be in SI units. Specifically, the software calculated the total impulse produced by thruster in \emph{pound-force seconds}. The trajectory calculation software then used these results, expected to be in \emph{newton seconds}, thus incorrect by a factor of 4.45, to update the predicted position of the spacecraft.
	
NASA took the entire responsibility for having vaporized about 300~M\$ in the Martian atmosphere, mainly for failing to make the appropriate checks and tests that would have caught this unit discrepancy~\cite{bib:mars}.	
\end{curiosity}

\subsubsection{Extrapolation}

If we believe the relation between our variables stay the same ($f(t)$ still linear), we can use the same formula to \emph{extrapolate} values \emph{outside} the range of the sample. For example if we keep the same constant velocity in our trip we could check the distance traveled after 3 hours:

\begin{ipython}
t = 180
w = (t - t_1)/(t_2 - t_1)
s = (1 - w)*s_1 + w*s_2
print ("{:.1f} km".format(s))
\end{ipython}
\begin{ioutput}
309.1 km
\end{ioutput}

In the given example the extrapolation failed since after minute 150 the traveled space ceased to be a linear function of time.

\subsection{Log-linear Interpolation}
\label{log-linear-interpolation}
When the function $f$ that we want to interpolate is an exponential we can fall back to the previous case by a simple variable transformation. 
Assume the following is the relationship between $p$ and $h$, two generic variables:

\begin{equation}
p = \mathrm{exp}(c \cdot h)
\end{equation}
Applying the logarithm to both sides of the equation gives:

\begin{equation}
s = \mathrm{log}(p) = \mathrm{log}(\mathrm{exp}(c \cdot h)) = c \cdot h
\end{equation}
so there is linear relation between the new variable $s$ and $h$. At this point we can use the results of the previous Section to interpolate for values of $s$, just remember to exponentiate the final result to get the correct $p$. In formulas:

\begin{align}
\label{eq:log_interp}
\begin{gathered}
w = \frac{h - h_1}{h_2 - h_1} \\
s = (1 - w)\cdot s_1 + w \cdot s_2\qquad (\textrm{now } s = \textrm{log}(p))\\
p = \textrm{exp}(s)
\end{gathered}
\end{align}

Let's see an example. Atmospheric pressure decreases with the altitude (i.e. the highest you flight the lower is the pressure) following an exponential law:

\begin{equation}
p = p_0\cdot e^{-\alpha h}
\end{equation}
where
\begin{itemize}
\tightlist
\item
  \(h\) is the altitude
\item
  \(p_0\) is the pressure at sea level
\item
  \(\alpha\) is a constant
\end{itemize}

Taking the logarithm of each side of the equation we get a linear relation which can be interpolated as seen before:

\begin{equation}
s = \mathrm{log}(p) = \mathrm{log}(p_0\cdot e^{-\alpha h})\propto - \alpha \cdot h
\end{equation}

Now assume that we have measured
\(p_1 = 90~\mathrm{kPa}\;(h_1 = 1000~\mathrm{m})\) and
\(p_2 = 40~\mathrm{kPa}\;(h_1 = 7000~\mathrm{m})\) what will be the atmospheric pressure on top of Mont Blanc (\(4812~\mathrm{m}\)) ? and on top of Mount Everest (\(8848~\mathrm{m}\)) ?

\begin{ipython}
# pressure on top of the Mont Blanc (interpolation)
from math import log, exp

# first we take the logarithm of our measurements to use the linear
# relation to interpolate
h_1 = 1000 # height in meters
s_1 = log(90) # logarithm of the pressure at heigth h1
h_2 = 7000 # height in meters
s_2 = log(40) # logarithm of the pressure at heigth h2

h = 4812
w = (h - h_1)/(h_2 - h_1)
s = (1 - w)*s_1 + w*s_2
print ("{:.1f} kPa".format(exp(s)))
\end{ipython}
\begin{ioutput}
53.8 kPa
\end{ioutput}

\begin{ipython}
h = 8848
w = (h - h_1)/(h_2 - h_1)
s = (1 - w)*s_1 + w*s_2

print ("{:.1f} kPa".format(exp(s)))
\end{ipython}
\begin{ioutput}
31.2 kPa
\end{ioutput}

In this case we check our results by plotting the found pressures on top of the $P$ vs $h$ plot shown on Wikipedia, see Fig~\ref{fig:Pvsh}.

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{figures/Atmospheric_Pressure_vs._Altitude.png}
\caption{Atmospheric pressure versus altitude (Wikipedia). Green points represent our measurements, red points represent interpolation/extrapolation.}
\label{fig:Pvsh}
\end{figure}

\subsection{Limitations of Interpolation}
Interpolation is just an approximation and works well when either the function $f$ is linear or we are trying to interpolate between two points that are close enough to believe that $f$ is almost linear in that interval.

It can be easily demonstrated that the linear approximation between two points of a given function $f(x)$ gets worse with the second derivative of the function that is approximated ($f''(x)$). This is intuitively correct: the "curvier" the function is, the worse the approximation made with simple linear interpolation becomes, see Fig.~\ref{fig:sine_interp} where we try to interpolate a sine function.

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{figures/wrong_interp.png}
  \caption{Trying to approximate a sine function with a line is clearly not going to work unless the interpolation interval is very small.}
  \label{fig:sine_interp}
\end{figure}

To improve the approximation accuracy with complicated curves a polynomial of higher order can be used ($ùëù(ùë•)=ùëé_0 + ùëé_1 ùë•+ ùëé_2 ùë•^2+\cdots$), for example in the evaluation of natural logarithm or trigonometric functions. It has to be clear however that going to higher degrees does not always help~\cite{bib:runge}.

\section{Discount Curve Interpolation}
\label{discount-curve-interpolation}
With $D(T)$ (or $D(0,T)$) it is represented the discount factor for a zero-rate (also called spot rate) $r$, and a time to cash flow $T$ (in years).

Discount factors are usually presented as curves (\emph{discount curves}) where each point represents a discount factor relative to a future date. Figure~\ref{fig:example_discount_curve} shows an example of discount curve.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/discount_curve}
	\caption{Example of discount curve.}
	\label{fig:example_discount_curve}
\end{figure}

Since discount curves are made of a discrete set of discount factors derived at some dates, we may need to find the factor at some different time; this is a typical financial application of interpolation.

To develop some \texttt{python} code which interpolates a discount curve the following inputs are needed:

\begin{itemize}
\tightlist
\item a list of pillars dates specifying the value dates of the given discount factors, \(t_0,...,t_{n-1}\);
\item a list of given discount factors, \(D(t_0),...,D(t_{n-1})\);
\item a pricing date (`today') which corresponds to \(t=0\).
\end{itemize}

The input argument to the function will be the value date at which we want to interpolate the discount factor. Since the discount factor can be expressed as an exponential the log-linear interpolation can be used:

\begin{equation}
\begin{gathered}
d(t_i)=\mathrm{ln}(D(t_i))\\
d(t) = (1-w)d(t_i) + wd(t_{i+1});\quad w=\frac{t-t_i}{t_{i+1}-t_i}\\
D(t) = \mathrm{exp}(d(t))
\end{gathered}
\end{equation}
where \(i\) is such that \(t_i \le t \le t_{i+1}\)

Instead of reinventing the wheel and performing the interpolation with homemade code the function \texttt{numpy.interp} is used. 
Say we want to interpolate the points at $x = 2.5$ given the following values:

\begin{ipython}
import numpy as np

xp = [0, 1, 5]
fp = [0, 2, 4]
np.interp(2.5, xp, fp)
\end{ipython}
\begin{ioutput}
2.75
\end{ioutput}

Since discount factors are an essential part for every financial calculation and we will keep using them everywhere, a \texttt{python} class which manages discount factors and curves is develop, using an object oriented approach.
This class, that we name \texttt{DiscountCurve}, should have: as attributes the pillar dates with the corresponding discount factors and at least a method to interpolate discount factors.

When dealing with discount factors we need to be careful though. \texttt{numpy.interp} only accepts numbers or a list of numbers as argument (i.e. it doesn't automatically convert or interpret dates as numbers and doesn't know how to interpolate them). So we need to do the conversion ourselves before passing any date to the interpolation function. This transformation will be implemented directly in the constructor of the class by replacing each date with the number of days from a reference date ($t_0$).

Furthermore we also attempted a simple optimization of the code: in the constructor we are going to compute also the logarithm of the input discount factors, so that we can save some computation time with respect to doing the log at every call of the interpolation method. 

\begin{ipython}
import math
import numpy as np
from datetime import date

class DiscountCurve:
    def __init__(self, pillar_dates, discount_factors):
        self.today = pillar?dates[0]
        self.discount_factors = discount_factors
        self.log_dfs = [math.log(discount_factor) \
            for discount_factor in self.discount_factors]
        self.pillar_days = [(pillar_date - self.today).days \
            for pillar_date in self.pillar_dates]

    def df(self, d):
        d_days = (d - self.today).days
        interp_log_df = \
            np.interp(d_days, self.pillar_days, self.log_dfs)
        return math.exp(interp_log_df)
\end{ipython}

\begin{finmarkets}
This class is going to be the first step in the creation of a \texttt{python} financial library, so copy the code into a separate file called \texttt{finmarkets.py} so that you can later reuse it. Also be sure that the code is well documented in its part.	
\end{finmarkets}

Assume we have three discount factors, we can now use our new class to create the corresponding discount curve. Then the \texttt{df} method provides discount factors on every date within the interval of the given pillar dates.

\begin{ipython}
from datetime import date
from finmarkets import DiscountCurve

today_date = date(2019, 10, 1)
pillar_dates = [today_date, date(2020, 10, 1), date(2021, 10, 1)]
discount_factors = [1.0, 0.97, 0.72]
curve = DiscountCurve(pillar_dates, discount_factors)

d0 = date(2020, 1, 1)
df0 = curve.df(d0)
print (df0)
\end{ipython}
\begin{ioutput}
0.9923728228571693
\end{ioutput}

\begin{ipython}
d1 = date(2021, 1, 1)
df1 = curve.df(d1)
print (df1)
\end{ipython}
\begin{ioutput}
0.8997999273630835
\end{ioutput}

A very useful way to check the correctness of a result is by plotting it. So let's see what this looks like when plotted on a semi-log graph and if it makes sense, Fig.~\ref{fig:log_discount_curve}.

\begin{ipython}
from matplotlib import pyplot as plt
import matplotlib.dates as mdates
plt.plot(pillar_dates, discount_factors, marker='o')
plt.plot(d0, df0, marker='X')
plt.plot(d1, df1, marker='X')
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))
plt.gca().xaxis.set_major_locator(mdates.YearLocator())
plt.grid(True)
plt.yscale("log")
plt.show()
\end{ipython}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/log_discount_curve}
	\caption{Plot of the discount curve defined in the text and of the two computed discount factors with semi-log scale.}
	\label{fig:log_discount_curve}
\end{figure}
\noindent
Let's see what it looks like when plotted on a linear graph too, Fig.~\ref{fig:linear_discount_curve}.
\begin{ipython}
plt.plot(pillar_dates, discount_factors, marker='o')
plt.plot(d0, df0, marker='X')
plt.plot(d1, df1, marker='X')
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))
plt.gca().xaxis.set_major_locator(mdates.YearLocator())
plt.grid(True)
plt.show()
\end{ipython}

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/linear_discount_curve}
	\caption{Plot of the discount curve defined in the text and of the two computed
		discount factors with linear scale.}
	\label{fig:linear_discount_curve}
\end{figure}
\noindent
Discrepancies in the linear plot are most likely due to rounding.

\section{Forward Rates}
\label{calculating-forward-rates}
A forward rate is an interest rate applicable to a financial transaction that will take place in the future. It can be considered as the market's expectation for future prices and can serve as an indicator of how it believes will perform.

Contrary the \emph{spot rate} is used by buyers and sellers looking to make an immediate purchase or sale, and it cannot be an indicator of market expectations.

Forward rates are calculated from the spot rate by exploiting the no arbitrage condition which states that investing at rate \(r_1\) for the period \((0, T_1)\) and then \emph{re-investing} at rate \(r_{1,2}\) for the time period \((T_1, T_2)\) is equivalent to invest at rate \(r_2\) for the full time period \((0, T_2)\). Essentially two investors shouldn't be able to earn money from arbitraging between different interest periods. That said:

\begin{equation}
(1+r_1 T_1)(1+r_{1,2}(T_2 - T_1)) = 1 + r_2 T_2
\label{eq:no_arbitrage_r}
\end{equation}
Solving for \(r_{1,2}\) leads to

\begin{equation}
F(T_1, T_2) = r_{1,2} = \frac{1}{T_2 - T_1}\Big(\frac{1+r_2 T_2}{1+r_1 T_1} - 1 \Big)
\label{eq:forward_rate_simple}
\end{equation}
\vspace{1cm}
The same expression in terms of the discount factor of Eq.~\ref{eq:discount_factor} becomes
\begin{equation}
F(T_1, T_2) = \frac{1}{T_2 - T_1}\Big(\frac{D(0, T_1)}{D(0, T_2)} - 1 \Big)
\end{equation}
Considering continuously compounded rates instead Eq.~\ref{eq:no_arbitrage_r} can be written as
\begin{equation*}
e^{{(r}_{2}T_{2})}=e^{{(r}_{1}T_{1})}\cdot \ e^{\left(r_{1,2} \left(T_{2}-T_{1}\right)\right)}
\end{equation*}
and the corresponding expression for the forward rate is
\begin{equation}
F(T_1, T_2) = r_{1,2} = \frac {1}{T_{2}-T_{1}}(\ln D(0,T_{1})-\ln D(0,T_{2}))
\quad(\textrm{since now } D(0, T_i)=e^{-r_i T_i})
\label{eq:forward_rate_continous}
\end{equation}

\begin{finmarkets}
We now write a \texttt{ForwardRateCurve} class which, given a set of spot rates, computes forward rates at any arbitrary date. This class has just a method to actually compute the forward rates. Also it goes into the \texttt{finmarkets} module and will be used to define LIBOR curves needed in the rest of these Lectures.
\end{finmarkets}

\begin{ipython}
import numpy as np
from math import log

class ForwardRateCurve:
    def __init__(self, pillars, rates):
        self.start_date = pillars[0]
        self.pillar_days = [(p-pillars[0]).days/365 for p in pillars]
        self.rates = rates

    def interp_rate(self, d):
        d_frac = (d-self.start_date).days/365
        return d_frac, np.interp(d_frac, self.pillar_days, self.rates)

    def forward_rate(self, d1, d2):
        d1_frac, r1 = self.interp_rate(d1)
        d2_frac, r2 = self.interp_rate(d2)
        return ((1 + r2)**d2_frac / (1 + r1)**d1_frac)*(1/(d2_frac - d1_frac)) - 1
\end{ipython}

As an example let's compute a forward rate from fake rates.
\begin{ipython}
from datetime import date
observation_date = date (2020, 1, 1)

pillar_dates = [observation_date, 
                date(2021, 1, 1), 
                date(2022, 8, 1)]
rates = [0.05, 0.07, 0.08]

fc = ForwardRateCurve(pillar_dates, rates)
print ("forward rate: {:.4f}".format(fc.forward_rate(date(2021, 1, 1), 
                                                     date(2022, 1, 1))))
\end{ipython}
\begin{solution}
forward rate: 0.0827
\end{solution}

\section{Multi-curve Framework}
\label{sec:financial-crisis}

Prior to the 2008 financial crisis, inter-bank deposits posed little credit/liquidity issues, inter-bank lending rates (e.g. LIBOR, EURIBOR) were essentially a good proxy for risk free rates. Basis swap spreads were negligible and thereby neglected. 

Looking at the historical series of the EURIBOR (6M) rate versus the EONIA Overnight Indexed Swap (OIS-6M) rate over the time interval 2006-2011 in Fig.~\ref{fig:credit_crunch} it becomes apparent how before August 2007 the two rates display strictly overlapping trends differing of no more than 6 bps.

\begin{figure}[htb]
	\centering
	\includegraphics[width=0.9\linewidth]{figures/credit_crunch.png}
	\caption{Historical series of EURIBOR 6M rate versus EONIA OIS 6M rate. The corresponding spread 
		is shown on the right axis (Jan. 06 - Dec. 10 window, source: Bloomberg).}
	\label{fig:credit_crunch}
\end{figure}

A single yield curve constructed out of selected deposit, FRA and swap rates served both the cash flow projection and discounting purposes.

During the 2008 financial crisis, the failure of some banks however proved that inter-bank lending rates were not risk-free. Meanwhile there was also significant counterparty credit risk arising from derivative transactions that were not subjected to collateral. Basis swap spreads greatly widened, and persist to this day. 

Still looking at Fig.~\ref{fig:credit_crunch} it is clear how in August 2007 a sudden increase of the EURIBOR rate and a simultaneous decrease of the OIS rate led to the explosion of the corresponding basis spread, touching the peak of 222 bps in October 2008, when Lehman Brothers filed for bankruptcy. Successively the basis has sensibly reduced and stabilized between 40 and 60 bps (notice that the pre-crisis level has never been recovered). The same effect is observed for other similar couples of series, e.g. EURIBOR 3M vs OIS 3M.

The existence of such significant basis swap spread reflects the fact that after the crisis interest rate market has been segmented into subareas corresponding to instruments with different underlying rate tenors, characterized by different rate dynamics. 

Traditional single curve based pricing approach ignores these differences. It mixes different underlying rate tenors and incorporates different rate dynamics, eventually leading to inconsistency.
After the crisis, the market practice has thus evolved to take into account the new market information (e.g. the basis swap spreads, collateralization, etc.), that translate into the additional requirement of homogeneity and funding. The homogeneity requirement means that interest rate derivatives with a given underlying rate tenor must be priced and hedged using vanilla interest rate market instruments with the same underlying. The funding requirement means that the discount rate of any cash flow generated by the derivative must be consistent, by no-arbitrage, with the funding rate associated with that cash flow. 

Driven by the crisis, many derivative contracts have been updated to include permissible credit mitigants for a transaction, such as netting and collateralization in cash. Since standard agreements stipulate daily margination on collateral and the cash collateral earns a return at overnight rate, overnight rate becomes a natural choice for the risk-free discount rate or the funding rate. This is referred to as \emph{OIS discounting}.

The large spread between risk free rate and inter-bank lending rate during and after 2008 financial crisis it is not possible anymore to use a single curve for discounting and derivative valuation. The traditional single curve used for both cash flow projection and discounting turned out to be obsolete. The markets have since nearly switched to multi-curve framework. 

For example, if we want to calculate the net present value (NPV) of a forward 6-month LIBOR coupon, we need to simultaneously use two different discount curves: 

\begin{itemize}
\tightlist
\item the 6-month LIBOR curve for determining the forward rate;
\item the EONIA curve for discounting the expected cash flow.
\end{itemize}

%The reason of the abrupt divergence between the Euribor and OIS rates can be explained by considering both the monetary policy decisions adopted by international authorities in response to the financial turmoil, and the impact of the credit crunch on both credit and liquidity risk perception of the market, coupled with the different financial meaning and dynamics of these rates.

%\begin{itemize}
%\tightlist
%\item
%  The Euribor rate is the reference rate for over-the-counter (OTC)
%  transactions in the Euro area. It is defined as the rate at which
%  Euro inter-bank deposits are being offered within the EMU zone by one
%  prime bank to another at 11:00 a.m. Brussels time. The rate fixings
%  for a strip of 15 maturities (from one day to one year) are
%  constructed as the average of the rates submitted (excluding the
%  highest and lowest 15\% tails) by a panel of 42 banks, selected
%  among the EU banks with the highest volume of business in the Euro
%  zone money markets, plus some large international bank from non-EU
%  countries with important euro zone operations. \emph{Thus, Euribor
%  rates reflect the average cost of funding of banks in the inter bank
%  market at each given maturity. During the crisis the solvency and
%  solidity of the whole financial sector was brought into question and
%  the credit and liquidity risk and uremia associated to inter-bank
%  counter-parties sharply increased.} The Euribor rates immediately
%  reflected these dynamics and raise to their highest values over more
%  than 10 years. As seen in the plot above, the Euribor 6M rate suddenly
%  increased on August 2007 and reached 5.49\% on 10th October 2008.
%\item
%  The EONIA rate is the reference rate for overnight OTC transactions in
%  the Euro area. It is constructed as the average rate of the overnight
%  transactions (one day maturity deposits) executed during a given
%  business day by a panel of banks on the inter-bank money market,
%  weighted with the corresponding transaction volumes. \emph{The EONIA
%  Contribution Panel coincides with the Euribor Contribution Panel, thus
%  EONIA rate includes information on the short term (overnight)
%  liquidity expectations of banks in the Euro money market. It is also
%  used by the European Central Bank (ECB) as a method of effecting and
%  observing the transmission of its monetary policy actions. During the
%  crisis the central banks were mainly concerned about stabilizing the
%  level of liquidity in the market, thus they reduced the level of the
%  official rates.} Furthermore, the daily tenor of the EONIA rate makes
%  negligible the credit and liquidity risks reflected on it: for this
%  reason the OIS rates are considered the best proxies available in the
%  market for the risk-free rate.
%\end{itemize}

%Our financial library has to implement the following calculation
%
%\[\mathrm{NPV} = D_{\mathrm{EONIA}}(T_1) \cdot \frac{1}{T_2-T_1}\Big(\frac{D_{\mathrm{LIBOR}}(T_1)}{D_{\mathrm{LIBOR}}(T_2)} - 1 \Big)\]
%\noindent
%In order to do so we can extend the \texttt{DiscountCurve} class with a \texttt{forward\_rate} method
%
%\begin{ipython}
%class DiscountCurve:
%    ...
%    def forward_rate(self, d1, d2):
%        return (self.df(d1) / self.df(d2) - 1.0) * \
%            (365.0 / ((d2 - d1).days))
%\end{ipython}

As an example let's define EONIA and LIBOR curves and compute the net present value of the forward 6-month LIBOR coupon mentioned before.

\begin{ipython}
from finmarkets import DiscountCurve, ForwardRateCurve
from math import exp

today = date (2020, 1, 1)
t1 = date(2020, 4, 1)
t2 = date(2020, 10, 1)
pillar_dates_eonia = [today, date(2021, 1, 1), date(2022, 10 ,1)] 
eonia_rates = [1.0, 0.97, 0.72]
pillar_dates_libor = [today, date(2020, 6, 1), date(2020, 12 ,1)] 
libor = [0.005, 0.01, 0.015]

eonia_curve = DiscountCurve(pillar_dates_eonia, eonia_rates) 
libor_curve = ForwardRateCurve(pillar_dates_libor, libor) 

C = eonia_curve.df(t1) * libor_curve.forward_rate(t1, t2)
t1_frac, r1 = libor_curve.interp_rate(t1)
C_pre2008 = exp(-r1*t1_frac) * libor_curve.forward_rate(t1, t2)

print ("C post 2008: {:.5f}".format(C))
print ("C pre 2008: {:.5f}".format(C_pre2008))
\end{ipython}
\begin{ioutput}
C post 2008: 1.00285
C pre 2008: 1.00846
\end{ioutput}

\subsection{Transitioning away from LIBOR~\cite{bib:str}}
A working group on euro risk-free rates was established to identify and recommend risk free rates that could serve as a basis for an alternative to current benchmarks used in a variety of financial instruments and contracts in the euro area, such as the euro overnight index average (EONIA) and the euro inter-bank offered rate (EURIBOR). 

The group recommended on September 2018 that the euro short-term rate (STR) be used as the risk-free rate for the euro area and is now focused on supporting the market with transitioning.
The ECB published the STR for the first time on 2nd October 2019, reflecting trading activity on 1st October 2019.

The working group recommends that market participants should gradually replace EONIA with the STR as a reference rate for all products and contracts and make all necessary adjustments for using the STR as their standard benchmark The working group recommends the STR plus a fixed spread of 8.5
basis points as the EONIA fallback rate for all products and purposes. The working group recommends that market participants should: consider, whenever feasible and appropriate, no longer entering into new contracts referencing EONIA, in particular new contracts maturing after 31 December 2021, as EONIA will cease to exist after that date.

%The working group is also looking at identifying fallbacks for
%EURIBOR based on the STR. Both backward and forward-looking
%options are being considered. As part of its work on forward-looking
%options, in March 2019 the working group recommended a
%methodology based on (tradable) overnight index swap (OIS) quotes
%for calculating a STR-based forward-looking term structure and later
%invited benchmark administrators to express their interest in
%producing such a term structure.

\section*{Exercises}
\input{discount_ex_text}

\begin{thebibliography}{9}
	%  %\bibitem{survey2019} StackOverflow \emph{The TEXbook}, Addison-Wesley, Reading,Massachusetts, second edition, 1984,
	\bibitem{bib:mars}\href{https://en.wikipedia.org/wiki/Mars_Climate_Orbiter}{\emph{Mars Climate Orbiter}}, Wikipedia [Online]
	\bibitem{bib:runge} \href{https://en.wikipedia.org/wiki/Runge\%27s_phenomenon}{\emph{Runge's phenomenon}}, Wikipedia [Online]
	\bibitem{bib:forward_rate}\href{https://www.investopedia.com/ask/answers/042315/what-difference-between-forward-rate-and-spot-rate.asp}{\emph{Forward Rate vs. Spot Rate: What's the Difference?}}, Investopedia [Online]
	\bibitem{bib:libor} \href{https://www.ig.com/it/glossario-trading/definizione-di-libor}{\emph{LIBOR}} [Online]
	\bibitem{bib:2008crisis} \href{https://www.investopedia.com/articles/economics/09/financial-crisis-review.asp}{\emph{The 2007-2008 Financial Crisis Review}}, Investopedia [Online]
	\bibitem{bib:str}
	B. Guggenheim and A. Schrimpf, 
	\href{https://www.bis.org/publ/work891.htm}{\emph{At the crossroads in the transition away from LIBOR - from overnight to term rates}}, BIS Working Papers No 891, 09 October 2020 [Online]
\end{thebibliography}
