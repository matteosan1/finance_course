{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "## Overview\n",
    "In this lesson we will see how machine learning techniques can be successfully applied to solve financial problems. We will first do a quick tour on the theory behind neural networks and then we will see an example and two practical applications regarding regression and classification issues. \n",
    "\n",
    "**Disclaimer**: this lecture just scratches the surface of the machine learning topic which has seen a huge development in the latest years leading to thousands of applications in many different fields.\n",
    "\n",
    "## Neural network Definition\n",
    "Artificial Neural Networks (ANN or simply NN) are information processing models that are developed by inspiring from the working principles of human brain. Their most essential property is the ability of learning from sample sets. \n",
    "\n",
    "The basic unit of ANN architecture are neurons which are internally in connection with other neurons. \n",
    "\n",
    "![Model of an artificial neuron.](neuron.jpeg)\n",
    "\n",
    "A neuron consists of weights ($w_i$) and real numbers ($x_i$). All inputs injected into a neuron are individually weighted, added together and passed into the activation function which produce the neuron output. There are many different types of activation function but one of the simplest is the *step function* which returns just 0 or 1 according to the input value (another is the *sigmoid* which can be thought of as the continuous version of the step function). \n",
    "\n",
    "![Step function.](step_function.png)\n",
    "![Sigmoid function.](sigmoid.png)\n",
    "\n",
    "\n",
    "## Training of a neuron\n",
    "\n",
    "When teaching children how to recognize a bus, we just tell them, showing an example: “This is a bus. That is not a bus.” until they learn the concept of what a bus is. \n",
    "Furthermore, if the child sees new objects that she hasn’t seen before, we could expect her to recognize correctly whether the new object is a bus or not.\n",
    "\n",
    "This is exactly the idea behind neurons.\n",
    "Similarly, inputs from a *training* set are presented to the neuron one after the other together with the correct output and the neuron weights are modified accordingly.\n",
    "\n",
    "When an entire pass through all of the input training vectors is completed the neuron has learnt ! \n",
    "\n",
    "At this time, if an input vector $\\vec{P}$ (already in the training set) is given to the neuron, it will output the correct value. If $\\vec{P}$ is not in the training set, the network will respond with an output similar to other training vectors close to $\\vec{P}$.\n",
    "\n",
    "Unfortunately using just a neuron is not too useful since it is not possible to solve\n",
    "the interesting problems we would like to face with just that simple architecture. The next step is then to put together more neurons in *layers*.\n",
    "\n",
    "### Multi-layered neural networks\n",
    "\n",
    "![A multi-layered neural network.](multilayer.jpeg)\n",
    "\n",
    "Each input from the *input layer* is fed up to each node in the next hidden layer, and from there to each node on the output layer. We should note that there can be any number of nodes per layer and there are usually multiple hidden layers to pass through before ultimately reaching the output layer.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "But to train this network we need a learning algorithm which should be able to tune not only the weights between the output layer and the hidden layer but also the weights between the hidden layer and the input layer. \n",
    "\n",
    "### Back propagation\n",
    "\n",
    "In order to tune the weights at each layer at every iteration we should know what the output would be at each node. But this is not possbile since the only value we know is the correct output at the last node (the final output of the NN which can be compared to our truth of the training output).\n",
    "The method that was suggested to overcome the issue was to take the errors at the output layer (last node) and proportionally propagate it backwards to all the hidden layer.\n",
    "\n",
    "So, what it's going to happen is:\n",
    "\n",
    "* present a training sample to the neural network (initialized with random weights);\n",
    "* compute the output received by calculating activations of each layer and thus calculate the error as the difference between the NN output and the training sample expected result;\n",
    "* having calculated the error, readjust the weights such that the error (difference) decreases;\n",
    "* continue the process for all training samples several times until the weights are not changing too much (a.k.a. the process converged).\n",
    "\n",
    "The NN error is computed by the *loss function* (usually it is either the mean squared error or the mean absolute error) and an *optimization function* is then \n",
    "used to choose the appropriate weight values in order to reduce the loss function value (we will use *Adam* as optimizator in the following but there are more).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Neural Network Design\n",
    "\n",
    "There is no rule to guide developer into the design of a neural network in terms of number of layers and neuron per layer. The most common strategy is a trail and error one where you finally pick up the solution giving the best accuracy. In general a larger number of nodes is better to catch highly structured data with a lot of feature although it may require larger training sample to work correctly.\n",
    "\n",
    "A common mistake to avoid is to *overtrain* a NN. Overtraining is what happens when the NN learns too well the training sample but its performance degrade substantially in an independent testing sample. \n",
    "\n",
    "So usually it is required to split the available sample in two parts training and testing (e.g. 80% and 20%) and to use the former to perform the training and the latter to cross-check the performance. **Usually performance are *measured* with the mean square error computed between the truth of the sample and the NN predictions.**\n",
    "\n",
    "Anyway as a rule of thumb a NN with just one hidden layer with a number of neurons averaging the inputs and outputs is sufficient in most cases. In the following we will use more complex networks just for illustration, no strong attempt in optimizing the layout has been done though.\n",
    "\n",
    "## Practical Examples\n",
    "\n",
    "Below it will be illustrated few practical applications of neural network trainings in python. \n",
    "Various modules are available to develop neural network in ```python```, we will\n",
    "use ```Keras``` a relatively high level library which in turn use ```TensorFlow``` a very famous machine learning tool developed by Google.\n",
    "\n",
    "In the attempt of keeping things as simple as possible I have added another layer above ```Keras```, ```FinNN``` so that you can try \n",
    "to design some NN without caring too much about the many details and parameters that are involved in the process.\n",
    "\n",
    "### Function approximation \n",
    "\n",
    "As a first practical example let's try to design an ANN which is capable of learning the functional form underlying a set of data.\n",
    "\n",
    "Let's generate a sample with $x$ (input), $f(x)$ (truth) pairs where $f(x) = x^2$ and let's start to code the NN structure. \n",
    "\n",
    "We start by importing the necessary modules.\n",
    "Then we generate the training sample (i.e. the $x$, $f(x)$ pairs) and apply a simple transformation on the sample in order to have all the inputs and outputs in the $[0, 1]$ range. This is usually done to provide the NN with *normalized* data, infact the NN can be fooled by large or very small numbers giving unstable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of original data  -50.0 49.989999999980114 9.895471195092372e-23 2500.0\n",
      "The same data after the normalization  0.0 1.0 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "from finnn import FinNN\n",
    "from numpy import arange, array\n",
    "\n",
    "# define the dataset\n",
    "x = array([i for i in arange(-50, 50, 0.01)])\n",
    "\n",
    "y = array([i**2.0 for i in x])\n",
    "print(\"Distribution of original data \", x.min(), x.max(), y.min(), y.max())\n",
    "\n",
    "trainer = FinNN()\n",
    "trainer.setData(x, y)\n",
    "\n",
    "trainer.normalize()\n",
    "\n",
    "# here you should see that x and y are between 0 and 1\n",
    "print(\"The same data after the normalization \", trainer.x.min(), \n",
    "      trainer.x.max(), trainer.y.min(), trainer.y.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can define the structure of the neural network. There is no predefined rule to decide the number of layers and nodes you need to go by trial and error. Here the problem is quite simple so there is no need to use a complecated NN. \n",
    "\n",
    "In the end I have decided to use two layers with 10 nodes each and a *sigmoidal* activation function. The input_dim parameter has to be set to 1 since we have just one single input, the $x$ value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design the neural network model\n",
    "trainer.addInputLayer(1, 5, 'sigmoid')\n",
    "trainer.addHiddenLayer(5, 'sigmoid')\n",
    "trainer.addHiddenLayer(2, 'sigmoid')\n",
    "trainer.addOutputLayer(1)\n",
    "\n",
    "# define the loss function (mean squared error) and optimization algorithm (Adam)\n",
    "trainer.compileModel('mse', 'adam')\n",
    "\n",
    "# fit the model on the training dataset\n",
    "# using 500 epochs, a batch_size of 10\n",
    "trainer.fit(150, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training is completed we can evaluate how good it is. To do this we can compute the residuals or the square root of the sum of the squared difference between the true value and the one predicted by the NN. We will also plot the true function and the predicted one in order to have a graphical representation of the goodness of our training.\n",
    "To have a numerical estimate of the agreement it has been computed also the *mean squared error* defined as:\n",
    "\n",
    "$MSE = \\frac{\\sum_{i=1}^n{\\big(\\frac{x_{i}^{pred} - x_i^{truth}}{x_i^{truth}}\\big)^2}}{n}$\n",
    "\n",
    "A *perfect* prediction would lead to $MSE=0$ so the lower this number the better the agreement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 74509240390132080713925634338375911784545517568.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# make predictions for the input data\n",
    "trainer.fullPrediction()\n",
    "\n",
    "# invert the previous transformation to get back the real data and not the normalized one\n",
    "trainer.reverseNormalization()\n",
    "\n",
    "# report model error computing the mean squared error\n",
    "print('MSE: %.3f' % mean_squared_error(trainer.y, trainer.predictions))\n",
    "\n",
    "# plot the true function and the prediction to see the actual difference\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(trainer.x, trainer.y, label='Actual')\n",
    "plt.scatter(trainer.x, trainer.predictions, label='Predicted', s=4)\n",
    "plt.title('Input (x) versus Output (y)')\n",
    "plt.xlabel('Input Variable (x)')\n",
    "plt.ylabel('Output Variable (y)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are good, both visually and numerically; the predicted and actual functions match pretty well. \n",
    "\n",
    "### Exercise 8.1\n",
    "\n",
    "In order to see how different parameter choices affect the training (both looking at a plot like the one before and the the $MSE$) try to:\n",
    "\n",
    "* reduce the number of points used in the training (change the step from 0.1 to 1 or to 0.01 in $\\tt{x = arange(-50, 51, 0.1))}$, expect worse results with less points;\n",
    "* change the number of nodes per layer;\n",
    "* change the activation function from 'sigmoid' to 'relu';\n",
    "* change the number of epochs, this is the number of times the neural network will process the sample data to improve the training; setting verbose to 1 will show the progress with an estimate of the goodness of the training after each epoch; expect worse training with less epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Black-Scholes call options\n",
    "\n",
    "The first financial application of a NN concerns the pricing of european call options: essentially we will create a neural network capable of approximate the famous Black-Scholes pricing formula.\n",
    "\n",
    "First of all let's create the training sample. In order to do so we define a grid of rate- volatility values and compute the price of a call using the pricing function in the $\\tt{finmarket.py}$ library. For simplicity we assume $\\mathrm{moneyness}=1$ and $T=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from finmarkets import call\n",
    "\n",
    "data = []\n",
    "rates = np.arange(0.01, 0.11, 0.001)\n",
    "sigmas = np.arange(0.1, 0.6, 0.005)\n",
    "\n",
    "for r in rates:\n",
    "    for sigma in sigmas:\n",
    "        call_price = call(1, r, sigma, 1)\n",
    "        data.append([r, sigma, call_price])\n",
    "        \n",
    "# we transform the list to a numpy array just because \n",
    "# an array it is more convenient to use later\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it takes some time to generate data samples, it is always advisable to save them in a file since we may need to load it many times during the NN development.\n",
    "This can be done with $\\tt{pandas}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['rate'] = data[:, 0]\n",
    "df['vol'] = data[:, 1]\n",
    "df['price'] = data[:, 2]\n",
    "\n",
    "df.to_csv(\"bs_training_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the previous example we will use the $\\tt{FinNN}$ utility class to develop the NN and also we will *normalize* data to get better results.\n",
    "**Beware that this time we have TWO input parameters (rate and volatilty)** and not just one.\n",
    "\n",
    "Furthermore we will also split the generated sample into a training and a testing part so that we could later check for overfitting by comparing the perfomance in the two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first load back data\n",
    "import pandas as pd\n",
    "from finnn import FinNN\n",
    "\n",
    "data =  pd.read_csv(\"bs_training_sample.csv\")\n",
    "\n",
    "x = data.iloc[:, :2].values\n",
    "y = data.iloc[:, 2].values\n",
    "\n",
    "# the last two parameters tell the class to split the original\n",
    "# sample in training (2/3) and testing parts (1/3)\n",
    "# and to not perform reshaping since data is already in the right form\n",
    "# two columns each row\n",
    "trainer = FinNN()\n",
    "trainer.setData(x, y, 0.20)\n",
    "trainer.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512640/512640 [==============================] - 8s 15us/step\n",
      "Training: 0.00012041853086374841\n",
      "128160/128160 [==============================] - 2s 15us/step\n",
      "Test: 0.0001205714993549019\n"
     ]
    }
   ],
   "source": [
    "# define the NN architecture\n",
    "trainer.addInputLayer(2, 20, 'sigmoid')\n",
    "trainer.addHiddenLayer(8, 'sigmoid')\n",
    "trainer.addOutputLayer(1)\n",
    "        \n",
    "# define loss and optimizer algorithms\n",
    "trainer.compileModel('mse', 'adam')\n",
    "    \n",
    "# run the training\n",
    "# this time we are using many more epochs \n",
    "# and a larger batch_size\n",
    "trainer.fit(1000, 500)\n",
    "\n",
    "# here we compare the performance \n",
    "# on the training and test sample\n",
    "trainer.evaluate()\n",
    "\n",
    "# when the training takes some time it is useful\n",
    "# to save the model weights in a file to use it later on\n",
    "trainer.saveModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the training and test samples give roughly the same $MSE$ value so we are reasonably sure that there hasn't been *overfitting*.\n",
    "After the training is completed again we can evaluate graphically how good it is.\n",
    "<img src=\"vol_rate.png\">\n",
    "We can also compare the prediction in a practical case; let's say we want to know the price of a call (with moneyness 1 and time to maturity 1 year) when the interest rate is 0.015 and the volatility 0.234:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-16.805685]]\n",
      "[[1005.0, 111.2]] => -16.8057 (expected 1.0000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from finmarkets import call\n",
    "\n",
    "# here we load the trained model\n",
    "trainer.loadModel('test')\n",
    "\n",
    "# this is our input vector\n",
    "rv = np.array([[1005, 111.2]])\n",
    "\n",
    "print (trainer.predict(rv))\n",
    "# here we compare the predection with the BS call price                 \n",
    "print ('{} => {:.4f} (expected {:.4f})'.format(rv.tolist(), \n",
    "                                        trainer.predict(rv)[0][0], \n",
    "                                        call(1, rv[0][0], rv[0][1], 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what happens when we ask the NN to predict call prices with rate and volatility outside the training *phase space* (with values that aren't in the intervals used in the training) ?\n",
    "Let's try the same exercise as before but with different inputs, say $r = 0.22$ and $\\sigma = 0.01$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22, 0.01]] => 0.1557 (expected 0.1975)\n"
     ]
    }
   ],
   "source": [
    "# this is our input vector\n",
    "rv = np.array([[0.22, 0.01]])\n",
    "                 \n",
    "# here we compare the predection with the BS call price                 \n",
    "print ('{} => {:.4f} (expected {:.4f})'.format(rv.tolist(), \n",
    "                                        trainer.predict(rv)[0][0], \n",
    "                                        call(1, rv[0][0], rv[0][1], 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case there is no agreement clearly showing that NN is not able to extrapolate the value of a function from input outside the training space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Neural net to recognize handwritten digits\n",
    "\n",
    "We don't usually appreciate how tough a problem our visual system solve (consider that it involves 5 visual cortices containing 140 million neurons each), but the difficulties of visual pattern recognition become apparent if you attempt to write a computer program to recognize digits like those below. \n",
    "\n",
    "Simple intuition about how we recognize shapes - \"a 9 has a loop at the top, and a vertical stroke in the bottom right\" - turn out to be not so simple to express algorithmically. When you try to make such rules precise, you quickly get lost in a morass of exceptions and caveats and special cases so that it seems hopeless.\n",
    "\n",
    "Neural networks approach the problem in a different way. The idea is to take a large number of handwritten digits and then develop a system which can learn from those training examples. \n",
    "\n",
    "![The so-called MNIST training sample](mnist_100_digits.png)\n",
    "\n",
    "By increasing the number of training examples, the network can learn more about handwriting, and so improve its accuracy. So while I've shown just 100 training digits above, we could certainly build a better handwriting recognizer by using thousands or even millions or billions of training examples (**as we have seen above neural nets are not capable of extrapolating results, hence it won't recongnize a digit written in some strange way not included in the training sample !!!**).\n",
    "\n",
    "Let's try to implement an ANN that is capable of recognizing handwritten digits.\n",
    "To start we need to install another module, ```mnist``` which containes various predefined training samples.\n",
    "This can be done by using ```pip```, which is a very useful tool that allows to install new modules to your python libraries or alternatively using the Anaconda GUI following the *Environment* tab.\n",
    "\n",
    "Our program will be based on a Convolutional Neural Network (CNN) which is specifically designed for image/pattern recognition. We won't go in the details since it is outside the scope of this lecture but it works essentially by applying on top of an image a series of filters (*convolutional layers*) that works as edge detectors and with them it classifies the images according to their relevant features.\n",
    "\n",
    "Convolutional layers prove very effective, and stacking them in deep models allows layers close to the input to learn low-level features (e.g. lines) and layers deeper in the model to learn high-order or more abstract features, like shapes or specific objects.\n",
    "\n",
    "![](edges.jpg)\n",
    "\n",
    "Another important difference with respect to the previous examples is that in this case we are going to solve a classification problem (contrary to before when we were trying to regress a sample or in other word to approximate a function). Indeed our NN output won't be a single number but rather a vector containing the probabilties that a handwritten digit was 0, 1, 2, ..., 8 and 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# contains our dataset for training\n",
    "import mnist \n",
    "\n",
    "from finnn import FinNN\n",
    "\n",
    "# load the training\n",
    "train_images = mnist.train_images() # the actual images\n",
    "train_labels = mnist.train_labels() # the truth (it is a 0, 1, 2...)\n",
    "\n",
    "# 0 means do not split the sample in training and testing sets\n",
    "# (MNIST has already dont it for us)\n",
    "# the last parameter tells FinNN class that we are going to develop a CNN\n",
    "trainer = FinNN(\"CNN2D\")\n",
    "trainer.setData(train_images, train_labels)\n",
    "\n",
    "#trainer.normalize()\n",
    "# for technical reasons you need to expand axis\n",
    "trainer.x = np.expand_dims(trainer.x, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "59999/59999 [==============================] - 11s 179us/step - loss: 1.8219\n",
      "Epoch 2/5\n",
      "59999/59999 [==============================] - 11s 179us/step - loss: 0.4252\n",
      "Epoch 3/5\n",
      "59999/59999 [==============================] - 11s 178us/step - loss: 0.2709\n",
      "Epoch 4/5\n",
      "59999/59999 [==============================] - 11s 178us/step - loss: 0.2130\n",
      "Epoch 5/5\n",
      "59999/59999 [==============================] - 11s 179us/step - loss: 0.1846\n"
     ]
    }
   ],
   "source": [
    "# define our convolutional NN\n",
    "# we decide to apply 8 filters to the images \n",
    "# each with 3x3 pixels size\n",
    "# the input images have 28x28 pixels size instead\n",
    "trainer.addConv2DLayer(8, 3, (28, 28, 1))\n",
    "\n",
    "# the output is given by 10 neurons returning the \n",
    "# probability that image is in each class.\n",
    "trainer.addCNNOutputLayer(10)\n",
    "        \n",
    "\n",
    "# adam is an algorithm to adjust the weights every cycle\n",
    "# loss function compute the error between the prediction and the truth \n",
    "# metrics which error to use \n",
    "trainer.compileModel('categorical_crossentropy', 'adam')\n",
    "\n",
    "trainer.fit(5)\n",
    "#validation_data=(test_images, to_categorical(test_labels)))\n",
    "    \n",
    "trainer.saveModel('digit_training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the most curious students\n",
    "\n",
    "If you look closely to the `finnn.py` module you will notice that I have cheated when\n",
    "describing the CNN architecture. In particular I have not mentioned the `MaxPooling2D`\n",
    "layer, so let's clarify its feature.\n",
    "\n",
    "Convolutional layers in a convolutional neural network systematically apply learned filters to input images in order to create feature maps that summarize the presence of those features in the input.\n",
    "\n",
    "A limitation of the feature map output of convolutional layers is that they record the precise position of features in the input. This means that small movements in the position of the feature in the input image will result in a different feature map. This can happen with re-cropping, rotation, shifting, and other minor changes to the input image.\n",
    "\n",
    "Imagine a program that look for car plates in pictures taken by a speed radar, cars won't\n",
    "be in the same position in the frame so there may be differences in the classification \n",
    "of similar (but not equal) pictures.\n",
    "\n",
    "A common approach to address this problem from signal processing is called *down sampling*. This is where a lower resolution version of an input signal (e.g. the picture) is created that still contains the large or important structural elements, without the fine detail that may not be as useful to the task.\n",
    "\n",
    "Down sampling can be achieved using a pooling layer.\n",
    "\n",
    "Pooling involves selecting a pooling operation, much like a filter to be applied to feature maps. The size of the pooling operation or filter is smaller than the size of the feature map; specifically, it is almost always 2×2 pixels.\n",
    "This means that the pooling layer will always reduce the size of each feature map by a factor of 2, e.g. each dimension is halved. For example, a pooling layer applied to a feature map of 6×6 (36 pixels) will result in an output pooled feature map of 3×3 (9 pixels).\n",
    "\n",
    "The most common pooling operation are:\n",
    "* Average Pooling: calculate the average value for each patch on the feature map;\n",
    "* Maximum Pooling (or Max Pooling): calculate the maximum value for each patch of the feature map.\n",
    "\n",
    "\n",
    "Now let's try to see how well our NN predicts MNIST testing digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesing on MNIST digits...\n",
      "Predicted:  [7 2 1 0 4 1 4 9 6 9]\n",
      "Truth: [7 2 1 0 4 1 4 9 5 9]\n",
      "highest prob.: ['1.000000', '1.000000', '0.999987', '0.999998', '1.000000', '0.999993', '0.993805', '0.652628', '0.959723', '0.999988']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "\n",
    "trainer.loadModel('digit_training')\n",
    "\n",
    "# testing with mnist test sample\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "predictions = trainer.predict(test_images[:10])\n",
    "print (\"Tesing on MNIST digits...\")\n",
    "print(\"Predicted: \", np.argmax(predictions, axis=1)) \n",
    "print(\"Truth:\", test_labels[:10])\n",
    "\n",
    "# this line returns the highest probability of the vector\n",
    "print(\"highest prob.:\", [\"{:.6f}\".format(p[np.argmax(p)]) for p in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the last two digits have lower probabilites let's check the entire vectors to see which other number have non-zero probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th digit: ['dig 0: 0.000000', 'dig 1: 0.000000', 'dig 2: 0.000232', 'dig 3: 0.000034', 'dig 4: 0.347104', 'dig 5: 0.000001', 'dig 6: 0.000000', 'dig 7: 0.000001', 'dig 8: 0.000000', 'dig 9: 0.652628']\n",
      "\n",
      "9th digit: ['dig 0: 0.000000', 'dig 1: 0.000000', 'dig 2: 0.000000', 'dig 3: 0.000000', 'dig 4: 0.000000', 'dig 5: 0.040277', 'dig 6: 0.959723', 'dig 7: 0.000000', 'dig 8: 0.000000', 'dig 9: 0.000000']\n"
     ]
    }
   ],
   "source": [
    "print(\"8th digit:\", [\"dig {}: {:.6f}\".format(i, p) for i, p in enumerate(predictions[7])])\n",
    "print ()\n",
    "print(\"9th digit:\", [\"dig {}: {:.6f}\".format(i, p) for i, p in enumerate(predictions[8])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the first case the second ranked digit is 5 (which can be confused with a six if the lower loop is almost closed), while in the second case it is a 7 (which can be confused with a 9 if the loop is opened). \n",
    "\n",
    "### Exercise 8.2\n",
    "To see how well our NN behaves with different kind of digits we will try to check how it works with my calligraphy (as homework try to repeat the exercise using your own digit following the instructions given below).\n",
    "\n",
    "* Open `paint` and create a 280x280 white square\n",
    "* Change brush type and set the maximum size\n",
    "* With the mouse draw a digit\n",
    "* Finally save the file (e.g. five.png)\n",
    "\n",
    "Before passing the image to the NN it has to be resized and this is done with an ad-hoc function (`transform_image`) which is in the `digit_converter.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tesing on custom digits...\n",
      "Predicted:  [4]\n",
      "%: ['1.000']\n",
      "\n",
      "\n",
      "Tesing on custom digits...\n",
      "Predicted:  [5]\n",
      "%: ['0.999']\n"
     ]
    }
   ],
   "source": [
    "from digit_converter import transform_image\n",
    "\n",
    "filenames = ['four.png', 'five.png']\n",
    "\n",
    "for f in filenames:\n",
    "    test_images = np.array(transform_image(f))\n",
    "    test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "    predict = trainer.predict(test_images)\n",
    "    print (\"\\n\")\n",
    "    print (\"Tesing on custom digits...\")\n",
    "    print (\"Predicted: \", np.argmax(predict, axis=1))\n",
    "    print(\"%:\", [\"{:.3f}\".format(p[np.argmax(p)]) for p in predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those the images I have checked:\n",
    "\n",
    "<img src=\"four.png\" width=80>\n",
    "<img src=\"five.png\" width=80>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Analysis\n",
    "\n",
    "In finance, *technical analysis* is a security analysis discipline for forecasting the direction of prices through the study of past market data, primarily price and volume.\n",
    "Essentially the analyst looks for particular patterns in the price time series that are *known* to develop in predictable ways to take profit of it.\n",
    "\n",
    "<img src=\"H_and_s_top_new.jpg\" width=400>\n",
    "<img src=\"Triangle-ascending.jpg\" width=400>\n",
    "\n",
    "As you may imagine we will try to develop a CNN (like in the handwriting case) capable of classifying features in time series to be used in a technical analysis (this is much faster than having somebody looking at thousands of time series by eye...).\n",
    "\n",
    "I have generated myself the training set simulating 21600 time series (1/3 with head and shoulder patter, 1/3 with triangle pattern and 1/3 with no pattern). *To make the training easier the features have been exagerated.*\n",
    "\n",
    "<figure>\n",
    "<img src=\"image_1.png\" width=300>\n",
    "<figcaption>No pattern</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<img src=\"image_2.png\" width=300>\n",
    "<figcaption>Head and shoulder pattern</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<img src=\"image_0.png\" width=300>\n",
    "<figcaption>Tringle pattern</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "21598/21598 [==============================] - 17s 774us/step - loss: 0.8423\n",
      "Epoch 2/80\n",
      "21598/21598 [==============================] - 16s 738us/step - loss: 0.6163\n",
      "Epoch 3/80\n",
      "21598/21598 [==============================] - 16s 748us/step - loss: 0.5836\n",
      "Epoch 4/80\n",
      "21598/21598 [==============================] - 16s 738us/step - loss: 0.5432\n",
      "Epoch 5/80\n",
      "21598/21598 [==============================] - 16s 730us/step - loss: 0.5513\n",
      "Epoch 6/80\n",
      "21598/21598 [==============================] - 15s 714us/step - loss: 0.5018\n",
      "Epoch 7/80\n",
      "21598/21598 [==============================] - 16s 721us/step - loss: 0.4953\n",
      "Epoch 8/80\n",
      "21598/21598 [==============================] - 16s 734us/step - loss: 0.4842\n",
      "Epoch 9/80\n",
      "21598/21598 [==============================] - 16s 730us/step - loss: 0.4737\n",
      "Epoch 10/80\n",
      "21598/21598 [==============================] - 16s 744us/step - loss: 0.4622\n",
      "Epoch 11/80\n",
      "21598/21598 [==============================] - 16s 738us/step - loss: 0.4431\n",
      "Epoch 12/80\n",
      "21598/21598 [==============================] - 16s 734us/step - loss: 0.39470s - loss: 0.394\n",
      "Epoch 13/80\n",
      "21598/21598 [==============================] - 16s 731us/step - loss: 0.3548\n",
      "Epoch 14/80\n",
      "21598/21598 [==============================] - 16s 742us/step - loss: 0.3372\n",
      "Epoch 15/80\n",
      "21598/21598 [==============================] - 16s 752us/step - loss: 0.3279\n",
      "Epoch 16/80\n",
      "21598/21598 [==============================] - 16s 748us/step - loss: 0.3226\n",
      "Epoch 17/80\n",
      "21598/21598 [==============================] - 16s 729us/step - loss: 0.3089\n",
      "Epoch 18/80\n",
      "21598/21598 [==============================] - 16s 728us/step - loss: 0.3101\n",
      "Epoch 19/80\n",
      "21598/21598 [==============================] - 16s 729us/step - loss: 0.2985\n",
      "Epoch 20/80\n",
      "21598/21598 [==============================] - 16s 741us/step - loss: 0.2966\n",
      "Epoch 21/80\n",
      "21598/21598 [==============================] - 16s 730us/step - loss: 0.2928\n",
      "Epoch 22/80\n",
      "21598/21598 [==============================] - 16s 755us/step - loss: 0.2915\n",
      "Epoch 23/80\n",
      "21598/21598 [==============================] - 16s 733us/step - loss: 0.2858\n",
      "Epoch 24/80\n",
      "21598/21598 [==============================] - 16s 739us/step - loss: 0.2819\n",
      "Epoch 25/80\n",
      "21598/21598 [==============================] - 16s 726us/step - loss: 0.2826\n",
      "Epoch 26/80\n",
      "21598/21598 [==============================] - 16s 726us/step - loss: 0.2786\n",
      "Epoch 27/80\n",
      "21598/21598 [==============================] - 16s 741us/step - loss: 0.2756\n",
      "Epoch 28/80\n",
      "21598/21598 [==============================] - 17s 764us/step - loss: 0.2680\n",
      "Epoch 29/80\n",
      "21598/21598 [==============================] - 17s 799us/step - loss: 0.2718\n",
      "Epoch 30/80\n",
      "21598/21598 [==============================] - 17s 807us/step - loss: 0.2637\n",
      "Epoch 31/80\n",
      "21598/21598 [==============================] - 16s 743us/step - loss: 0.2696\n",
      "Epoch 32/80\n",
      "21598/21598 [==============================] - 16s 758us/step - loss: 0.2594\n",
      "Epoch 33/80\n",
      "21598/21598 [==============================] - 17s 769us/step - loss: 0.2563\n",
      "Epoch 34/80\n",
      "21598/21598 [==============================] - 17s 788us/step - loss: 0.2493\n",
      "Epoch 35/80\n",
      "21598/21598 [==============================] - 17s 768us/step - loss: 0.2501\n",
      "Epoch 36/80\n",
      "21598/21598 [==============================] - 17s 771us/step - loss: 0.2424\n",
      "Epoch 37/80\n",
      "21598/21598 [==============================] - 16s 757us/step - loss: 0.2464\n",
      "Epoch 38/80\n",
      "21598/21598 [==============================] - 16s 757us/step - loss: 0.2394\n",
      "Epoch 39/80\n",
      "21598/21598 [==============================] - 17s 774us/step - loss: 0.2396\n",
      "Epoch 40/80\n",
      "21598/21598 [==============================] - 16s 764us/step - loss: 0.2344\n",
      "Epoch 41/80\n",
      "21598/21598 [==============================] - 16s 760us/step - loss: 0.2419\n",
      "Epoch 42/80\n",
      "21598/21598 [==============================] - 18s 812us/step - loss: 0.2295\n",
      "Epoch 43/80\n",
      "21598/21598 [==============================] - 16s 735us/step - loss: 0.2281\n",
      "Epoch 44/80\n",
      "21598/21598 [==============================] - 17s 785us/step - loss: 0.2299\n",
      "Epoch 45/80\n",
      "21598/21598 [==============================] - 17s 765us/step - loss: 0.2369\n",
      "Epoch 46/80\n",
      "21598/21598 [==============================] - 17s 789us/step - loss: 0.2246\n",
      "Epoch 47/80\n",
      "21598/21598 [==============================] - 16s 761us/step - loss: 0.2262\n",
      "Epoch 48/80\n",
      "21598/21598 [==============================] - 16s 756us/step - loss: 0.2256\n",
      "Epoch 49/80\n",
      "21598/21598 [==============================] - 16s 748us/step - loss: 0.2192\n",
      "Epoch 50/80\n",
      "21598/21598 [==============================] - 17s 779us/step - loss: 0.2209\n",
      "Epoch 51/80\n",
      "21598/21598 [==============================] - 17s 793us/step - loss: 0.2223\n",
      "Epoch 52/80\n",
      "21598/21598 [==============================] - 16s 758us/step - loss: 0.2198\n",
      "Epoch 53/80\n",
      "21598/21598 [==============================] - 16s 753us/step - loss: 0.2145\n",
      "Epoch 54/80\n",
      "21598/21598 [==============================] - 18s 819us/step - loss: 0.2205\n",
      "Epoch 55/80\n",
      "21598/21598 [==============================] - 17s 781us/step - loss: 0.2140\n",
      "Epoch 56/80\n",
      "21598/21598 [==============================] - 16s 740us/step - loss: 0.2160\n",
      "Epoch 57/80\n",
      "21598/21598 [==============================] - 16s 743us/step - loss: 0.2097\n",
      "Epoch 58/80\n",
      "21598/21598 [==============================] - 16s 732us/step - loss: 0.2066\n",
      "Epoch 59/80\n",
      "21598/21598 [==============================] - 16s 744us/step - loss: 0.2140\n",
      "Epoch 60/80\n",
      "21598/21598 [==============================] - 16s 740us/step - loss: 0.2089\n",
      "Epoch 61/80\n",
      "21598/21598 [==============================] - 16s 726us/step - loss: 0.2059\n",
      "Epoch 62/80\n",
      "21598/21598 [==============================] - 16s 743us/step - loss: 0.2118\n",
      "Epoch 63/80\n",
      "21598/21598 [==============================] - 17s 792us/step - loss: 0.2063\n",
      "Epoch 64/80\n",
      "21598/21598 [==============================] - 17s 783us/step - loss: 0.2052\n",
      "Epoch 65/80\n",
      "21598/21598 [==============================] - 17s 779us/step - loss: 0.2054\n",
      "Epoch 66/80\n",
      "21598/21598 [==============================] - 16s 736us/step - loss: 0.2075\n",
      "Epoch 67/80\n",
      "21598/21598 [==============================] - 16s 734us/step - loss: 0.2010\n",
      "Epoch 68/80\n",
      "21598/21598 [==============================] - 16s 757us/step - loss: 0.2008\n",
      "Epoch 69/80\n",
      "21598/21598 [==============================] - 16s 735us/step - loss: 0.2013\n",
      "Epoch 70/80\n",
      "21598/21598 [==============================] - 16s 729us/step - loss: 0.2014\n",
      "Epoch 71/80\n",
      "21598/21598 [==============================] - 16s 747us/step - loss: 0.1936\n",
      "Epoch 72/80\n",
      "21598/21598 [==============================] - 16s 729us/step - loss: 0.2095\n",
      "Epoch 73/80\n",
      "21598/21598 [==============================] - 17s 790us/step - loss: 0.2009\n",
      "Epoch 74/80\n",
      "21598/21598 [==============================] - 17s 809us/step - loss: 0.1915\n",
      "Epoch 75/80\n",
      "21598/21598 [==============================] - 17s 797us/step - loss: 0.1880\n",
      "Epoch 76/80\n",
      "21598/21598 [==============================] - 17s 772us/step - loss: 0.1992\n",
      "Epoch 77/80\n",
      "21598/21598 [==============================] - 16s 741us/step - loss: 0.1883\n",
      "Epoch 78/80\n",
      "21598/21598 [==============================] - 17s 775us/step - loss: 0.1894\n",
      "Epoch 79/80\n",
      "21598/21598 [==============================] - 17s 789us/step - loss: 0.2116\n",
      "Epoch 80/80\n",
      "21598/21598 [==============================] - 17s 804us/step - loss: 0.1881\n"
     ]
    }
   ],
   "source": [
    "from finnn import FinNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_labels = pd.read_csv(\"training_techana_labels.csv\")\n",
    "train_images = pd.read_csv(\"training_techana_images.csv\")\n",
    "#train_images = train_images[:3000]\n",
    "#train_images = np.array(train_images)\n",
    "train_images = np.expand_dims(train_images, axis=2)\n",
    "\n",
    "trainer = FinNN(\"CNN1D\")\n",
    "trainer.setData(train_images, train_labels)\n",
    "\n",
    "# define the CNN \n",
    "trainer.addConv1DInputLayer(80, 20, (101, 1))\n",
    "trainer.addConv1DLayer(80, 15)\n",
    "trainer.addMaxPooling1D(3)\n",
    "trainer.addConv1DLayer(100, 10)\n",
    "trainer.addConv1DLayer(100, 5)\n",
    "trainer.addGlobalAveragePooling1D()\n",
    "trainer.addDropout(0.5)\n",
    "trainer.addCNNOutputLayer(3)\n",
    "\n",
    "trainer.compileModel('categorical_crossentropy', 'adam')\n",
    "\n",
    "# make the training\n",
    "trainer.fit(80, 35)\n",
    "\n",
    "trainer.saveModel('techana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again for the most curious students\n",
    "\n",
    "Large neural nets trained on relatively small datasets can overfit the training data.\n",
    "\n",
    "This has the effect of the model learning the statistical noise in the training data, which results in poor performance when the model is evaluated on new data, e.g. a test dataset. \n",
    "\n",
    "One approach to reduce overfitting is to fit all possible different neural networks on the same dataset and to average the predictions from each model. This is not feasible in practice, and can be approximated using a small collection of different models, called an ensemble.\n",
    "A problem even with the ensemble approximation is that it requires multiple models to be fit and stored, which can be a challenge if the models are large, requiring days or weeks to train and tune.\n",
    "\n",
    "*Dropout* is a regularization method that approximates training a large number of neural networks with different architectures in parallel.\n",
    "\n",
    "During training, some number of layer outputs are randomly ignored or *dropped out*. This has the effect of making the layer look-like and be treated-like a layer with a different number of nodes and connectivity to the prior layer. In effect, each update to a layer during training is performed with a different “view” of the configured layer.\n",
    "\n",
    "Even if the it may seems counterintuitive (better training when switching off nodes) indeed dropout breaks-up situations where network layers co-adapt to correct mistakes from prior layers, in turn making the model more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the perfomance I wanted to simulate a real case scenario where the time series are analyzed in real-time in order to predict as soon as possible a particular pattern and take advantage of the prediction.\n",
    "\n",
    "TO do so I have created a longer time series and passed as input to the CNN sliding time windows to simulate the evolution of the time series. The goal was to check when the neural network was capable of predicting the incoming pattern.\n",
    "\n",
    "<img src=\"closing_price.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['0.71', '0.00', '0.29']\n",
      "0 ['0.66', '0.00', '0.34']\n",
      "0 ['0.82', '0.00', '0.18']\n",
      "0 ['0.91', '0.00', '0.09']\n",
      "2 ['0.40', '0.06', '0.54']\n",
      "1 ['0.00', '1.00', '0.00']\n",
      "1 ['0.00', '1.00', '0.00']\n",
      "1 ['0.00', '1.00', '0.00']\n",
      "1 ['0.00', '1.00', '0.00']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "test_images = pd.read_csv(\"testing_techana_frames.csv\")\n",
    "test_images = np.expand_dims(test_images, axis=2)\n",
    "\n",
    "trainer.loadModel('techana')\n",
    "\n",
    "predictions = trainer.predict(test_images)\n",
    "for i in range(len(predictions)):\n",
    "    print (np.argmax(predictions[i]), [\"{:.2f}\".format(p) for p in predictions[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So at the 6th sample the CNN start recognizing the *head and shoulder* pattern in the price evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 8.3\n",
    "Taking as example the pricing NN trained on call, try to price put options."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
