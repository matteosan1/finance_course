{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Practical Lesson 8\n",
    "\n",
    "## Overview\n",
    "In this lesson we will see how machine learning techniques can be successfully applied to solve financial problems. We will first do a quick tour on the theory behind neural networks and then we will see an example and two practical applications regarding regression and classification issues.\n",
    "\n",
    "## Neural networks\n",
    "\n",
    "### Definition\n",
    "Artificial Neural Networks (ANN) are information processing models that are developed by inspiring from the working principles of human brain. Their most essential property is the ability of learning from sample sets. The basic process units of ANN architecture are neurons which are internally in connection with other neurons. \n",
    "\n",
    "![Model of an artificial neuron.](neuron.jpeg)\n",
    "\n",
    "A neuron consists of weights ($w_i$) and real ($x_i$) numbers. All inputs injected into neurons are individually weighted, added together and passed into the activation function. There are many different types of activation function but one of the simplest would be step function (another is the sigmoid). \n",
    "\n",
    "![Step function.](step_function.png)\n",
    "![Sigmoid function.](sigmoid.png)\n",
    "\n",
    "The activation function is then responsible to provide the neuron output.\n",
    "\n",
    "### Training of a neuron\n",
    "\n",
    "When teaching children how to recognize a bus, we just tell them, showing an example: “This is a bus. That is not a bus.” until they learn the concept of what a bus is. \n",
    "Furthermore, if the child sees new objects that she hasn’t seen before, we could expect her to recognize correctly whether the new object is a bus or not.\n",
    "This is exactly the idea behind the neurons.\n",
    "Similarly, inputs from a *training* set are presented to the neuron one after the other and weights are modified according to the expected output.\n",
    "\n",
    "When an entire pass through all of the input training vectors is completed the neuron has learnt ! At this time, if an input vector $\\vec{P}$ (already in the training set) is given to the neuron, it will output the correct value. If $\\vec{P}$ is not in the training set, the network will respond with an output similar to other training vectors close to $\\vec{P}$.\n",
    "\n",
    "Unfortunately using just a neuron is not too useful since it is not possible to solve\n",
    "the interesting problems we would like to face with just that simple architecture. The next step is then to put together more neurons in *layers*.\n",
    "\n",
    "### Multi-layered neural networks\n",
    "\n",
    "![A multi-layered neural network.](multilayer.jpeg)\n",
    "\n",
    "Each input from the *input layer* is fed up to each node in the hidden layer, and from there to each node on the output layer. We should note that there can be any number of nodes per layer and there are usually multiple hidden layers to pass through before ultimately reaching the output layer.\n",
    "But to train this network we need a learning algorithm which should be able to tune not only the weights between the output layer and the hidden layer but also the weights between the hidden layer and the input layer. \n",
    "\n",
    "### Back propagation\n",
    "\n",
    "First of all, we need to understand what do we lack. To tune the weights between the hidden layer and the input layer, we need to know the error at the hidden layer, but we know the error only at the output layer (we know the correct output from the training sample and we also know the output predicted by the network.)\n",
    "So, the method that was suggested was to take the errors at the output layer and proportionally propagate them backwards to the hidden layer.\n",
    "\n",
    "So, what we are doing is:\n",
    "\n",
    "* we present a training sample to the neural network (initialized with random weights);\n",
    "* compute the output received by calculating activations of each layer and thus calculate the error;\n",
    "* having calculated the error, we readjust the weights such that the error decreases;\n",
    "* we continue the process for all training samples several times until the weights are not changing too much.\n",
    "\n",
    "### Neural Network Design\n",
    "\n",
    "There is no rule to guide us into the design of a neural network in terms of number of layers and neuron per layer. The most common strategy is a trail and error one where you finally pick up the solution giving the best accuracy.\n",
    "\n",
    "A common mistake to avoid is to start with a too complex (with many layers and neurons) network which usually leads to *overtraining*. Overtraining is what happens when the NN learns too well the training sample but its performance degrade substantially in an independent testing sample.\n",
    "\n",
    "A NN with just one hidden layer with a number of neurons averaging the inputs and outputs is sufficient in most cases. In the following we will use more complex networks just for illustration, no attempt in optimizing the layout has been done.\n",
    "\n",
    "\n",
    "## Neural net to recognize handwritten digits\n",
    "\n",
    "We don't usually appreciate how tough a problem our visual system solve (consider that it involves 5 visual cortices containing 140 million neurons each), but the difficulties of visual pattern recognition become apparent if you attempt to write a computer program to recognize digits like those below. \n",
    "\n",
    "![The so-called MNIST training sample](mnist_100_digits.png)\n",
    "\n",
    "Simple intuition about how we recognize shapes - \"a 9 has a loop at the top, and a vertical stroke in the bottom right\" - turn out to be not so simple to express algorithmically. When you try to make such rules precise, you quickly get lost in a morass of exceptions and caveats and special cases so that it seems hopeless.\n",
    "\n",
    "Neural networks approach the problem in a different way. The idea is to take a large number of handwritten digits and then develop a system which can learn from those training examples. By increasing the number of training examples, the network can learn more about handwriting, and so improve its accuracy. So while I've shown just 100 training digits above, we could certainly build a better handwriting recognizer by using thousands or even millions or billions of training examples (**remember that neural nets are not so capable of extrapolating results, hence it won't recongnize a digit written in some strange way not included in the training sample !!!**).\n",
    "\n",
    "Let's try to implement an ANN that is capable of recognizing handwritten digits.\n",
    "To start we need to install three new modules, the easiest way of doing that is to run Anaconda on you computers (repl.it is too slow in this case):\n",
    "\n",
    "* open an anaconda-shell and type the following:\n",
    "```pip install keras, mnist, tensorflow```\n",
    "\n",
    "```pip``` is a very useful tool that allows to install new modules to your python libraries.\n",
    "Alternatively using the Anaconda GUI you should be able to install the packages using the *Environment* tab.\n",
    "\n",
    "Our program will be based on a Convolutional Neural Network (CNN, will see later other two types of NN) which is designed for image/pattern recognition. It works essentially by applying on top of an image a series of filters (matrices) that works as edge detectors and with them it classifies the images according to their features.\n",
    "\n",
    "![](edges.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 1.8699 - mean_squared_error: 0.0193\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.3434 - mean_squared_error: 0.0092\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.2325 - mean_squared_error: 0.0079\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# contains our dataset for training\n",
    "import mnist \n",
    "# keras gives us all the tools to work with NN\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load the training\n",
    "train_images = mnist.train_images() # the actual images\n",
    "train_labels = mnist.train_labels() # the truth (it is a 0, 1, 2...)\n",
    "\n",
    "# transform data for convenience\n",
    "#train_images = (train_images / 255) - 0.5\n",
    "# for technical reasons you need to expand axis\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "\n",
    "# definition of the actual network\n",
    "num_filters = 8\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "# the input size reflects the size of the image with\n",
    "# the numbers 28x28 pixels\n",
    "model = Sequential([\n",
    "    Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)), \n",
    "    MaxPooling2D(pool_size=pool_size), # reduce the size of the representation\n",
    "                                       # to reduce the size of the parameters\n",
    "    Flatten(), # this step of flattening is necessary to transform a \n",
    "               # 2D matrix into a vector to connect to a classifier\n",
    "    Dense(10, activation=\"softmax\") # softmax is just another type of\n",
    "                                    # activation functions like sigmoid or step func.\n",
    "])\n",
    "# the output is given by 10 neurons returning the \n",
    "# probability that image is in each class.\n",
    "\n",
    "# adam is an algorithm to adjust the weights every cycle\n",
    "# loss function compute the error between the prediction and the truth \n",
    "# metrics which error to use \n",
    "model.compile('adam', loss=\"categorical_crossentropy\",\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "model.fit(train_images,\n",
    "          to_categorical(train_labels),\n",
    "          epochs=3)#,\n",
    "          #validation_data=(test_images, to_categorical(test_labels)))\n",
    "    \n",
    "model.save('digit_training.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to see how well our NN predicts MNIST testing digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesing on MNIST digits...\n",
      "Predicted:  [7 2 1 0 4]\n",
      "Truth: [7 2 1 0 4]\n",
      "%: ['1.000', '1.000', '0.995', '1.000', '1.000']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('digit_training.h5')\n",
    "\n",
    "# testing with mnist test sample\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "predictions = model.predict(test_images[:5])\n",
    "print (\"Tesing on MNIST digits...\")\n",
    "print(\"Predicted: \", np.argmax(predictions, axis=1)) \n",
    "print(\"Truth:\", test_labels[:5])\n",
    "print(\"%:\", [\"{:.3f}\".format(p[np.argmax(p)]) for p in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how well our NN behaves with different kind of digits we will try to check how it works with your own calligraphy.\n",
    "\n",
    "* Open `paint` and create a 280x280 white square\n",
    "* Change brush type and set the maximum size\n",
    "* With the mouse draw a digit\n",
    "* Finally save the file (e.g. five.png)\n",
    "\n",
    "Before passing the image to the NN it has to be resized and this is done with an ad hoc function (`transform_image`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tesing on custom digits...\n",
      "Predicted:  [5]\n",
      "%: ['0.739']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from digit_converter import transform_image\n",
    "\n",
    "model = load_model('digit_training.h5')\n",
    "\n",
    "test_images = np.array(transform_image(\"five.png\"))\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "predict = model.predict(test_images)\n",
    "print (\"\\n\")\n",
    "print (\"Tesing on custom digits...\")\n",
    "print (\"Predicted: \", np.argmax(predict, axis=1))\n",
    "print(\"%:\", [\"{:.3f}\".format(p[np.argmax(p)]) for p in predict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those the images I have checked:\n",
    "\n",
    "<img src=\"four.png\" width=80>\n",
    "<img src=\"five.png\" width=80>\n",
    "\n",
    "## Black-Scholes call options\n",
    "\n",
    "The first financial application of a NN concerns the pricing of european call options. \n",
    "In this case I have generated myself a large number of call options with a strike (100) and a maturity (1 year), simulated the underlying development and finally trained the NN using as inputs: volatility, strike, maturity and the underlying. The truth is the price of the call computed using the Black-Scholes formula.\n",
    "\n",
    "![](underlyings.png)\n",
    "\n",
    "The code used for the simulation is in $\\href{https://repl.it/@MatteoSani/exercises8}{\\textrm{bs_simulation.py}}$. I have also simulated two testing samples, one with the parameters included in the training events, and one with parameters outside.\n",
    "The training and testing samples have been stored in a *csv* (comma-separated values) file,\n",
    "which has a particular format very easy to read.\n",
    "\n",
    "In the training I have used a *traditional* NN with an input layer with 4 neurons (the number of inputs), an hidden layer with 10 neurons and an output layer with 1 single neuron (since I need just a number, the price of the call)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2919/2919 [==============================] - 0s 90us/step - loss: 12.5533 - mse: 258.4865 - mae: 12.5533\n",
      "Epoch 2/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 7.4621 - mse: 91.6238 - mae: 7.4621\n",
      "Epoch 3/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 7.1069 - mse: 80.2523 - mae: 7.1069\n",
      "Epoch 4/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 6.9312 - mse: 75.3490 - mae: 6.9312\n",
      "Epoch 5/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 6.6959 - mse: 70.6037 - mae: 6.6959\n",
      "Epoch 6/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 6.3101 - mse: 62.6802 - mae: 6.3101\n",
      "Epoch 7/1000\n",
      "2919/2919 [==============================] - 0s 29us/step - loss: 5.6291 - mse: 49.2896 - mae: 5.6291\n",
      "Epoch 8/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 4.4202 - mse: 29.9391 - mae: 4.4202\n",
      "Epoch 9/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 3.4398 - mse: 17.3718 - mae: 3.4398\n",
      "Epoch 10/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 3.2166 - mse: 15.1599 - mae: 3.2166\n",
      "Epoch 11/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 3.0702 - mse: 14.8278 - mae: 3.0702\n",
      "Epoch 12/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 2.9990 - mse: 14.5053 - mae: 2.9990\n",
      "Epoch 13/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 2.9795 - mse: 14.2987 - mae: 2.9795\n",
      "Epoch 14/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 2.9882 - mse: 13.9151 - mae: 2.9882\n",
      "Epoch 15/1000\n",
      "2919/2919 [==============================] - 0s 61us/step - loss: 2.9485 - mse: 13.8181 - mae: 2.9485\n",
      "Epoch 16/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 2.9111 - mse: 13.7501 - mae: 2.9111\n",
      "Epoch 17/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 2.9103 - mse: 13.7801 - mae: 2.9103\n",
      "Epoch 18/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 2.8862 - mse: 13.6769 - mae: 2.8862\n",
      "Epoch 19/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 2.8899 - mse: 13.2104 - mae: 2.8899\n",
      "Epoch 20/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 2.8885 - mse: 13.2452 - mae: 2.8885\n",
      "Epoch 21/1000\n",
      "2919/2919 [==============================] - 0s 55us/step - loss: 2.8709 - mse: 13.5292 - mae: 2.8709\n",
      "Epoch 22/1000\n",
      "2919/2919 [==============================] - 0s 57us/step - loss: 2.8517 - mse: 13.2096 - mae: 2.8517\n",
      "Epoch 23/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 2.8366 - mse: 13.1191 - mae: 2.8366\n",
      "Epoch 24/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 2.8110 - mse: 12.9568 - mae: 2.8110\n",
      "Epoch 25/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 2.8440 - mse: 13.1435 - mae: 2.8440\n",
      "Epoch 26/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 2.8193 - mse: 12.8428 - mae: 2.8193\n",
      "Epoch 27/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 2.7974 - mse: 12.7741 - mae: 2.7974\n",
      "Epoch 28/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 2.7729 - mse: 12.5024 - mae: 2.7729\n",
      "Epoch 29/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 2.7923 - mse: 12.4583 - mae: 2.7923\n",
      "Epoch 30/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 2.7726 - mse: 12.3411 - mae: 2.7726\n",
      "Epoch 31/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 2.7480 - mse: 12.2228 - mae: 2.7480\n",
      "Epoch 32/1000\n",
      "2919/2919 [==============================] - 0s 53us/step - loss: 2.7455 - mse: 12.2429 - mae: 2.7455\n",
      "Epoch 33/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 2.7378 - mse: 12.1415 - mae: 2.7378\n",
      "Epoch 34/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 2.6992 - mse: 11.8289 - mae: 2.6992\n",
      "Epoch 35/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 2.7104 - mse: 11.8994 - mae: 2.7104\n",
      "Epoch 36/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 2.6628 - mse: 11.8247 - mae: 2.6628\n",
      "Epoch 37/1000\n",
      "2919/2919 [==============================] - 0s 64us/step - loss: 2.6734 - mse: 11.6964 - mae: 2.6734\n",
      "Epoch 38/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 2.6980 - mse: 11.4491 - mae: 2.6980\n",
      "Epoch 39/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 2.6400 - mse: 11.0912 - mae: 2.6400\n",
      "Epoch 40/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 2.6134 - mse: 11.3412 - mae: 2.6134\n",
      "Epoch 41/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 2.5907 - mse: 11.0712 - mae: 2.5907\n",
      "Epoch 42/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 2.5848 - mse: 10.6258 - mae: 2.5848\n",
      "Epoch 43/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 2.5574 - mse: 10.7708 - mae: 2.5574\n",
      "Epoch 44/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 2.5529 - mse: 10.5566 - mae: 2.5529\n",
      "Epoch 45/1000\n",
      "2919/2919 [==============================] - 0s 55us/step - loss: 2.5212 - mse: 10.4020 - mae: 2.5212\n",
      "Epoch 46/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 2.4904 - mse: 10.1184 - mae: 2.4904\n",
      "Epoch 47/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 2.4934 - mse: 9.7522 - mae: 2.4934\n",
      "Epoch 48/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 2.4516 - mse: 9.5544 - mae: 2.4516\n",
      "Epoch 49/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 2.4264 - mse: 9.4477 - mae: 2.4264\n",
      "Epoch 50/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 2.4020 - mse: 8.7222 - mae: 2.4020\n",
      "Epoch 51/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 2.3816 - mse: 8.8803 - mae: 2.3816\n",
      "Epoch 52/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 2.3257 - mse: 8.4097 - mae: 2.3257\n",
      "Epoch 53/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 2.2762 - mse: 7.9649 - mae: 2.2762\n",
      "Epoch 54/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 2.2146 - mse: 7.2856 - mae: 2.2146\n",
      "Epoch 55/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 2.1592 - mse: 7.1400 - mae: 2.1592\n",
      "Epoch 56/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 2.1043 - mse: 6.7861 - mae: 2.1043\n",
      "Epoch 57/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 2.0491 - mse: 6.3789 - mae: 2.0491\n",
      "Epoch 58/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 1.9652 - mse: 5.9332 - mae: 1.9652\n",
      "Epoch 59/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 1.8887 - mse: 5.4778 - mae: 1.8887\n",
      "Epoch 60/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 1.8145 - mse: 4.9397 - mae: 1.8145\n",
      "Epoch 61/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 1.7267 - mse: 4.4376 - mae: 1.7267\n",
      "Epoch 62/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 1.5817 - mse: 3.7981 - mae: 1.5817\n",
      "Epoch 63/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 1.4697 - mse: 3.1684 - mae: 1.4697\n",
      "Epoch 64/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 1.3192 - mse: 2.5925 - mae: 1.3192\n",
      "Epoch 65/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 1.1166 - mse: 1.8473 - mae: 1.1166\n",
      "Epoch 66/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.8580 - mse: 1.1138 - mae: 0.8580\n",
      "Epoch 67/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.5538 - mse: 0.4918 - mae: 0.5538\n",
      "Epoch 68/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.3834 - mse: 0.2358 - mae: 0.3834\n",
      "Epoch 69/1000\n",
      "2919/2919 [==============================] - 0s 62us/step - loss: 0.2797 - mse: 0.1316 - mae: 0.2797\n",
      "Epoch 70/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.2393 - mse: 0.0925 - mae: 0.2393\n",
      "Epoch 71/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.2370 - mse: 0.0911 - mae: 0.2370\n",
      "Epoch 72/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.2005 - mse: 0.0641 - mae: 0.2005\n",
      "Epoch 73/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1668 - mse: 0.0463 - mae: 0.1668\n",
      "Epoch 74/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1832 - mse: 0.0556 - mae: 0.1832\n",
      "Epoch 75/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.2042 - mse: 0.0672 - mae: 0.2042\n",
      "Epoch 76/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1642 - mse: 0.0447 - mae: 0.1642\n",
      "Epoch 77/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1897 - mse: 0.0585 - mae: 0.1897\n",
      "Epoch 78/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1607 - mse: 0.0432 - mae: 0.1607\n",
      "Epoch 79/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1639 - mse: 0.0437 - mae: 0.1639\n",
      "Epoch 80/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1602 - mse: 0.0435 - mae: 0.1602\n",
      "Epoch 81/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1605 - mse: 0.0429 - mae: 0.1605\n",
      "Epoch 82/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1567 - mse: 0.0406 - mae: 0.1567\n",
      "Epoch 83/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1641 - mse: 0.0454 - mae: 0.1641\n",
      "Epoch 84/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1501 - mse: 0.0386 - mae: 0.1501\n",
      "Epoch 85/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1425 - mse: 0.0352 - mae: 0.1425\n",
      "Epoch 86/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1683 - mse: 0.0464 - mae: 0.1683\n",
      "Epoch 87/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.2022 - mse: 0.0673 - mae: 0.2022\n",
      "Epoch 88/1000\n",
      "2919/2919 [==============================] - 0s 154us/step - loss: 0.1664 - mse: 0.0470 - mae: 0.1664\n",
      "Epoch 89/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1555 - mse: 0.0408 - mae: 0.1555\n",
      "Epoch 90/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.1669 - mse: 0.0471 - mae: 0.1669\n",
      "Epoch 91/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1485 - mse: 0.0370 - mae: 0.1485\n",
      "Epoch 92/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1515 - mse: 0.0382 - mae: 0.1515\n",
      "Epoch 93/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1593 - mse: 0.0420 - mae: 0.1593\n",
      "Epoch 94/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1450 - mse: 0.0364 - mae: 0.1450\n",
      "Epoch 95/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1606 - mse: 0.0432 - mae: 0.1606\n",
      "Epoch 96/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1465 - mse: 0.0365 - mae: 0.1465\n",
      "Epoch 97/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1541 - mse: 0.0399 - mae: 0.1541\n",
      "Epoch 98/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1370 - mse: 0.0323 - mae: 0.1370\n",
      "Epoch 99/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1449 - mse: 0.0354 - mae: 0.1449\n",
      "Epoch 100/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1524 - mse: 0.0388 - mae: 0.1524\n",
      "Epoch 101/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1405 - mse: 0.0335 - mae: 0.1405\n",
      "Epoch 102/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1858 - mse: 0.0548 - mae: 0.1858\n",
      "Epoch 103/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.1400 - mse: 0.0327 - mae: 0.1400\n",
      "Epoch 104/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1481 - mse: 0.0364 - mae: 0.1481\n",
      "Epoch 105/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1475 - mse: 0.0364 - mae: 0.1475\n",
      "Epoch 106/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1518 - mse: 0.0393 - mae: 0.1518\n",
      "Epoch 107/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1562 - mse: 0.0405 - mae: 0.1562\n",
      "Epoch 108/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1454 - mse: 0.0357 - mae: 0.1454\n",
      "Epoch 109/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1559 - mse: 0.0394 - mae: 0.1559\n",
      "Epoch 110/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1683 - mse: 0.0477 - mae: 0.1683\n",
      "Epoch 111/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1234 - mse: 0.0266 - mae: 0.1234\n",
      "Epoch 112/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1376 - mse: 0.0327 - mae: 0.1376\n",
      "Epoch 113/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1421 - mse: 0.0343 - mae: 0.1421\n",
      "Epoch 114/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1339 - mse: 0.0307 - mae: 0.1339\n",
      "Epoch 115/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1484 - mse: 0.0374 - mae: 0.1484\n",
      "Epoch 116/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1568 - mse: 0.0397 - mae: 0.1568\n",
      "Epoch 117/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1529 - mse: 0.0399 - mae: 0.1529\n",
      "Epoch 118/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1429 - mse: 0.0340 - mae: 0.1429\n",
      "Epoch 119/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1688 - mse: 0.0465 - mae: 0.1688\n",
      "Epoch 120/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1888 - mse: 0.0591 - mae: 0.1888\n",
      "Epoch 121/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1432 - mse: 0.0340 - mae: 0.1432\n",
      "Epoch 122/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1465 - mse: 0.0355 - mae: 0.1465\n",
      "Epoch 123/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.1755 - mse: 0.0507 - mae: 0.1755\n",
      "Epoch 124/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1360 - mse: 0.0314 - mae: 0.1360\n",
      "Epoch 125/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1332 - mse: 0.0312 - mae: 0.1332\n",
      "Epoch 126/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1239 - mse: 0.0268 - mae: 0.1239\n",
      "Epoch 127/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1388 - mse: 0.0326 - mae: 0.1388\n",
      "Epoch 128/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1382 - mse: 0.0333 - mae: 0.1382\n",
      "Epoch 129/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1530 - mse: 0.0396 - mae: 0.1530\n",
      "Epoch 130/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1350 - mse: 0.0314 - mae: 0.1350\n",
      "Epoch 131/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1475 - mse: 0.0356 - mae: 0.1475\n",
      "Epoch 132/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1471 - mse: 0.0363 - mae: 0.1471\n",
      "Epoch 133/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1348 - mse: 0.0308 - mae: 0.1348\n",
      "Epoch 134/1000\n",
      "2919/2919 [==============================] - 0s 31us/step - loss: 0.1548 - mse: 0.0397 - mae: 0.1548\n",
      "Epoch 135/1000\n",
      "2919/2919 [==============================] - 0s 31us/step - loss: 0.1321 - mse: 0.0303 - mae: 0.1321\n",
      "Epoch 136/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1670 - mse: 0.0463 - mae: 0.1670\n",
      "Epoch 137/1000\n",
      "2919/2919 [==============================] - 0s 29us/step - loss: 0.1509 - mse: 0.0386 - mae: 0.1509\n",
      "Epoch 138/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1429 - mse: 0.0340 - mae: 0.1429\n",
      "Epoch 139/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1264 - mse: 0.0277 - mae: 0.1264\n",
      "Epoch 140/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1286 - mse: 0.0284 - mae: 0.1286\n",
      "Epoch 141/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1432 - mse: 0.0350 - mae: 0.1432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1462 - mse: 0.0359 - mae: 0.1462\n",
      "Epoch 143/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1308 - mse: 0.0300 - mae: 0.1308\n",
      "Epoch 144/1000\n",
      "2919/2919 [==============================] - 0s 31us/step - loss: 0.2044 - mse: 0.0680 - mae: 0.2044\n",
      "Epoch 145/1000\n",
      "2919/2919 [==============================] - 0s 65us/step - loss: 0.1267 - mse: 0.0288 - mae: 0.1267\n",
      "Epoch 146/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1596 - mse: 0.0428 - mae: 0.1596\n",
      "Epoch 147/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1319 - mse: 0.0305 - mae: 0.1319\n",
      "Epoch 148/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1329 - mse: 0.0296 - mae: 0.1329\n",
      "Epoch 149/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1315 - mse: 0.0310 - mae: 0.1315\n",
      "Epoch 150/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1244 - mse: 0.0273 - mae: 0.1244\n",
      "Epoch 151/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1498 - mse: 0.0379 - mae: 0.1498\n",
      "Epoch 152/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1205 - mse: 0.0266 - mae: 0.1205\n",
      "Epoch 153/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1227 - mse: 0.0268 - mae: 0.1227\n",
      "Epoch 154/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1401 - mse: 0.0342 - mae: 0.1401\n",
      "Epoch 155/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1266 - mse: 0.0275 - mae: 0.1266\n",
      "Epoch 156/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1352 - mse: 0.0307 - mae: 0.1352\n",
      "Epoch 157/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1618 - mse: 0.0439 - mae: 0.1618\n",
      "Epoch 158/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1372 - mse: 0.0336 - mae: 0.1372\n",
      "Epoch 159/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1633 - mse: 0.0435 - mae: 0.1633\n",
      "Epoch 160/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1359 - mse: 0.0314 - mae: 0.1359\n",
      "Epoch 161/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1581 - mse: 0.0417 - mae: 0.1581\n",
      "Epoch 162/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1311 - mse: 0.0298 - mae: 0.1311\n",
      "Epoch 163/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1380 - mse: 0.0328 - mae: 0.1380\n",
      "Epoch 164/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1344 - mse: 0.0303 - mae: 0.1344\n",
      "Epoch 165/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1326 - mse: 0.0316 - mae: 0.1326\n",
      "Epoch 166/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1448 - mse: 0.0365 - mae: 0.1448\n",
      "Epoch 167/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1388 - mse: 0.0327 - mae: 0.1388\n",
      "Epoch 168/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1279 - mse: 0.0287 - mae: 0.1279\n",
      "Epoch 169/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1399 - mse: 0.0341 - mae: 0.1399\n",
      "Epoch 170/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1399 - mse: 0.0329 - mae: 0.1399\n",
      "Epoch 171/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1445 - mse: 0.0354 - mae: 0.1445\n",
      "Epoch 172/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1354 - mse: 0.0322 - mae: 0.1354\n",
      "Epoch 173/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1307 - mse: 0.0291 - mae: 0.1307\n",
      "Epoch 174/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1424 - mse: 0.0337 - mae: 0.1424\n",
      "Epoch 175/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1574 - mse: 0.0426 - mae: 0.1574\n",
      "Epoch 176/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1421 - mse: 0.0348 - mae: 0.1421\n",
      "Epoch 177/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1345 - mse: 0.0306 - mae: 0.1345\n",
      "Epoch 178/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1623 - mse: 0.0444 - mae: 0.1623\n",
      "Epoch 179/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1508 - mse: 0.0374 - mae: 0.1508\n",
      "Epoch 180/1000\n",
      "2919/2919 [==============================] - 0s 31us/step - loss: 0.1273 - mse: 0.0281 - mae: 0.1273\n",
      "Epoch 181/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1462 - mse: 0.0364 - mae: 0.1462\n",
      "Epoch 182/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1304 - mse: 0.0292 - mae: 0.1304\n",
      "Epoch 183/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1267 - mse: 0.0283 - mae: 0.1267\n",
      "Epoch 184/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1525 - mse: 0.0388 - mae: 0.1525\n",
      "Epoch 185/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1286 - mse: 0.0284 - mae: 0.1286\n",
      "Epoch 186/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1258 - mse: 0.0282 - mae: 0.1258\n",
      "Epoch 187/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1369 - mse: 0.0331 - mae: 0.1369\n",
      "Epoch 188/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1398 - mse: 0.0357 - mae: 0.1398\n",
      "Epoch 189/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1256 - mse: 0.0273 - mae: 0.1256\n",
      "Epoch 190/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1239 - mse: 0.0269 - mae: 0.1239\n",
      "Epoch 191/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1520 - mse: 0.0391 - mae: 0.1520\n",
      "Epoch 192/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1281 - mse: 0.0288 - mae: 0.1281\n",
      "Epoch 193/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1275 - mse: 0.0280 - mae: 0.1275\n",
      "Epoch 194/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1618 - mse: 0.0429 - mae: 0.1618\n",
      "Epoch 195/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1366 - mse: 0.0320 - mae: 0.1366\n",
      "Epoch 196/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1323 - mse: 0.0299 - mae: 0.1323\n",
      "Epoch 197/1000\n",
      "2919/2919 [==============================] - 0s 31us/step - loss: 0.1266 - mse: 0.0277 - mae: 0.1266\n",
      "Epoch 198/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1276 - mse: 0.0281 - mae: 0.1276\n",
      "Epoch 199/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1317 - mse: 0.0301 - mae: 0.1317\n",
      "Epoch 200/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1403 - mse: 0.0352 - mae: 0.1403\n",
      "Epoch 201/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1639 - mse: 0.0469 - mae: 0.1639\n",
      "Epoch 202/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1959 - mse: 0.0611 - mae: 0.1959\n",
      "Epoch 203/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1336 - mse: 0.0309 - mae: 0.1336\n",
      "Epoch 204/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1269 - mse: 0.0281 - mae: 0.1269\n",
      "Epoch 205/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1295 - mse: 0.0290 - mae: 0.1295\n",
      "Epoch 206/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1244 - mse: 0.0268 - mae: 0.1244\n",
      "Epoch 207/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1374 - mse: 0.0315 - mae: 0.1374\n",
      "Epoch 208/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1434 - mse: 0.0358 - mae: 0.1434\n",
      "Epoch 209/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1227 - mse: 0.0262 - mae: 0.1227\n",
      "Epoch 210/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1410 - mse: 0.0335 - mae: 0.1410\n",
      "Epoch 211/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1296 - mse: 0.0284 - mae: 0.1296\n",
      "Epoch 212/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1319 - mse: 0.0313 - mae: 0.1319\n",
      "Epoch 213/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1278 - mse: 0.0282 - mae: 0.1278\n",
      "Epoch 214/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1281 - mse: 0.0276 - mae: 0.1281\n",
      "Epoch 215/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1365 - mse: 0.0328 - mae: 0.1365\n",
      "Epoch 216/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1438 - mse: 0.0346 - mae: 0.1438\n",
      "Epoch 217/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1622 - mse: 0.0469 - mae: 0.1622\n",
      "Epoch 218/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1280 - mse: 0.0284 - mae: 0.1280\n",
      "Epoch 219/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.1252 - mse: 0.0271 - mae: 0.1252\n",
      "Epoch 220/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.1221 - mse: 0.0257 - mae: 0.1221\n",
      "Epoch 221/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1385 - mse: 0.0335 - mae: 0.1385\n",
      "Epoch 222/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1426 - mse: 0.0344 - mae: 0.1426\n",
      "Epoch 223/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1293 - mse: 0.0286 - mae: 0.1293\n",
      "Epoch 224/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1519 - mse: 0.0431 - mae: 0.1519\n",
      "Epoch 225/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1387 - mse: 0.0318 - mae: 0.1387\n",
      "Epoch 226/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1189 - mse: 0.0241 - mae: 0.1189\n",
      "Epoch 227/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1416 - mse: 0.0338 - mae: 0.1416\n",
      "Epoch 228/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1285 - mse: 0.0286 - mae: 0.1285\n",
      "Epoch 229/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1646 - mse: 0.0443 - mae: 0.1646\n",
      "Epoch 230/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1474 - mse: 0.0364 - mae: 0.1474\n",
      "Epoch 231/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1359 - mse: 0.0303 - mae: 0.1359\n",
      "Epoch 232/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1279 - mse: 0.0283 - mae: 0.1279\n",
      "Epoch 233/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1682 - mse: 0.0458 - mae: 0.1682\n",
      "Epoch 234/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1260 - mse: 0.0267 - mae: 0.1260\n",
      "Epoch 235/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1201 - mse: 0.0255 - mae: 0.1201\n",
      "Epoch 236/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1237 - mse: 0.0268 - mae: 0.1237\n",
      "Epoch 237/1000\n",
      "2919/2919 [==============================] - 0s 55us/step - loss: 0.1371 - mse: 0.0317 - mae: 0.1371\n",
      "Epoch 238/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1339 - mse: 0.0300 - mae: 0.1339\n",
      "Epoch 239/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1334 - mse: 0.0307 - mae: 0.1334\n",
      "Epoch 240/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1193 - mse: 0.0250 - mae: 0.1193\n",
      "Epoch 241/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1317 - mse: 0.0292 - mae: 0.1317\n",
      "Epoch 242/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1292 - mse: 0.0279 - mae: 0.1292\n",
      "Epoch 243/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1330 - mse: 0.0307 - mae: 0.1330\n",
      "Epoch 244/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1211 - mse: 0.0257 - mae: 0.1211\n",
      "Epoch 245/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1273 - mse: 0.0278 - mae: 0.1273\n",
      "Epoch 246/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1661 - mse: 0.0436 - mae: 0.1661\n",
      "Epoch 247/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1304 - mse: 0.0288 - mae: 0.1304\n",
      "Epoch 248/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1227 - mse: 0.0260 - mae: 0.1227\n",
      "Epoch 249/1000\n",
      "2919/2919 [==============================] - 0s 29us/step - loss: 0.1244 - mse: 0.0264 - mae: 0.1244\n",
      "Epoch 250/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1475 - mse: 0.0356 - mae: 0.1475\n",
      "Epoch 251/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1410 - mse: 0.0328 - mae: 0.1410\n",
      "Epoch 252/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1369 - mse: 0.0321 - mae: 0.1369\n",
      "Epoch 253/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1357 - mse: 0.0306 - mae: 0.1357\n",
      "Epoch 254/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1521 - mse: 0.0404 - mae: 0.1521\n",
      "Epoch 255/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1284 - mse: 0.0275 - mae: 0.1284\n",
      "Epoch 256/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1288 - mse: 0.0277 - mae: 0.1288\n",
      "Epoch 257/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1367 - mse: 0.0311 - mae: 0.1367\n",
      "Epoch 258/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1269 - mse: 0.0271 - mae: 0.1269\n",
      "Epoch 259/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1242 - mse: 0.0261 - mae: 0.1242\n",
      "Epoch 260/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1557 - mse: 0.0408 - mae: 0.1557\n",
      "Epoch 261/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1179 - mse: 0.0239 - mae: 0.1179\n",
      "Epoch 262/1000\n",
      "2919/2919 [==============================] - 0s 52us/step - loss: 0.1224 - mse: 0.0252 - mae: 0.1224\n",
      "Epoch 263/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1242 - mse: 0.0257 - mae: 0.1242\n",
      "Epoch 264/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.1297 - mse: 0.0287 - mae: 0.1297\n",
      "Epoch 265/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1336 - mse: 0.0304 - mae: 0.1336\n",
      "Epoch 266/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1210 - mse: 0.0255 - mae: 0.1210\n",
      "Epoch 267/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1231 - mse: 0.0258 - mae: 0.1231\n",
      "Epoch 268/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1485 - mse: 0.0361 - mae: 0.1485\n",
      "Epoch 269/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1560 - mse: 0.0398 - mae: 0.1560\n",
      "Epoch 270/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1348 - mse: 0.0306 - mae: 0.1348\n",
      "Epoch 271/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1357 - mse: 0.0311 - mae: 0.1357\n",
      "Epoch 272/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1371 - mse: 0.0319 - mae: 0.1371\n",
      "Epoch 273/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1246 - mse: 0.0257 - mae: 0.1246\n",
      "Epoch 274/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1537 - mse: 0.0403 - mae: 0.1537\n",
      "Epoch 275/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1126 - mse: 0.0220 - mae: 0.1126\n",
      "Epoch 276/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1222 - mse: 0.0262 - mae: 0.1222\n",
      "Epoch 277/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1207 - mse: 0.0249 - mae: 0.1207\n",
      "Epoch 278/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1305 - mse: 0.0283 - mae: 0.1305\n",
      "Epoch 279/1000\n",
      "2919/2919 [==============================] - 1s 217us/step - loss: 0.1581 - mse: 0.0399 - mae: 0.1581\n",
      "Epoch 280/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1235 - mse: 0.0256 - mae: 0.1235\n",
      "Epoch 281/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1368 - mse: 0.0318 - mae: 0.1368\n",
      "Epoch 282/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1385 - mse: 0.0323 - mae: 0.1385\n",
      "Epoch 283/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1301 - mse: 0.0294 - mae: 0.1301\n",
      "Epoch 284/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1395 - mse: 0.0318 - mae: 0.1395\n",
      "Epoch 285/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1352 - mse: 0.0300 - mae: 0.1352\n",
      "Epoch 286/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1270 - mse: 0.0268 - mae: 0.1270\n",
      "Epoch 287/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1222 - mse: 0.0250 - mae: 0.1222\n",
      "Epoch 288/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1146 - mse: 0.0228 - mae: 0.1146\n",
      "Epoch 289/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1222 - mse: 0.0253 - mae: 0.1222\n",
      "Epoch 290/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1485 - mse: 0.0358 - mae: 0.1485\n",
      "Epoch 291/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1233 - mse: 0.0258 - mae: 0.1233\n",
      "Epoch 292/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1234 - mse: 0.0252 - mae: 0.1234\n",
      "Epoch 293/1000\n",
      "2919/2919 [==============================] - 0s 97us/step - loss: 0.1140 - mse: 0.0219 - mae: 0.1140\n",
      "Epoch 294/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1293 - mse: 0.0274 - mae: 0.1293\n",
      "Epoch 295/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1241 - mse: 0.0255 - mae: 0.1241\n",
      "Epoch 296/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1329 - mse: 0.0291 - mae: 0.1329\n",
      "Epoch 297/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1363 - mse: 0.0306 - mae: 0.1363\n",
      "Epoch 298/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1331 - mse: 0.0294 - mae: 0.1331\n",
      "Epoch 299/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1400 - mse: 0.0341 - mae: 0.1400\n",
      "Epoch 300/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1215 - mse: 0.0244 - mae: 0.1215\n",
      "Epoch 301/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1505 - mse: 0.0365 - mae: 0.1505\n",
      "Epoch 302/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1435 - mse: 0.0337 - mae: 0.1435\n",
      "Epoch 303/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1126 - mse: 0.0214 - mae: 0.1126\n",
      "Epoch 304/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1433 - mse: 0.0338 - mae: 0.1433\n",
      "Epoch 305/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1300 - mse: 0.0275 - mae: 0.1300\n",
      "Epoch 306/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1192 - mse: 0.0239 - mae: 0.1192\n",
      "Epoch 307/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1265 - mse: 0.0267 - mae: 0.1265\n",
      "Epoch 308/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1186 - mse: 0.0235 - mae: 0.1186\n",
      "Epoch 309/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1272 - mse: 0.0265 - mae: 0.1272\n",
      "Epoch 310/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1159 - mse: 0.0220 - mae: 0.1159\n",
      "Epoch 311/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1299 - mse: 0.0276 - mae: 0.1299\n",
      "Epoch 312/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1158 - mse: 0.0224 - mae: 0.1158\n",
      "Epoch 313/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1257 - mse: 0.0266 - mae: 0.1257\n",
      "Epoch 314/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1468 - mse: 0.0338 - mae: 0.1468\n",
      "Epoch 315/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1517 - mse: 0.0375 - mae: 0.1517\n",
      "Epoch 316/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1217 - mse: 0.0238 - mae: 0.1217\n",
      "Epoch 317/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1301 - mse: 0.0279 - mae: 0.1301\n",
      "Epoch 318/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1207 - mse: 0.0240 - mae: 0.1207\n",
      "Epoch 319/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1154 - mse: 0.0217 - mae: 0.1154\n",
      "Epoch 320/1000\n",
      "2919/2919 [==============================] - 0s 31us/step - loss: 0.1267 - mse: 0.0265 - mae: 0.1267\n",
      "Epoch 321/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1160 - mse: 0.0225 - mae: 0.1160\n",
      "Epoch 322/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1396 - mse: 0.0312 - mae: 0.1396\n",
      "Epoch 323/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1372 - mse: 0.0318 - mae: 0.1372\n",
      "Epoch 324/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1136 - mse: 0.0216 - mae: 0.1136\n",
      "Epoch 325/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.1311 - mse: 0.0273 - mae: 0.1311\n",
      "Epoch 326/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1205 - mse: 0.0238 - mae: 0.1205\n",
      "Epoch 327/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1115 - mse: 0.0208 - mae: 0.1115\n",
      "Epoch 328/1000\n",
      "2919/2919 [==============================] - 1s 175us/step - loss: 0.1586 - mse: 0.0408 - mae: 0.1586\n",
      "Epoch 329/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1195 - mse: 0.0241 - mae: 0.1195\n",
      "Epoch 330/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1263 - mse: 0.0261 - mae: 0.1263\n",
      "Epoch 331/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1259 - mse: 0.0263 - mae: 0.1259\n",
      "Epoch 332/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1371 - mse: 0.0309 - mae: 0.1371\n",
      "Epoch 333/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1205 - mse: 0.0239 - mae: 0.1205\n",
      "Epoch 334/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.1338 - mse: 0.0301 - mae: 0.1338\n",
      "Epoch 335/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1174 - mse: 0.0225 - mae: 0.1174\n",
      "Epoch 336/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1130 - mse: 0.0209 - mae: 0.1130\n",
      "Epoch 337/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1229 - mse: 0.0244 - mae: 0.1229\n",
      "Epoch 338/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1208 - mse: 0.0240 - mae: 0.1208\n",
      "Epoch 339/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1211 - mse: 0.0242 - mae: 0.1211\n",
      "Epoch 340/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1176 - mse: 0.0226 - mae: 0.1176\n",
      "Epoch 341/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1555 - mse: 0.0379 - mae: 0.1555\n",
      "Epoch 342/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1108 - mse: 0.0199 - mae: 0.1108\n",
      "Epoch 343/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1208 - mse: 0.0234 - mae: 0.1208\n",
      "Epoch 344/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1274 - mse: 0.0261 - mae: 0.1274\n",
      "Epoch 345/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1234 - mse: 0.0243 - mae: 0.1234\n",
      "Epoch 346/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1277 - mse: 0.0262 - mae: 0.1277\n",
      "Epoch 347/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1167 - mse: 0.0233 - mae: 0.1167\n",
      "Epoch 348/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1245 - mse: 0.0253 - mae: 0.1245\n",
      "Epoch 349/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1075 - mse: 0.0189 - mae: 0.1075\n",
      "Epoch 350/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1106 - mse: 0.0201 - mae: 0.1106\n",
      "Epoch 351/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1264 - mse: 0.0254 - mae: 0.1264\n",
      "Epoch 352/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1098 - mse: 0.0201 - mae: 0.1098\n",
      "Epoch 353/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1074 - mse: 0.0193 - mae: 0.1074\n",
      "Epoch 354/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1226 - mse: 0.0242 - mae: 0.1226\n",
      "Epoch 355/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1258 - mse: 0.0268 - mae: 0.1258\n",
      "Epoch 356/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1483 - mse: 0.0357 - mae: 0.1483\n",
      "Epoch 357/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1206 - mse: 0.0236 - mae: 0.1206\n",
      "Epoch 358/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1403 - mse: 0.0325 - mae: 0.1403\n",
      "Epoch 359/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1181 - mse: 0.0232 - mae: 0.1181\n",
      "Epoch 360/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1280 - mse: 0.0259 - mae: 0.1280\n",
      "Epoch 361/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1374 - mse: 0.0341 - mae: 0.1374\n",
      "Epoch 362/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1174 - mse: 0.0231 - mae: 0.1174\n",
      "Epoch 363/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1120 - mse: 0.0208 - mae: 0.1120\n",
      "Epoch 364/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1246 - mse: 0.0254 - mae: 0.1246\n",
      "Epoch 365/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1363 - mse: 0.0296 - mae: 0.1363\n",
      "Epoch 366/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1198 - mse: 0.0238 - mae: 0.1198\n",
      "Epoch 367/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1352 - mse: 0.0286 - mae: 0.1352\n",
      "Epoch 368/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1184 - mse: 0.0226 - mae: 0.1184\n",
      "Epoch 369/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1305 - mse: 0.0272 - mae: 0.1305\n",
      "Epoch 370/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1039 - mse: 0.0180 - mae: 0.1039\n",
      "Epoch 371/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1437 - mse: 0.0328 - mae: 0.1437\n",
      "Epoch 372/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1115 - mse: 0.0205 - mae: 0.1115\n",
      "Epoch 373/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1050 - mse: 0.0183 - mae: 0.1050\n",
      "Epoch 374/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1080 - mse: 0.0192 - mae: 0.1080\n",
      "Epoch 375/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1369 - mse: 0.0317 - mae: 0.1369\n",
      "Epoch 376/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1157 - mse: 0.0219 - mae: 0.1157\n",
      "Epoch 377/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1230 - mse: 0.0250 - mae: 0.1230\n",
      "Epoch 378/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1333 - mse: 0.0284 - mae: 0.1333\n",
      "Epoch 379/1000\n",
      "2919/2919 [==============================] - 0s 83us/step - loss: 0.1451 - mse: 0.0345 - mae: 0.1451\n",
      "Epoch 380/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1203 - mse: 0.0237 - mae: 0.1203\n",
      "Epoch 381/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1296 - mse: 0.0277 - mae: 0.1296\n",
      "Epoch 382/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.0994 - mse: 0.0165 - mae: 0.0994\n",
      "Epoch 383/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1359 - mse: 0.0320 - mae: 0.1359\n",
      "Epoch 384/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1118 - mse: 0.0208 - mae: 0.1118\n",
      "Epoch 385/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1313 - mse: 0.0281 - mae: 0.1313\n",
      "Epoch 386/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1081 - mse: 0.0200 - mae: 0.1081\n",
      "Epoch 387/1000\n",
      "2919/2919 [==============================] - 0s 56us/step - loss: 0.1113 - mse: 0.0203 - mae: 0.1113\n",
      "Epoch 388/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.1123 - mse: 0.0210 - mae: 0.1123\n",
      "Epoch 389/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1102 - mse: 0.0199 - mae: 0.1102\n",
      "Epoch 390/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1173 - mse: 0.0223 - mae: 0.1173\n",
      "Epoch 391/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1151 - mse: 0.0216 - mae: 0.1151\n",
      "Epoch 392/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1003 - mse: 0.0167 - mae: 0.1003\n",
      "Epoch 393/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1134 - mse: 0.0215 - mae: 0.1134\n",
      "Epoch 394/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1136 - mse: 0.0212 - mae: 0.1136\n",
      "Epoch 395/1000\n",
      "2919/2919 [==============================] - 0s 55us/step - loss: 0.1315 - mse: 0.0283 - mae: 0.1315\n",
      "Epoch 396/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1060 - mse: 0.0191 - mae: 0.1060\n",
      "Epoch 397/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1107 - mse: 0.0203 - mae: 0.1107\n",
      "Epoch 398/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1460 - mse: 0.0346 - mae: 0.1460\n",
      "Epoch 399/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1491 - mse: 0.0356 - mae: 0.1491\n",
      "Epoch 400/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1386 - mse: 0.0313 - mae: 0.1386\n",
      "Epoch 401/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1053 - mse: 0.0176 - mae: 0.1053\n",
      "Epoch 402/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.1213 - mse: 0.0242 - mae: 0.1213\n",
      "Epoch 403/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1379 - mse: 0.0303 - mae: 0.1379\n",
      "Epoch 404/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1129 - mse: 0.0212 - mae: 0.1129\n",
      "Epoch 405/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1128 - mse: 0.0210 - mae: 0.1128\n",
      "Epoch 406/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1308 - mse: 0.0280 - mae: 0.1308\n",
      "Epoch 407/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1247 - mse: 0.0263 - mae: 0.1247\n",
      "Epoch 408/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1487 - mse: 0.0355 - mae: 0.1487\n",
      "Epoch 409/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1153 - mse: 0.0220 - mae: 0.1153\n",
      "Epoch 410/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1146 - mse: 0.0215 - mae: 0.1146\n",
      "Epoch 411/1000\n",
      "2919/2919 [==============================] - 0s 57us/step - loss: 0.1156 - mse: 0.0213 - mae: 0.1156\n",
      "Epoch 412/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1047 - mse: 0.0184 - mae: 0.1047\n",
      "Epoch 413/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1280 - mse: 0.0269 - mae: 0.1280\n",
      "Epoch 414/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1296 - mse: 0.0269 - mae: 0.1296\n",
      "Epoch 415/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1195 - mse: 0.0234 - mae: 0.1195\n",
      "Epoch 416/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1267 - mse: 0.0259 - mae: 0.1267\n",
      "Epoch 417/1000\n",
      "2919/2919 [==============================] - 0s 52us/step - loss: 0.1195 - mse: 0.0232 - mae: 0.1195\n",
      "Epoch 418/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1068 - mse: 0.0190 - mae: 0.1068\n",
      "Epoch 419/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1193 - mse: 0.0231 - mae: 0.1193\n",
      "Epoch 420/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1155 - mse: 0.0220 - mae: 0.1155\n",
      "Epoch 421/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1141 - mse: 0.0217 - mae: 0.1141\n",
      "Epoch 422/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1001 - mse: 0.0165 - mae: 0.1001\n",
      "Epoch 423/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1071 - mse: 0.0191 - mae: 0.1071\n",
      "Epoch 424/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1102 - mse: 0.0200 - mae: 0.1102\n",
      "Epoch 425/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1176 - mse: 0.0226 - mae: 0.1176\n",
      "Epoch 426/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1177 - mse: 0.0230 - mae: 0.1177\n",
      "Epoch 427/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1546 - mse: 0.0399 - mae: 0.1546\n",
      "Epoch 428/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1305 - mse: 0.0276 - mae: 0.1305\n",
      "Epoch 429/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1520 - mse: 0.0373 - mae: 0.1520\n",
      "Epoch 430/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.0991 - mse: 0.0164 - mae: 0.0991\n",
      "Epoch 431/1000\n",
      "2919/2919 [==============================] - 0s 28us/step - loss: 0.1053 - mse: 0.0182 - mae: 0.1053\n",
      "Epoch 432/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1071 - mse: 0.0189 - mae: 0.1071\n",
      "Epoch 433/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1080 - mse: 0.0192 - mae: 0.1080\n",
      "Epoch 434/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1041 - mse: 0.0183 - mae: 0.1041\n",
      "Epoch 435/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1067 - mse: 0.0190 - mae: 0.1067\n",
      "Epoch 436/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1010 - mse: 0.0175 - mae: 0.1010\n",
      "Epoch 437/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.0975 - mse: 0.0162 - mae: 0.0975\n",
      "Epoch 438/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1103 - mse: 0.0204 - mae: 0.1103\n",
      "Epoch 439/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1081 - mse: 0.0197 - mae: 0.1081\n",
      "Epoch 440/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1177 - mse: 0.0234 - mae: 0.1177\n",
      "Epoch 441/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1243 - mse: 0.0255 - mae: 0.1243\n",
      "Epoch 442/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1113 - mse: 0.0202 - mae: 0.1113\n",
      "Epoch 443/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1124 - mse: 0.0213 - mae: 0.1124\n",
      "Epoch 444/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1282 - mse: 0.0264 - mae: 0.1282\n",
      "Epoch 445/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1541 - mse: 0.0399 - mae: 0.1541\n",
      "Epoch 446/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1470 - mse: 0.0340 - mae: 0.1470\n",
      "Epoch 447/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1095 - mse: 0.0201 - mae: 0.1095\n",
      "Epoch 448/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1141 - mse: 0.0214 - mae: 0.1141\n",
      "Epoch 449/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1308 - mse: 0.0274 - mae: 0.1308\n",
      "Epoch 450/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1051 - mse: 0.0183 - mae: 0.1051\n",
      "Epoch 451/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1241 - mse: 0.0254 - mae: 0.1241\n",
      "Epoch 452/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1097 - mse: 0.0197 - mae: 0.1097\n",
      "Epoch 453/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1190 - mse: 0.0225 - mae: 0.1190\n",
      "Epoch 454/1000\n",
      "2919/2919 [==============================] - 0s 52us/step - loss: 0.1017 - mse: 0.0176 - mae: 0.1017\n",
      "Epoch 455/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.1117 - mse: 0.0212 - mae: 0.1117\n",
      "Epoch 456/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1003 - mse: 0.0178 - mae: 0.1003\n",
      "Epoch 457/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1114 - mse: 0.0204 - mae: 0.1114\n",
      "Epoch 458/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1109 - mse: 0.0203 - mae: 0.1109\n",
      "Epoch 459/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1356 - mse: 0.0293 - mae: 0.1356\n",
      "Epoch 460/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1510 - mse: 0.0367 - mae: 0.1510\n",
      "Epoch 461/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1093 - mse: 0.0198 - mae: 0.1093\n",
      "Epoch 462/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1061 - mse: 0.0193 - mae: 0.1061\n",
      "Epoch 463/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1141 - mse: 0.0213 - mae: 0.1141\n",
      "Epoch 464/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1208 - mse: 0.0242 - mae: 0.1208\n",
      "Epoch 465/1000\n",
      "2919/2919 [==============================] - 0s 55us/step - loss: 0.1367 - mse: 0.0306 - mae: 0.1367\n",
      "Epoch 466/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1572 - mse: 0.0406 - mae: 0.1572\n",
      "Epoch 467/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1058 - mse: 0.0183 - mae: 0.1058\n",
      "Epoch 468/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1298 - mse: 0.0276 - mae: 0.1298\n",
      "Epoch 469/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1073 - mse: 0.0192 - mae: 0.1073\n",
      "Epoch 470/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1009 - mse: 0.0173 - mae: 0.1009\n",
      "Epoch 471/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1141 - mse: 0.0214 - mae: 0.1141\n",
      "Epoch 472/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1093 - mse: 0.0201 - mae: 0.1093\n",
      "Epoch 473/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.0983 - mse: 0.0163 - mae: 0.0983\n",
      "Epoch 474/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1185 - mse: 0.0237 - mae: 0.1185\n",
      "Epoch 475/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1049 - mse: 0.0185 - mae: 0.1049\n",
      "Epoch 476/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1113 - mse: 0.0211 - mae: 0.1113\n",
      "Epoch 477/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.0996 - mse: 0.0171 - mae: 0.0996\n",
      "Epoch 478/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1121 - mse: 0.0212 - mae: 0.1121\n",
      "Epoch 479/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1275 - mse: 0.0265 - mae: 0.1275\n",
      "Epoch 480/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1210 - mse: 0.0244 - mae: 0.1210\n",
      "Epoch 481/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1340 - mse: 0.0293 - mae: 0.1340\n",
      "Epoch 482/1000\n",
      "2919/2919 [==============================] - 0s 52us/step - loss: 0.1059 - mse: 0.0185 - mae: 0.1059\n",
      "Epoch 483/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1166 - mse: 0.0224 - mae: 0.1166\n",
      "Epoch 484/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1157 - mse: 0.0234 - mae: 0.1157\n",
      "Epoch 485/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1597 - mse: 0.0405 - mae: 0.1597\n",
      "Epoch 486/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1378 - mse: 0.0313 - mae: 0.1378\n",
      "Epoch 487/1000\n",
      "2919/2919 [==============================] - 0s 52us/step - loss: 0.1351 - mse: 0.0309 - mae: 0.1351\n",
      "Epoch 488/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1176 - mse: 0.0229 - mae: 0.1176\n",
      "Epoch 489/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.0980 - mse: 0.0163 - mae: 0.0980\n",
      "Epoch 490/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1214 - mse: 0.0239 - mae: 0.1214\n",
      "Epoch 491/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1052 - mse: 0.0185 - mae: 0.1052\n",
      "Epoch 492/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1139 - mse: 0.0211 - mae: 0.1139\n",
      "Epoch 493/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1154 - mse: 0.0217 - mae: 0.1154\n",
      "Epoch 494/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1023 - mse: 0.0176 - mae: 0.1023\n",
      "Epoch 495/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1067 - mse: 0.0184 - mae: 0.1067\n",
      "Epoch 496/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1120 - mse: 0.0200 - mae: 0.1120\n",
      "Epoch 497/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1521 - mse: 0.0365 - mae: 0.1521\n",
      "Epoch 498/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1086 - mse: 0.0192 - mae: 0.1086\n",
      "Epoch 499/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1356 - mse: 0.0292 - mae: 0.1356\n",
      "Epoch 500/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1089 - mse: 0.0205 - mae: 0.1089\n",
      "Epoch 501/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1149 - mse: 0.0220 - mae: 0.1149\n",
      "Epoch 502/1000\n",
      "2919/2919 [==============================] - 0s 30us/step - loss: 0.1162 - mse: 0.0218 - mae: 0.1162\n",
      "Epoch 503/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1076 - mse: 0.0193 - mae: 0.1076\n",
      "Epoch 504/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1059 - mse: 0.0188 - mae: 0.1059\n",
      "Epoch 505/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1127 - mse: 0.0211 - mae: 0.1127\n",
      "Epoch 506/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1040 - mse: 0.0177 - mae: 0.1040\n",
      "Epoch 507/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1076 - mse: 0.0193 - mae: 0.1076\n",
      "Epoch 508/1000\n",
      "2919/2919 [==============================] - 0s 133us/step - loss: 0.1019 - mse: 0.0172 - mae: 0.1019\n",
      "Epoch 509/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.0980 - mse: 0.0163 - mae: 0.0980\n",
      "Epoch 510/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1108 - mse: 0.0207 - mae: 0.1108\n",
      "Epoch 511/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1225 - mse: 0.0247 - mae: 0.1225\n",
      "Epoch 512/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1051 - mse: 0.0185 - mae: 0.1051\n",
      "Epoch 513/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.1384 - mse: 0.0328 - mae: 0.1384\n",
      "Epoch 514/1000\n",
      "2919/2919 [==============================] - 0s 53us/step - loss: 0.1167 - mse: 0.0220 - mae: 0.1167\n",
      "Epoch 515/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1121 - mse: 0.0209 - mae: 0.1121\n",
      "Epoch 516/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1233 - mse: 0.0247 - mae: 0.1233\n",
      "Epoch 517/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1159 - mse: 0.0233 - mae: 0.1159\n",
      "Epoch 518/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1316 - mse: 0.0283 - mae: 0.1316\n",
      "Epoch 519/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1178 - mse: 0.0232 - mae: 0.1178\n",
      "Epoch 520/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1082 - mse: 0.0193 - mae: 0.1082\n",
      "Epoch 521/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.0979 - mse: 0.0161 - mae: 0.0979\n",
      "Epoch 522/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1460 - mse: 0.0335 - mae: 0.1460\n",
      "Epoch 523/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1297 - mse: 0.0271 - mae: 0.1297\n",
      "Epoch 524/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1130 - mse: 0.0204 - mae: 0.1130\n",
      "Epoch 525/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1334 - mse: 0.0297 - mae: 0.1334\n",
      "Epoch 526/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1305 - mse: 0.0283 - mae: 0.1305\n",
      "Epoch 527/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1061 - mse: 0.0182 - mae: 0.1061\n",
      "Epoch 528/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1216 - mse: 0.0237 - mae: 0.1216\n",
      "Epoch 529/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1156 - mse: 0.0225 - mae: 0.1156\n",
      "Epoch 530/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1305 - mse: 0.0267 - mae: 0.1305\n",
      "Epoch 531/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1158 - mse: 0.0231 - mae: 0.1158\n",
      "Epoch 532/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.0940 - mse: 0.0147 - mae: 0.0940\n",
      "Epoch 533/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1034 - mse: 0.0179 - mae: 0.1034\n",
      "Epoch 534/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1013 - mse: 0.0169 - mae: 0.1013\n",
      "Epoch 535/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.0984 - mse: 0.0164 - mae: 0.0984\n",
      "Epoch 536/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0978 - mse: 0.0160 - mae: 0.0978\n",
      "Epoch 537/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1056 - mse: 0.0183 - mae: 0.1056\n",
      "Epoch 538/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1148 - mse: 0.0214 - mae: 0.1148\n",
      "Epoch 539/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1044 - mse: 0.0182 - mae: 0.1044\n",
      "Epoch 540/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0986 - mse: 0.0165 - mae: 0.0986\n",
      "Epoch 541/1000\n",
      "2919/2919 [==============================] - 1s 238us/step - loss: 0.1444 - mse: 0.0334 - mae: 0.1444\n",
      "Epoch 542/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1160 - mse: 0.0234 - mae: 0.1160\n",
      "Epoch 543/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.1116 - mse: 0.0206 - mae: 0.1116\n",
      "Epoch 544/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1055 - mse: 0.0183 - mae: 0.1055\n",
      "Epoch 545/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1353 - mse: 0.0304 - mae: 0.1353\n",
      "Epoch 546/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1148 - mse: 0.0219 - mae: 0.1148\n",
      "Epoch 547/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1208 - mse: 0.0244 - mae: 0.1208\n",
      "Epoch 548/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1030 - mse: 0.0182 - mae: 0.1030\n",
      "Epoch 549/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1220 - mse: 0.0243 - mae: 0.1220\n",
      "Epoch 550/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1122 - mse: 0.0206 - mae: 0.1122\n",
      "Epoch 551/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1015 - mse: 0.0166 - mae: 0.1015\n",
      "Epoch 552/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1234 - mse: 0.0247 - mae: 0.1234\n",
      "Epoch 553/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1158 - mse: 0.0217 - mae: 0.1158\n",
      "Epoch 554/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1158 - mse: 0.0223 - mae: 0.1158\n",
      "Epoch 555/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1016 - mse: 0.0175 - mae: 0.1016\n",
      "Epoch 556/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.0998 - mse: 0.0167 - mae: 0.0998\n",
      "Epoch 557/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.0976 - mse: 0.0161 - mae: 0.0976\n",
      "Epoch 558/1000\n",
      "2919/2919 [==============================] - 0s 57us/step - loss: 0.1048 - mse: 0.0181 - mae: 0.1048\n",
      "Epoch 559/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1050 - mse: 0.0185 - mae: 0.1050\n",
      "Epoch 560/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0922 - mse: 0.0146 - mae: 0.0922\n",
      "Epoch 561/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1263 - mse: 0.0253 - mae: 0.1263\n",
      "Epoch 562/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1030 - mse: 0.0172 - mae: 0.1030\n",
      "Epoch 563/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1132 - mse: 0.0213 - mae: 0.1132\n",
      "Epoch 564/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1037 - mse: 0.0178 - mae: 0.1037\n",
      "Epoch 565/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1209 - mse: 0.0234 - mae: 0.1209\n",
      "Epoch 566/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1292 - mse: 0.0280 - mae: 0.1292\n",
      "Epoch 567/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1000 - mse: 0.0173 - mae: 0.1000\n",
      "Epoch 568/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.0990 - mse: 0.0162 - mae: 0.0990\n",
      "Epoch 569/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1502 - mse: 0.0375 - mae: 0.1503\n",
      "Epoch 570/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1155 - mse: 0.0220 - mae: 0.1155\n",
      "Epoch 571/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1217 - mse: 0.0250 - mae: 0.1217\n",
      "Epoch 572/1000\n",
      "2919/2919 [==============================] - 0s 31us/step - loss: 0.0941 - mse: 0.0152 - mae: 0.0941\n",
      "Epoch 573/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1438 - mse: 0.0333 - mae: 0.1438\n",
      "Epoch 574/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1149 - mse: 0.0215 - mae: 0.1149\n",
      "Epoch 575/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.0993 - mse: 0.0168 - mae: 0.0993\n",
      "Epoch 576/1000\n",
      "2919/2919 [==============================] - 0s 129us/step - loss: 0.0997 - mse: 0.0167 - mae: 0.0997\n",
      "Epoch 577/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.0989 - mse: 0.0159 - mae: 0.0989\n",
      "Epoch 578/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1060 - mse: 0.0181 - mae: 0.1060\n",
      "Epoch 579/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0963 - mse: 0.0158 - mae: 0.0963\n",
      "Epoch 580/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1283 - mse: 0.0263 - mae: 0.1283\n",
      "Epoch 581/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.0986 - mse: 0.0164 - mae: 0.0986\n",
      "Epoch 582/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1171 - mse: 0.0224 - mae: 0.1171\n",
      "Epoch 583/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1039 - mse: 0.0183 - mae: 0.1039\n",
      "Epoch 584/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1216 - mse: 0.0239 - mae: 0.1216\n",
      "Epoch 585/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1135 - mse: 0.0220 - mae: 0.1135\n",
      "Epoch 586/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.1099 - mse: 0.0206 - mae: 0.1099\n",
      "Epoch 587/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1324 - mse: 0.0289 - mae: 0.1324\n",
      "Epoch 588/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1146 - mse: 0.0215 - mae: 0.1146\n",
      "Epoch 589/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1234 - mse: 0.0250 - mae: 0.1234\n",
      "Epoch 590/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1017 - mse: 0.0174 - mae: 0.1017\n",
      "Epoch 591/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0944 - mse: 0.0149 - mae: 0.0944\n",
      "Epoch 592/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1060 - mse: 0.0181 - mae: 0.1060\n",
      "Epoch 593/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1125 - mse: 0.0223 - mae: 0.1125\n",
      "Epoch 594/1000\n",
      "2919/2919 [==============================] - 1s 194us/step - loss: 0.1123 - mse: 0.0209 - mae: 0.1123\n",
      "Epoch 595/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.0958 - mse: 0.0154 - mae: 0.0958\n",
      "Epoch 596/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1125 - mse: 0.0206 - mae: 0.1125\n",
      "Epoch 597/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1123 - mse: 0.0210 - mae: 0.1123\n",
      "Epoch 598/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1272 - mse: 0.0279 - mae: 0.1272\n",
      "Epoch 599/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1217 - mse: 0.0232 - mae: 0.1217\n",
      "Epoch 600/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1038 - mse: 0.0182 - mae: 0.1038\n",
      "Epoch 601/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.0910 - mse: 0.0142 - mae: 0.0910\n",
      "Epoch 602/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1279 - mse: 0.0269 - mae: 0.1279\n",
      "Epoch 603/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1256 - mse: 0.0252 - mae: 0.1256\n",
      "Epoch 604/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1287 - mse: 0.0264 - mae: 0.1287\n",
      "Epoch 605/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1090 - mse: 0.0204 - mae: 0.1090\n",
      "Epoch 606/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1112 - mse: 0.0210 - mae: 0.1112\n",
      "Epoch 607/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1050 - mse: 0.0182 - mae: 0.1050\n",
      "Epoch 608/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1040 - mse: 0.0182 - mae: 0.1040\n",
      "Epoch 609/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1142 - mse: 0.0212 - mae: 0.1142\n",
      "Epoch 610/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1029 - mse: 0.0174 - mae: 0.1029\n",
      "Epoch 611/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1091 - mse: 0.0190 - mae: 0.1091\n",
      "Epoch 612/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.1213 - mse: 0.0238 - mae: 0.1213\n",
      "Epoch 613/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.0973 - mse: 0.0160 - mae: 0.0973\n",
      "Epoch 614/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.0988 - mse: 0.0166 - mae: 0.0988\n",
      "Epoch 615/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1139 - mse: 0.0212 - mae: 0.1139\n",
      "Epoch 616/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1098 - mse: 0.0197 - mae: 0.1098\n",
      "Epoch 617/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1137 - mse: 0.0214 - mae: 0.1137\n",
      "Epoch 618/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1004 - mse: 0.0169 - mae: 0.1004\n",
      "Epoch 619/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0930 - mse: 0.0152 - mae: 0.0930\n",
      "Epoch 620/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1015 - mse: 0.0170 - mae: 0.1015\n",
      "Epoch 621/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1034 - mse: 0.0183 - mae: 0.1034\n",
      "Epoch 622/1000\n",
      "2919/2919 [==============================] - 0s 57us/step - loss: 0.0976 - mse: 0.0159 - mae: 0.0976\n",
      "Epoch 623/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1010 - mse: 0.0171 - mae: 0.1010\n",
      "Epoch 624/1000\n",
      "2919/2919 [==============================] - 0s 54us/step - loss: 0.1204 - mse: 0.0236 - mae: 0.1204\n",
      "Epoch 625/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1082 - mse: 0.0191 - mae: 0.1082\n",
      "Epoch 626/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0998 - mse: 0.0169 - mae: 0.0998\n",
      "Epoch 627/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1097 - mse: 0.0203 - mae: 0.1097\n",
      "Epoch 628/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.0983 - mse: 0.0172 - mae: 0.0983\n",
      "Epoch 629/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0996 - mse: 0.0167 - mae: 0.0996\n",
      "Epoch 630/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1452 - mse: 0.0343 - mae: 0.1452\n",
      "Epoch 631/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1024 - mse: 0.0180 - mae: 0.1024\n",
      "Epoch 632/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1222 - mse: 0.0262 - mae: 0.1222\n",
      "Epoch 633/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1038 - mse: 0.0187 - mae: 0.1038\n",
      "Epoch 634/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1099 - mse: 0.0206 - mae: 0.1099\n",
      "Epoch 635/1000\n",
      "2919/2919 [==============================] - 0s 151us/step - loss: 0.1060 - mse: 0.0197 - mae: 0.1060\n",
      "Epoch 636/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1435 - mse: 0.0346 - mae: 0.1435\n",
      "Epoch 637/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.0984 - mse: 0.0167 - mae: 0.0984\n",
      "Epoch 638/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1205 - mse: 0.0244 - mae: 0.1205\n",
      "Epoch 639/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1063 - mse: 0.0202 - mae: 0.1063\n",
      "Epoch 640/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1396 - mse: 0.0357 - mae: 0.1396\n",
      "Epoch 641/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1066 - mse: 0.0185 - mae: 0.1066\n",
      "Epoch 642/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1316 - mse: 0.0287 - mae: 0.1316\n",
      "Epoch 643/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1041 - mse: 0.0179 - mae: 0.1041\n",
      "Epoch 644/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.1005 - mse: 0.0175 - mae: 0.1005\n",
      "Epoch 645/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1142 - mse: 0.0220 - mae: 0.1142\n",
      "Epoch 646/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1128 - mse: 0.0224 - mae: 0.1128\n",
      "Epoch 647/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.0966 - mse: 0.0162 - mae: 0.0966\n",
      "Epoch 648/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.0930 - mse: 0.0150 - mae: 0.0930\n",
      "Epoch 649/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1063 - mse: 0.0186 - mae: 0.1063\n",
      "Epoch 650/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1085 - mse: 0.0196 - mae: 0.1085\n",
      "Epoch 651/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1306 - mse: 0.0276 - mae: 0.1306\n",
      "Epoch 652/1000\n",
      "2919/2919 [==============================] - 0s 52us/step - loss: 0.0918 - mse: 0.0147 - mae: 0.0918\n",
      "Epoch 653/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.0944 - mse: 0.0152 - mae: 0.0944\n",
      "Epoch 654/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1009 - mse: 0.0182 - mae: 0.1009\n",
      "Epoch 655/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.0976 - mse: 0.0160 - mae: 0.0976\n",
      "Epoch 656/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.0938 - mse: 0.0152 - mae: 0.0938\n",
      "Epoch 657/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0966 - mse: 0.0162 - mae: 0.0966\n",
      "Epoch 658/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1298 - mse: 0.0281 - mae: 0.1298\n",
      "Epoch 659/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1250 - mse: 0.0258 - mae: 0.1250\n",
      "Epoch 660/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1090 - mse: 0.0208 - mae: 0.1090\n",
      "Epoch 661/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1158 - mse: 0.0223 - mae: 0.1158\n",
      "Epoch 662/1000\n",
      "2919/2919 [==============================] - 0s 58us/step - loss: 0.0999 - mse: 0.0171 - mae: 0.0999\n",
      "Epoch 663/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1336 - mse: 0.0320 - mae: 0.1336\n",
      "Epoch 664/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1381 - mse: 0.0309 - mae: 0.1381\n",
      "Epoch 665/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1011 - mse: 0.0171 - mae: 0.1011\n",
      "Epoch 666/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1387 - mse: 0.0317 - mae: 0.1387\n",
      "Epoch 667/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1122 - mse: 0.0212 - mae: 0.1122\n",
      "Epoch 668/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1112 - mse: 0.0212 - mae: 0.1112\n",
      "Epoch 669/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0997 - mse: 0.0167 - mae: 0.0997\n",
      "Epoch 670/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1028 - mse: 0.0175 - mae: 0.1028\n",
      "Epoch 671/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1311 - mse: 0.0275 - mae: 0.1311\n",
      "Epoch 672/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1110 - mse: 0.0204 - mae: 0.1110\n",
      "Epoch 673/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1227 - mse: 0.0244 - mae: 0.1227\n",
      "Epoch 674/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1016 - mse: 0.0173 - mae: 0.1016\n",
      "Epoch 675/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1567 - mse: 0.0390 - mae: 0.1567\n",
      "Epoch 676/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1035 - mse: 0.0182 - mae: 0.1035\n",
      "Epoch 677/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.0999 - mse: 0.0170 - mae: 0.0999\n",
      "Epoch 678/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1058 - mse: 0.0192 - mae: 0.1058\n",
      "Epoch 679/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1234 - mse: 0.0243 - mae: 0.1234\n",
      "Epoch 680/1000\n",
      "2919/2919 [==============================] - 1s 212us/step - loss: 0.1303 - mse: 0.0272 - mae: 0.1303\n",
      "Epoch 681/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1054 - mse: 0.0194 - mae: 0.1054\n",
      "Epoch 682/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1143 - mse: 0.0206 - mae: 0.1143\n",
      "Epoch 683/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0913 - mse: 0.0144 - mae: 0.0913\n",
      "Epoch 684/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0972 - mse: 0.0155 - mae: 0.0972\n",
      "Epoch 685/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1024 - mse: 0.0176 - mae: 0.1024\n",
      "Epoch 686/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0971 - mse: 0.0155 - mae: 0.0971\n",
      "Epoch 687/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1108 - mse: 0.0212 - mae: 0.1108\n",
      "Epoch 688/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.0953 - mse: 0.0152 - mae: 0.0953\n",
      "Epoch 689/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1004 - mse: 0.0173 - mae: 0.1004\n",
      "Epoch 690/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1115 - mse: 0.0207 - mae: 0.1115\n",
      "Epoch 691/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1146 - mse: 0.0220 - mae: 0.1146\n",
      "Epoch 692/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0993 - mse: 0.0163 - mae: 0.0993\n",
      "Epoch 693/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1138 - mse: 0.0209 - mae: 0.1138\n",
      "Epoch 694/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1052 - mse: 0.0183 - mae: 0.1052\n",
      "Epoch 695/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0962 - mse: 0.0160 - mae: 0.0962\n",
      "Epoch 696/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1131 - mse: 0.0218 - mae: 0.1131\n",
      "Epoch 697/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1019 - mse: 0.0175 - mae: 0.1019\n",
      "Epoch 698/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1136 - mse: 0.0212 - mae: 0.1136\n",
      "Epoch 699/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1113 - mse: 0.0198 - mae: 0.1113\n",
      "Epoch 700/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1092 - mse: 0.0194 - mae: 0.1092\n",
      "Epoch 701/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.0973 - mse: 0.0158 - mae: 0.0973\n",
      "Epoch 702/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1085 - mse: 0.0195 - mae: 0.1085\n",
      "Epoch 703/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1090 - mse: 0.0192 - mae: 0.1090\n",
      "Epoch 704/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.0932 - mse: 0.0149 - mae: 0.0932\n",
      "Epoch 705/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1379 - mse: 0.0329 - mae: 0.1379\n",
      "Epoch 706/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1019 - mse: 0.0173 - mae: 0.1019\n",
      "Epoch 707/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1026 - mse: 0.0180 - mae: 0.1026\n",
      "Epoch 708/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1059 - mse: 0.0187 - mae: 0.1059\n",
      "Epoch 709/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1109 - mse: 0.0201 - mae: 0.1109\n",
      "Epoch 710/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1302 - mse: 0.0273 - mae: 0.1302\n",
      "Epoch 711/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0927 - mse: 0.0145 - mae: 0.0927\n",
      "Epoch 712/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1321 - mse: 0.0280 - mae: 0.1321\n",
      "Epoch 713/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1040 - mse: 0.0183 - mae: 0.1040\n",
      "Epoch 714/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.0995 - mse: 0.0165 - mae: 0.0995\n",
      "Epoch 715/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1408 - mse: 0.0316 - mae: 0.1408\n",
      "Epoch 716/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1056 - mse: 0.0181 - mae: 0.1056\n",
      "Epoch 717/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1135 - mse: 0.0209 - mae: 0.1135\n",
      "Epoch 718/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.0991 - mse: 0.0166 - mae: 0.0991\n",
      "Epoch 719/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1056 - mse: 0.0181 - mae: 0.1056\n",
      "Epoch 720/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1216 - mse: 0.0244 - mae: 0.1216\n",
      "Epoch 721/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.0988 - mse: 0.0162 - mae: 0.0988\n",
      "Epoch 722/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.0967 - mse: 0.0156 - mae: 0.0967\n",
      "Epoch 723/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1145 - mse: 0.0214 - mae: 0.1145\n",
      "Epoch 724/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0937 - mse: 0.0150 - mae: 0.0937\n",
      "Epoch 725/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1191 - mse: 0.0238 - mae: 0.1191\n",
      "Epoch 726/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0973 - mse: 0.0159 - mae: 0.0973\n",
      "Epoch 727/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.0953 - mse: 0.0155 - mae: 0.0953\n",
      "Epoch 728/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1182 - mse: 0.0226 - mae: 0.1182\n",
      "Epoch 729/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1283 - mse: 0.0284 - mae: 0.1283\n",
      "Epoch 730/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1034 - mse: 0.0178 - mae: 0.1034\n",
      "Epoch 731/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.0943 - mse: 0.0152 - mae: 0.0943\n",
      "Epoch 732/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1298 - mse: 0.0283 - mae: 0.1298\n",
      "Epoch 733/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1047 - mse: 0.0183 - mae: 0.1047\n",
      "Epoch 734/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1036 - mse: 0.0178 - mae: 0.1036\n",
      "Epoch 735/1000\n",
      "2919/2919 [==============================] - 0s 98us/step - loss: 0.0971 - mse: 0.0160 - mae: 0.0971\n",
      "Epoch 736/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1111 - mse: 0.0200 - mae: 0.1111\n",
      "Epoch 737/1000\n",
      "2919/2919 [==============================] - 0s 79us/step - loss: 0.1032 - mse: 0.0178 - mae: 0.1032\n",
      "Epoch 738/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.1053 - mse: 0.0186 - mae: 0.1053\n",
      "Epoch 739/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1084 - mse: 0.0194 - mae: 0.1084\n",
      "Epoch 740/1000\n",
      "2919/2919 [==============================] - 0s 114us/step - loss: 0.1248 - mse: 0.0252 - mae: 0.1248\n",
      "Epoch 741/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1025 - mse: 0.0176 - mae: 0.1025\n",
      "Epoch 742/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0935 - mse: 0.0149 - mae: 0.0935\n",
      "Epoch 743/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1006 - mse: 0.0172 - mae: 0.1006\n",
      "Epoch 744/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1185 - mse: 0.0236 - mae: 0.1185\n",
      "Epoch 745/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.0923 - mse: 0.0147 - mae: 0.0923\n",
      "Epoch 746/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1020 - mse: 0.0177 - mae: 0.1020\n",
      "Epoch 747/1000\n",
      "2919/2919 [==============================] - 0s 56us/step - loss: 0.1062 - mse: 0.0188 - mae: 0.1062\n",
      "Epoch 748/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1296 - mse: 0.0282 - mae: 0.1296\n",
      "Epoch 749/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1264 - mse: 0.0253 - mae: 0.1264\n",
      "Epoch 750/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1064 - mse: 0.0188 - mae: 0.1064\n",
      "Epoch 751/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0938 - mse: 0.0146 - mae: 0.0938\n",
      "Epoch 752/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1160 - mse: 0.0235 - mae: 0.1160\n",
      "Epoch 753/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1062 - mse: 0.0188 - mae: 0.1062\n",
      "Epoch 754/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1336 - mse: 0.0295 - mae: 0.1336\n",
      "Epoch 755/1000\n",
      "2919/2919 [==============================] - 0s 68us/step - loss: 0.1072 - mse: 0.0187 - mae: 0.1072\n",
      "Epoch 756/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1172 - mse: 0.0238 - mae: 0.1172\n",
      "Epoch 757/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1222 - mse: 0.0247 - mae: 0.1222\n",
      "Epoch 758/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.0962 - mse: 0.0153 - mae: 0.0962\n",
      "Epoch 759/1000\n",
      "2919/2919 [==============================] - 0s 57us/step - loss: 0.1206 - mse: 0.0241 - mae: 0.1206\n",
      "Epoch 760/1000\n",
      "2919/2919 [==============================] - 0s 52us/step - loss: 0.0973 - mse: 0.0162 - mae: 0.0973\n",
      "Epoch 761/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.0978 - mse: 0.0163 - mae: 0.0978\n",
      "Epoch 762/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1024 - mse: 0.0177 - mae: 0.1024\n",
      "Epoch 763/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1077 - mse: 0.0191 - mae: 0.1077\n",
      "Epoch 764/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1314 - mse: 0.0279 - mae: 0.1314\n",
      "Epoch 765/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1014 - mse: 0.0178 - mae: 0.1014\n",
      "Epoch 766/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0980 - mse: 0.0162 - mae: 0.0980\n",
      "Epoch 767/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1016 - mse: 0.0170 - mae: 0.1016\n",
      "Epoch 768/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1037 - mse: 0.0172 - mae: 0.1037\n",
      "Epoch 769/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1001 - mse: 0.0171 - mae: 0.1001\n",
      "Epoch 770/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1002 - mse: 0.0164 - mae: 0.1002\n",
      "Epoch 771/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1003 - mse: 0.0164 - mae: 0.1003\n",
      "Epoch 772/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0932 - mse: 0.0147 - mae: 0.0932\n",
      "Epoch 773/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1002 - mse: 0.0169 - mae: 0.1002\n",
      "Epoch 774/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0948 - mse: 0.0153 - mae: 0.0948\n",
      "Epoch 775/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0985 - mse: 0.0163 - mae: 0.0985\n",
      "Epoch 776/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1281 - mse: 0.0265 - mae: 0.1281\n",
      "Epoch 777/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1236 - mse: 0.0259 - mae: 0.1236\n",
      "Epoch 778/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1192 - mse: 0.0230 - mae: 0.1192\n",
      "Epoch 779/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.0966 - mse: 0.0163 - mae: 0.0966\n",
      "Epoch 780/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1089 - mse: 0.0194 - mae: 0.1089\n",
      "Epoch 781/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1100 - mse: 0.0204 - mae: 0.1100\n",
      "Epoch 782/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0913 - mse: 0.0144 - mae: 0.0913\n",
      "Epoch 783/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.0937 - mse: 0.0149 - mae: 0.0937\n",
      "Epoch 784/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1009 - mse: 0.0172 - mae: 0.1009\n",
      "Epoch 785/1000\n",
      "2919/2919 [==============================] - 0s 32us/step - loss: 0.1150 - mse: 0.0218 - mae: 0.1150\n",
      "Epoch 786/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1082 - mse: 0.0192 - mae: 0.1082\n",
      "Epoch 787/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0998 - mse: 0.0166 - mae: 0.0998\n",
      "Epoch 788/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1138 - mse: 0.0211 - mae: 0.1138\n",
      "Epoch 789/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1031 - mse: 0.0174 - mae: 0.1031\n",
      "Epoch 790/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1003 - mse: 0.0171 - mae: 0.1003\n",
      "Epoch 791/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0955 - mse: 0.0156 - mae: 0.0955\n",
      "Epoch 792/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.0951 - mse: 0.0155 - mae: 0.0951\n",
      "Epoch 793/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1062 - mse: 0.0190 - mae: 0.1062\n",
      "Epoch 794/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.0995 - mse: 0.0166 - mae: 0.0995\n",
      "Epoch 795/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.0998 - mse: 0.0170 - mae: 0.0998\n",
      "Epoch 796/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1008 - mse: 0.0168 - mae: 0.1008\n",
      "Epoch 797/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.0938 - mse: 0.0151 - mae: 0.0938\n",
      "Epoch 798/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1067 - mse: 0.0193 - mae: 0.1067\n",
      "Epoch 799/1000\n",
      "2919/2919 [==============================] - 1s 190us/step - loss: 0.1064 - mse: 0.0185 - mae: 0.1064\n",
      "Epoch 800/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1211 - mse: 0.0251 - mae: 0.1211\n",
      "Epoch 801/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1025 - mse: 0.0181 - mae: 0.1025\n",
      "Epoch 802/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1382 - mse: 0.0303 - mae: 0.1382\n",
      "Epoch 803/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1195 - mse: 0.0242 - mae: 0.1195\n",
      "Epoch 804/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1209 - mse: 0.0238 - mae: 0.1209\n",
      "Epoch 805/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1157 - mse: 0.0219 - mae: 0.1157\n",
      "Epoch 806/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1131 - mse: 0.0204 - mae: 0.1131\n",
      "Epoch 807/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1279 - mse: 0.0261 - mae: 0.1279\n",
      "Epoch 808/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.0942 - mse: 0.0150 - mae: 0.0942\n",
      "Epoch 809/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0909 - mse: 0.0142 - mae: 0.0909\n",
      "Epoch 810/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1000 - mse: 0.0167 - mae: 0.1000\n",
      "Epoch 811/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1049 - mse: 0.0188 - mae: 0.1049\n",
      "Epoch 812/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1156 - mse: 0.0226 - mae: 0.1156\n",
      "Epoch 813/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0928 - mse: 0.0150 - mae: 0.0928\n",
      "Epoch 814/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0951 - mse: 0.0153 - mae: 0.0951\n",
      "Epoch 815/1000\n",
      "2919/2919 [==============================] - 0s 29us/step - loss: 0.1056 - mse: 0.0186 - mae: 0.1056\n",
      "Epoch 816/1000\n",
      "2919/2919 [==============================] - 0s 29us/step - loss: 0.1080 - mse: 0.0194 - mae: 0.1080\n",
      "Epoch 817/1000\n",
      "2919/2919 [==============================] - 0s 29us/step - loss: 0.1271 - mse: 0.0278 - mae: 0.1271\n",
      "Epoch 818/1000\n",
      "2919/2919 [==============================] - 0s 29us/step - loss: 0.0948 - mse: 0.0153 - mae: 0.0948\n",
      "Epoch 819/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1179 - mse: 0.0225 - mae: 0.1179\n",
      "Epoch 820/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.0980 - mse: 0.0162 - mae: 0.0980\n",
      "Epoch 821/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.0987 - mse: 0.0164 - mae: 0.0987\n",
      "Epoch 822/1000\n",
      "2919/2919 [==============================] - 1s 232us/step - loss: 0.1221 - mse: 0.0250 - mae: 0.1221\n",
      "Epoch 823/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.0960 - mse: 0.0154 - mae: 0.0960\n",
      "Epoch 824/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.0977 - mse: 0.0163 - mae: 0.0977\n",
      "Epoch 825/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1119 - mse: 0.0216 - mae: 0.1119\n",
      "Epoch 826/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1150 - mse: 0.0221 - mae: 0.1150\n",
      "Epoch 827/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.0975 - mse: 0.0166 - mae: 0.0975\n",
      "Epoch 828/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0942 - mse: 0.0157 - mae: 0.0942\n",
      "Epoch 829/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0958 - mse: 0.0152 - mae: 0.0958\n",
      "Epoch 830/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1472 - mse: 0.0338 - mae: 0.1472\n",
      "Epoch 831/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0945 - mse: 0.0153 - mae: 0.0945\n",
      "Epoch 832/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1120 - mse: 0.0210 - mae: 0.1120\n",
      "Epoch 833/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1010 - mse: 0.0168 - mae: 0.1010\n",
      "Epoch 834/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1108 - mse: 0.0201 - mae: 0.1108\n",
      "Epoch 835/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1019 - mse: 0.0176 - mae: 0.1019\n",
      "Epoch 836/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.0977 - mse: 0.0164 - mae: 0.0977\n",
      "Epoch 837/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1076 - mse: 0.0191 - mae: 0.1076\n",
      "Epoch 838/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1053 - mse: 0.0188 - mae: 0.1053\n",
      "Epoch 839/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1060 - mse: 0.0186 - mae: 0.1060\n",
      "Epoch 840/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1146 - mse: 0.0223 - mae: 0.1146\n",
      "Epoch 841/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1012 - mse: 0.0174 - mae: 0.1012\n",
      "Epoch 842/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.0914 - mse: 0.0142 - mae: 0.0914\n",
      "Epoch 843/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1018 - mse: 0.0177 - mae: 0.1018\n",
      "Epoch 844/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.0986 - mse: 0.0162 - mae: 0.0986\n",
      "Epoch 845/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.0984 - mse: 0.0165 - mae: 0.0984\n",
      "Epoch 846/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.0898 - mse: 0.0139 - mae: 0.0898\n",
      "Epoch 847/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.0980 - mse: 0.0160 - mae: 0.0980\n",
      "Epoch 848/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0931 - mse: 0.0147 - mae: 0.0931\n",
      "Epoch 849/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.0965 - mse: 0.0158 - mae: 0.0965\n",
      "Epoch 850/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1125 - mse: 0.0225 - mae: 0.1125\n",
      "Epoch 851/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1034 - mse: 0.0178 - mae: 0.1034\n",
      "Epoch 852/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1068 - mse: 0.0198 - mae: 0.1068\n",
      "Epoch 853/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.0914 - mse: 0.0144 - mae: 0.0914\n",
      "Epoch 854/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1082 - mse: 0.0196 - mae: 0.1082\n",
      "Epoch 855/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1045 - mse: 0.0185 - mae: 0.1045\n",
      "Epoch 856/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1143 - mse: 0.0217 - mae: 0.1143\n",
      "Epoch 857/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.1101 - mse: 0.0210 - mae: 0.1101\n",
      "Epoch 858/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1020 - mse: 0.0172 - mae: 0.1020\n",
      "Epoch 859/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1018 - mse: 0.0169 - mae: 0.1018\n",
      "Epoch 860/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1151 - mse: 0.0228 - mae: 0.1151\n",
      "Epoch 861/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.1087 - mse: 0.0196 - mae: 0.1087\n",
      "Epoch 862/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0922 - mse: 0.0142 - mae: 0.0922\n",
      "Epoch 863/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1056 - mse: 0.0195 - mae: 0.1056\n",
      "Epoch 864/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1066 - mse: 0.0186 - mae: 0.1066\n",
      "Epoch 865/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1073 - mse: 0.0190 - mae: 0.1073\n",
      "Epoch 866/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1237 - mse: 0.0259 - mae: 0.1237\n",
      "Epoch 867/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1270 - mse: 0.0282 - mae: 0.1270\n",
      "Epoch 868/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1009 - mse: 0.0178 - mae: 0.1009\n",
      "Epoch 869/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1413 - mse: 0.0368 - mae: 0.1413\n",
      "Epoch 870/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1003 - mse: 0.0169 - mae: 0.1003\n",
      "Epoch 871/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1090 - mse: 0.0209 - mae: 0.1090\n",
      "Epoch 872/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1140 - mse: 0.0214 - mae: 0.1140\n",
      "Epoch 873/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.0995 - mse: 0.0164 - mae: 0.0995\n",
      "Epoch 874/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1074 - mse: 0.0193 - mae: 0.1074\n",
      "Epoch 875/1000\n",
      "2919/2919 [==============================] - 0s 50us/step - loss: 0.1127 - mse: 0.0204 - mae: 0.1127\n",
      "Epoch 876/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.0947 - mse: 0.0151 - mae: 0.0947\n",
      "Epoch 877/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1009 - mse: 0.0171 - mae: 0.1009\n",
      "Epoch 878/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1154 - mse: 0.0237 - mae: 0.1154\n",
      "Epoch 879/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1241 - mse: 0.0240 - mae: 0.1241\n",
      "Epoch 880/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1066 - mse: 0.0182 - mae: 0.1066\n",
      "Epoch 881/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1239 - mse: 0.0257 - mae: 0.1239\n",
      "Epoch 882/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0876 - mse: 0.0133 - mae: 0.0876\n",
      "Epoch 883/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0898 - mse: 0.0136 - mae: 0.0898\n",
      "Epoch 884/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1011 - mse: 0.0174 - mae: 0.1011\n",
      "Epoch 885/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0970 - mse: 0.0161 - mae: 0.0970\n",
      "Epoch 886/1000\n",
      "2919/2919 [==============================] - 0s 47us/step - loss: 0.1335 - mse: 0.0294 - mae: 0.1335\n",
      "Epoch 887/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.0980 - mse: 0.0163 - mae: 0.0980\n",
      "Epoch 888/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1055 - mse: 0.0185 - mae: 0.1055\n",
      "Epoch 889/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1035 - mse: 0.0177 - mae: 0.1035\n",
      "Epoch 890/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1640 - mse: 0.0488 - mae: 0.1640\n",
      "Epoch 891/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1218 - mse: 0.0253 - mae: 0.1218\n",
      "Epoch 892/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.0970 - mse: 0.0157 - mae: 0.0970\n",
      "Epoch 893/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1071 - mse: 0.0195 - mae: 0.1071\n",
      "Epoch 894/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.0839 - mse: 0.0121 - mae: 0.0839\n",
      "Epoch 895/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.0978 - mse: 0.0158 - mae: 0.0978\n",
      "Epoch 896/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1113 - mse: 0.0200 - mae: 0.1113\n",
      "Epoch 897/1000\n",
      "2919/2919 [==============================] - 1s 227us/step - loss: 0.1048 - mse: 0.0189 - mae: 0.1048\n",
      "Epoch 898/1000\n",
      "2919/2919 [==============================] - 0s 51us/step - loss: 0.0948 - mse: 0.0152 - mae: 0.0948\n",
      "Epoch 899/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1072 - mse: 0.0189 - mae: 0.1072\n",
      "Epoch 900/1000\n",
      "2919/2919 [==============================] - 0s 49us/step - loss: 0.0943 - mse: 0.0148 - mae: 0.0943\n",
      "Epoch 901/1000\n",
      "2919/2919 [==============================] - 0s 46us/step - loss: 0.0961 - mse: 0.0154 - mae: 0.0961\n",
      "Epoch 902/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1028 - mse: 0.0172 - mae: 0.1028\n",
      "Epoch 903/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1282 - mse: 0.0264 - mae: 0.1282\n",
      "Epoch 904/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.1097 - mse: 0.0210 - mae: 0.1097\n",
      "Epoch 905/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1083 - mse: 0.0196 - mae: 0.1083\n",
      "Epoch 906/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0935 - mse: 0.0145 - mae: 0.0935\n",
      "Epoch 907/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0922 - mse: 0.0139 - mae: 0.0922\n",
      "Epoch 908/1000\n",
      "2919/2919 [==============================] - 0s 48us/step - loss: 0.1065 - mse: 0.0190 - mae: 0.1065\n",
      "Epoch 909/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.0966 - mse: 0.0163 - mae: 0.0966\n",
      "Epoch 910/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0911 - mse: 0.0141 - mae: 0.0911\n",
      "Epoch 911/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0973 - mse: 0.0157 - mae: 0.0973\n",
      "Epoch 912/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1285 - mse: 0.0262 - mae: 0.1285\n",
      "Epoch 913/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.1006 - mse: 0.0168 - mae: 0.1006\n",
      "Epoch 914/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1032 - mse: 0.0179 - mae: 0.1032\n",
      "Epoch 915/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.0963 - mse: 0.0155 - mae: 0.0963\n",
      "Epoch 916/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.1004 - mse: 0.0166 - mae: 0.1004\n",
      "Epoch 917/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.0909 - mse: 0.0143 - mae: 0.0909\n",
      "Epoch 918/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1265 - mse: 0.0274 - mae: 0.1265\n",
      "Epoch 919/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0979 - mse: 0.0158 - mae: 0.0979\n",
      "Epoch 920/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1182 - mse: 0.0229 - mae: 0.1182\n",
      "Epoch 921/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1183 - mse: 0.0231 - mae: 0.1183\n",
      "Epoch 922/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1042 - mse: 0.0173 - mae: 0.1042\n",
      "Epoch 923/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1023 - mse: 0.0174 - mae: 0.1023\n",
      "Epoch 924/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1095 - mse: 0.0201 - mae: 0.1095\n",
      "Epoch 925/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0837 - mse: 0.0120 - mae: 0.0837\n",
      "Epoch 926/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.0925 - mse: 0.0145 - mae: 0.0925\n",
      "Epoch 927/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1053 - mse: 0.0186 - mae: 0.1053\n",
      "Epoch 928/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1084 - mse: 0.0192 - mae: 0.1084\n",
      "Epoch 929/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.0998 - mse: 0.0165 - mae: 0.0998\n",
      "Epoch 930/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0878 - mse: 0.0131 - mae: 0.0878\n",
      "Epoch 931/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1022 - mse: 0.0171 - mae: 0.1022\n",
      "Epoch 932/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.0999 - mse: 0.0164 - mae: 0.0999\n",
      "Epoch 933/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0896 - mse: 0.0137 - mae: 0.0896\n",
      "Epoch 934/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.0970 - mse: 0.0156 - mae: 0.0970\n",
      "Epoch 935/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1223 - mse: 0.0241 - mae: 0.1223\n",
      "Epoch 936/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1034 - mse: 0.0178 - mae: 0.1034\n",
      "Epoch 937/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0929 - mse: 0.0151 - mae: 0.0929\n",
      "Epoch 938/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.1107 - mse: 0.0204 - mae: 0.1107\n",
      "Epoch 939/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.0978 - mse: 0.0162 - mae: 0.0978\n",
      "Epoch 940/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0944 - mse: 0.0151 - mae: 0.0944\n",
      "Epoch 941/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1072 - mse: 0.0189 - mae: 0.1072\n",
      "Epoch 942/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.0935 - mse: 0.0146 - mae: 0.0935\n",
      "Epoch 943/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.0843 - mse: 0.0124 - mae: 0.0843\n",
      "Epoch 944/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.0924 - mse: 0.0147 - mae: 0.0924\n",
      "Epoch 945/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.0956 - mse: 0.0154 - mae: 0.0956\n",
      "Epoch 946/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1107 - mse: 0.0198 - mae: 0.1107\n",
      "Epoch 947/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1127 - mse: 0.0210 - mae: 0.1127\n",
      "Epoch 948/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1273 - mse: 0.0265 - mae: 0.1273\n",
      "Epoch 949/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1033 - mse: 0.0180 - mae: 0.1033\n",
      "Epoch 950/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0907 - mse: 0.0138 - mae: 0.0907\n",
      "Epoch 951/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.0961 - mse: 0.0160 - mae: 0.0961\n",
      "Epoch 952/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.0851 - mse: 0.0127 - mae: 0.0851\n",
      "Epoch 953/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1265 - mse: 0.0275 - mae: 0.1265\n",
      "Epoch 954/1000\n",
      "2919/2919 [==============================] - 0s 42us/step - loss: 0.0913 - mse: 0.0146 - mae: 0.0913\n",
      "Epoch 955/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1129 - mse: 0.0209 - mae: 0.1129\n",
      "Epoch 956/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1037 - mse: 0.0188 - mae: 0.1037\n",
      "Epoch 957/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1283 - mse: 0.0275 - mae: 0.1283\n",
      "Epoch 958/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.0970 - mse: 0.0153 - mae: 0.0970\n",
      "Epoch 959/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0937 - mse: 0.0147 - mae: 0.0937\n",
      "Epoch 960/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1121 - mse: 0.0221 - mae: 0.1121\n",
      "Epoch 961/1000\n",
      "2919/2919 [==============================] - 0s 43us/step - loss: 0.0967 - mse: 0.0158 - mae: 0.0967\n",
      "Epoch 962/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1066 - mse: 0.0187 - mae: 0.1066\n",
      "Epoch 963/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0923 - mse: 0.0143 - mae: 0.0923\n",
      "Epoch 964/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.1107 - mse: 0.0210 - mae: 0.1107\n",
      "Epoch 965/1000\n",
      "2919/2919 [==============================] - 0s 40us/step - loss: 0.1151 - mse: 0.0215 - mae: 0.1151\n",
      "Epoch 966/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.0916 - mse: 0.0143 - mae: 0.0916\n",
      "Epoch 967/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0943 - mse: 0.0151 - mae: 0.0943\n",
      "Epoch 968/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.0952 - mse: 0.0153 - mae: 0.0952\n",
      "Epoch 969/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1156 - mse: 0.0227 - mae: 0.1156\n",
      "Epoch 970/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.0914 - mse: 0.0140 - mae: 0.0914\n",
      "Epoch 971/1000\n",
      "2919/2919 [==============================] - 0s 45us/step - loss: 0.0932 - mse: 0.0150 - mae: 0.0932\n",
      "Epoch 972/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1041 - mse: 0.0179 - mae: 0.1041\n",
      "Epoch 973/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0954 - mse: 0.0153 - mae: 0.0954\n",
      "Epoch 974/1000\n",
      "2919/2919 [==============================] - 0s 41us/step - loss: 0.0818 - mse: 0.0117 - mae: 0.0818\n",
      "Epoch 975/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1321 - mse: 0.0282 - mae: 0.1321\n",
      "Epoch 976/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.0967 - mse: 0.0160 - mae: 0.0967\n",
      "Epoch 977/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1153 - mse: 0.0212 - mae: 0.1153\n",
      "Epoch 978/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1013 - mse: 0.0171 - mae: 0.1013\n",
      "Epoch 979/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1031 - mse: 0.0180 - mae: 0.1031\n",
      "Epoch 980/1000\n",
      "2919/2919 [==============================] - 0s 39us/step - loss: 0.1412 - mse: 0.0326 - mae: 0.1412\n",
      "Epoch 981/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.0933 - mse: 0.0149 - mae: 0.0933\n",
      "Epoch 982/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.1058 - mse: 0.0187 - mae: 0.1058\n",
      "Epoch 983/1000\n",
      "2919/2919 [==============================] - 0s 44us/step - loss: 0.1056 - mse: 0.0185 - mae: 0.1056\n",
      "Epoch 984/1000\n",
      "2919/2919 [==============================] - 0s 37us/step - loss: 0.1049 - mse: 0.0182 - mae: 0.1049\n",
      "Epoch 985/1000\n",
      "2919/2919 [==============================] - 0s 34us/step - loss: 0.0983 - mse: 0.0160 - mae: 0.0983\n",
      "Epoch 986/1000\n",
      "2919/2919 [==============================] - 0s 31us/step - loss: 0.1069 - mse: 0.0185 - mae: 0.1069\n",
      "Epoch 987/1000\n",
      "2919/2919 [==============================] - 0s 31us/step - loss: 0.0932 - mse: 0.0148 - mae: 0.0932\n",
      "Epoch 988/1000\n",
      "2919/2919 [==============================] - 0s 30us/step - loss: 0.0862 - mse: 0.0127 - mae: 0.0862\n",
      "Epoch 989/1000\n",
      "2919/2919 [==============================] - 0s 30us/step - loss: 0.1084 - mse: 0.0196 - mae: 0.1084\n",
      "Epoch 990/1000\n",
      "2919/2919 [==============================] - 0s 29us/step - loss: 0.1233 - mse: 0.0254 - mae: 0.1233\n",
      "Epoch 991/1000\n",
      "2919/2919 [==============================] - 0s 36us/step - loss: 0.0955 - mse: 0.0160 - mae: 0.0955\n",
      "Epoch 992/1000\n",
      "2919/2919 [==============================] - 0s 30us/step - loss: 0.1177 - mse: 0.0227 - mae: 0.1177\n",
      "Epoch 993/1000\n",
      "2919/2919 [==============================] - 0s 30us/step - loss: 0.0975 - mse: 0.0163 - mae: 0.0975\n",
      "Epoch 994/1000\n",
      "2919/2919 [==============================] - 0s 30us/step - loss: 0.1029 - mse: 0.0177 - mae: 0.1029\n",
      "Epoch 995/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1038 - mse: 0.0180 - mae: 0.1038\n",
      "Epoch 996/1000\n",
      "2919/2919 [==============================] - 0s 38us/step - loss: 0.1191 - mse: 0.0228 - mae: 0.1191\n",
      "Epoch 997/1000\n",
      "2919/2919 [==============================] - 0s 33us/step - loss: 0.1168 - mse: 0.0220 - mae: 0.1168\n",
      "Epoch 998/1000\n",
      "2919/2919 [==============================] - 0s 53us/step - loss: 0.0841 - mse: 0.0124 - mae: 0.0841\n",
      "Epoch 999/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.0930 - mse: 0.0145 - mae: 0.0930\n",
      "Epoch 1000/1000\n",
      "2919/2919 [==============================] - 0s 35us/step - loss: 0.1038 - mse: 0.0183 - mae: 0.1038\n",
      "2919/2919 [==============================] - 0s 33us/step\n",
      "Test: [0.08122403969150388, 0.011596422642469406, 0.08122401684522629]\n"
     ]
    }
   ],
   "source": [
    "# Regression Example \n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"bs_training.csv\")\n",
    "X_train = dataset.iloc[:, :4].values\n",
    "Y_train = dataset.iloc[:, 4].values\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mse', 'mae'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=1000, verbose=1)#, batch_size=10)\n",
    "evaluator = model.evaluate(X_train, Y_train)\n",
    "print('Test: {}'.format(evaluator))\n",
    "\n",
    "model.save('bs_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see now how the NN behaves with the two testing samples. First the one generated with parameters in the training phase space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = load_model('bs_model.h5')\n",
    "\n",
    "dataset = pd.read_csv(\"bs_testing.csv\")\n",
    "X_test = dataset.iloc[:, :4].values\n",
    "Y_test = dataset.iloc[:, 4].values\n",
    "\n",
    "plt.plot(model.predict(X_test), color=\"red\", label=\"NN price\")\n",
    "plt.plot(Y_test, label=\"BS price\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"comparison_fair.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agreement is pretty good. To illustrate how a neural network is not able to extrapolate results if the prediction is tried with inputs outside the phase-space of the training (i.e. testing sample different from the one used in the training) I have tried to predict the price of a call with different maturity (strike and vol are in the range of the training instead):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = load_model('bs_model.h5')\n",
    "\n",
    "dataset = pd.read_csv(\"bs_testing_off.csv\")\n",
    "X_test = dataset.iloc[:, :4].values\n",
    "Y_test = dataset.iloc[:, 4].values\n",
    "\n",
    "plt.plot(model.predict(X_test), color=\"red\", label=\"NN price\")\n",
    "plt.plot(Y_test, label=\"BS price\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"comparison_off.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Analysis\n",
    "In finance, technical analysis is a security analysis discipline for forecasting the direction of prices through the study of past market data, primarily price and volume.\n",
    "Essentially the analyst looks for particular patterns in the price time series that are *known* to develop in predictable ways to take profit of it.\n",
    "\n",
    "<img src=\"H_and_s_top_new.jpg\" width=400>\n",
    "<img src=\"Triangle-ascending.jpg\" width=400>\n",
    "\n",
    "As you may imagine we will try to develop a CNN (like in the handwriting case) capable of classifying features in time series to be used in a technical analysis (this is much faster than having somebody looking at thousands of time series by eye...).\n",
    "\n",
    "As in the previous application I have generated myself the training set simulating 21600 time series (1/3 with head and shoulder patter, 1/3 with triangle pattern and 1/3 with no pattern). *To make the training easier the features have been exagerated.*\n",
    "\n",
    "<figure>\n",
    "<img src=\"image_1.png\" width=300>\n",
    "<figcaption>No pattern</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<img src=\"image_2.png\" width=300>\n",
    "<figcaption>Head and shoulder pattern</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<img src=\"image_0.png\" width=300>\n",
    "<figcaption>Tringle pattern</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sani/.python3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      " - 2s - loss: 0.9404 - accuracy: 0.7007\n",
      "Epoch 2/80\n",
      " - 2s - loss: 0.4922 - accuracy: 0.8320\n",
      "Epoch 3/80\n",
      " - 2s - loss: 0.4599 - accuracy: 0.8413\n",
      "Epoch 4/80\n",
      " - 2s - loss: 0.4443 - accuracy: 0.8510\n",
      "Epoch 5/80\n",
      " - 2s - loss: 0.4457 - accuracy: 0.8517\n",
      "Epoch 6/80\n",
      " - 2s - loss: 0.4575 - accuracy: 0.8453\n",
      "Epoch 7/80\n",
      " - 2s - loss: 0.4403 - accuracy: 0.8460\n",
      "Epoch 8/80\n",
      " - 2s - loss: 0.4326 - accuracy: 0.8527\n",
      "Epoch 9/80\n",
      " - 2s - loss: 0.4432 - accuracy: 0.8490\n",
      "Epoch 10/80\n",
      " - 2s - loss: 0.4274 - accuracy: 0.8500\n",
      "Epoch 11/80\n",
      " - 2s - loss: 0.4465 - accuracy: 0.8430\n",
      "Epoch 12/80\n",
      " - 2s - loss: 0.4312 - accuracy: 0.8483\n",
      "Epoch 13/80\n",
      " - 2s - loss: 0.4277 - accuracy: 0.8537\n",
      "Epoch 14/80\n",
      " - 2s - loss: 0.4181 - accuracy: 0.8510\n",
      "Epoch 15/80\n",
      " - 2s - loss: 0.4406 - accuracy: 0.8497\n",
      "Epoch 16/80\n",
      " - 2s - loss: 0.4250 - accuracy: 0.8467\n",
      "Epoch 17/80\n",
      " - 2s - loss: 0.4235 - accuracy: 0.8520\n",
      "Epoch 18/80\n",
      " - 2s - loss: 0.4224 - accuracy: 0.8537\n",
      "Epoch 19/80\n",
      " - 1s - loss: 0.4090 - accuracy: 0.8603\n",
      "Epoch 20/80\n",
      " - 1s - loss: 0.4013 - accuracy: 0.8587\n",
      "Epoch 21/80\n",
      " - 2s - loss: 0.4025 - accuracy: 0.8540\n",
      "Epoch 22/80\n",
      " - 2s - loss: 0.3892 - accuracy: 0.8590\n",
      "Epoch 23/80\n",
      " - 2s - loss: 0.3913 - accuracy: 0.8600\n",
      "Epoch 24/80\n",
      " - 2s - loss: 0.4005 - accuracy: 0.8547\n",
      "Epoch 25/80\n",
      " - 2s - loss: 0.3901 - accuracy: 0.8577\n",
      "Epoch 26/80\n",
      " - 2s - loss: 0.3701 - accuracy: 0.8663\n",
      "Epoch 27/80\n",
      " - 2s - loss: 0.3760 - accuracy: 0.8623\n",
      "Epoch 28/80\n",
      " - 2s - loss: 0.3530 - accuracy: 0.8670\n",
      "Epoch 29/80\n",
      " - 2s - loss: 0.3436 - accuracy: 0.8673\n",
      "Epoch 30/80\n",
      " - 2s - loss: 0.3439 - accuracy: 0.8680\n",
      "Epoch 31/80\n",
      " - 2s - loss: 0.3276 - accuracy: 0.8707\n",
      "Epoch 32/80\n",
      " - 2s - loss: 0.3327 - accuracy: 0.8697\n",
      "Epoch 33/80\n",
      " - 2s - loss: 0.6462 - accuracy: 0.8333\n",
      "Epoch 34/80\n",
      " - 2s - loss: 0.4555 - accuracy: 0.8397\n",
      "Epoch 35/80\n",
      " - 2s - loss: 0.4020 - accuracy: 0.8537\n",
      "Epoch 36/80\n",
      " - 2s - loss: 0.4163 - accuracy: 0.8500\n",
      "Epoch 37/80\n",
      " - 2s - loss: 0.3562 - accuracy: 0.8643\n",
      "Epoch 38/80\n",
      " - 2s - loss: 0.3541 - accuracy: 0.8617\n",
      "Epoch 39/80\n",
      " - 2s - loss: 0.3457 - accuracy: 0.8647\n",
      "Epoch 40/80\n",
      " - 2s - loss: 0.3310 - accuracy: 0.8697\n",
      "Epoch 41/80\n",
      " - 2s - loss: 0.3311 - accuracy: 0.8700\n",
      "Epoch 42/80\n",
      " - 2s - loss: 0.3232 - accuracy: 0.8703\n",
      "Epoch 43/80\n",
      " - 2s - loss: 0.3286 - accuracy: 0.8707\n",
      "Epoch 44/80\n",
      " - 1s - loss: 0.3195 - accuracy: 0.8737\n",
      "Epoch 45/80\n",
      " - 2s - loss: 0.3026 - accuracy: 0.8793\n",
      "Epoch 46/80\n",
      " - 1s - loss: 0.2971 - accuracy: 0.8740\n",
      "Epoch 47/80\n",
      " - 2s - loss: 0.3064 - accuracy: 0.8810\n",
      "Epoch 48/80\n",
      " - 1s - loss: 0.2952 - accuracy: 0.8837\n",
      "Epoch 49/80\n",
      " - 1s - loss: 0.2982 - accuracy: 0.8837\n",
      "Epoch 50/80\n",
      " - 2s - loss: 0.2803 - accuracy: 0.8870\n",
      "Epoch 51/80\n",
      " - 2s - loss: 0.2863 - accuracy: 0.8860\n",
      "Epoch 52/80\n",
      " - 2s - loss: 0.2730 - accuracy: 0.8927\n",
      "Epoch 53/80\n",
      " - 2s - loss: 0.2756 - accuracy: 0.8900\n",
      "Epoch 54/80\n",
      " - 2s - loss: 0.2751 - accuracy: 0.8897\n",
      "Epoch 55/80\n",
      " - 2s - loss: 0.2625 - accuracy: 0.8970\n",
      "Epoch 56/80\n",
      " - 2s - loss: 0.2645 - accuracy: 0.8933\n",
      "Epoch 57/80\n",
      " - 2s - loss: 0.2653 - accuracy: 0.8970\n",
      "Epoch 58/80\n",
      " - 2s - loss: 0.2555 - accuracy: 0.9000\n",
      "Epoch 59/80\n",
      " - 1s - loss: 0.2548 - accuracy: 0.9017\n",
      "Epoch 60/80\n",
      " - 1s - loss: 0.2444 - accuracy: 0.9007\n",
      "Epoch 61/80\n",
      " - 2s - loss: 0.2478 - accuracy: 0.9027\n",
      "Epoch 62/80\n",
      " - 1s - loss: 0.2456 - accuracy: 0.8987\n",
      "Epoch 63/80\n",
      " - 2s - loss: 0.2345 - accuracy: 0.9087\n",
      "Epoch 64/80\n",
      " - 1s - loss: 0.2372 - accuracy: 0.9027\n",
      "Epoch 65/80\n",
      " - 2s - loss: 0.2373 - accuracy: 0.9040\n",
      "Epoch 66/80\n",
      " - 2s - loss: 0.2268 - accuracy: 0.9083\n",
      "Epoch 67/80\n",
      " - 2s - loss: 0.2252 - accuracy: 0.9057\n",
      "Epoch 68/80\n",
      " - 1s - loss: 0.2128 - accuracy: 0.9170\n",
      "Epoch 69/80\n",
      " - 1s - loss: 0.2504 - accuracy: 0.8987\n",
      "Epoch 70/80\n",
      " - 2s - loss: 0.2235 - accuracy: 0.9043\n",
      "Epoch 71/80\n",
      " - 2s - loss: 0.2222 - accuracy: 0.9153\n",
      "Epoch 72/80\n",
      " - 2s - loss: 0.2149 - accuracy: 0.9100\n",
      "Epoch 73/80\n",
      " - 2s - loss: 0.2154 - accuracy: 0.9110\n",
      "Epoch 74/80\n",
      " - 2s - loss: 0.2128 - accuracy: 0.9163\n",
      "Epoch 75/80\n",
      " - 1s - loss: 0.2074 - accuracy: 0.9167\n",
      "Epoch 76/80\n",
      " - 1s - loss: 0.2246 - accuracy: 0.9087\n",
      "Epoch 77/80\n",
      " - 2s - loss: 0.2166 - accuracy: 0.9087\n",
      "Epoch 78/80\n",
      " - 2s - loss: 0.1974 - accuracy: 0.9187\n",
      "Epoch 79/80\n",
      " - 2s - loss: 0.1914 - accuracy: 0.9237\n",
      "Epoch 80/80\n",
      " - 1s - loss: 0.1953 - accuracy: 0.9237\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv1D, Dropout, MaxPooling1D, Flatten, GlobalAveragePooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load the training set\n",
    "with open(\"training_techana_labels.json\", \"r\") as f:\n",
    "    train_labels = json.load(f)\n",
    "train_labels = train_labels[:3000]\n",
    "train_images = []\n",
    "\n",
    "with open(\"training_techana_images.json\", \"r\") as f:\n",
    "    train_images = json.load(f)\n",
    "train_images = train_images[:3000]\n",
    "train_images = np.array(train_images)\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "\n",
    "# define the CNN \n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=80, kernel_size=20, \n",
    "                 activation='relu', input_shape=(101, 1)))\n",
    "model.add(Conv1D(filters=80, kernel_size=15, \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(filters=100, kernel_size=10, \n",
    "                 activation='relu'))\n",
    "model.add(Conv1D(filters=100, kernel_size=5, \n",
    "                 activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# make the training\n",
    "model.fit(train_images, to_categorical(train_labels), \n",
    "          epochs=80, batch_size=35, verbose=2)\n",
    "\n",
    "model.save('techana.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the perfomance I have created a longer time series and passed as input to the CNN a sliding time window to simulate the evolution of the price and a feature that is coming.\n",
    "The goal is to check when the neural net is capable of predicting the incoming pattern.\n",
    "\n",
    "<img src=\"closing_price.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sani/.python3/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['0.97', '0.00', '0.03']\n",
      "0 ['0.67', '0.00', '0.33']\n",
      "0 ['0.97', '0.00', '0.03']\n",
      "0 ['0.93', '0.00', '0.07']\n",
      "0 ['0.93', '0.00', '0.07']\n",
      "0 ['0.57', '0.00', '0.43']\n",
      "1 ['0.00', '1.00', '0.00']\n",
      "1 ['0.00', '1.00', '0.00']\n",
      "1 ['0.00', '1.00', '0.00']\n",
      "1 ['0.00', '1.00', '0.00']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "test_images = []\n",
    "\n",
    "with open(\"testing_techana_frames.json\", \"r\") as f:\n",
    "    test_images = json.load(f)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "#for i in range(test_images.shape[0]):\n",
    "#    plt.plot(test_images[i, :])\n",
    "#    plt.show()\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "model = load_model('techana.h5')\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "for i in range(len(predictions)):\n",
    "    print (np.argmax(predictions[i]), [\"{:.2f}\".format(p) for p in predictions[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So at the 6th sample the CNN start recognizing the *head and shoulder* pattern in the price evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 8.1\n",
    "Try to repeat all the example shown during the lesson.\n",
    "\n",
    "### Exercise 8.2\n",
    "Using the same code illustrated above, test the ANN to recognize digits with your own handwriting (e.g. try to exagerate some feature to fool the NN, or even pass it letters instead of digits and interpret the results).\n",
    "\n",
    "### Exercise 8.3\n",
    "Taking as example the pricing NN trained on call, try to price put options.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
